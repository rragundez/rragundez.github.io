<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Rodrigo Agundez</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2022-02-01T00:00:00+01:00</updated><entry><title>Hogan Assessment</title><link href="/2022-02-01-hogan-assessment.html" rel="alternate"></link><published>2022-02-01T00:00:00+01:00</published><updated>2022-02-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2022-02-01:/2022-02-01-hogan-assessment.html</id><summary type="html">&lt;p&gt;Went over the &lt;a href="https://www.hoganassessments.com/assessment/motives-values-preferences-inventory/"&gt;Hogan assessment&lt;/a&gt; to recognize my strengths and weaknesses with the intention of shaping my teams and environment to suit my strengths and start a path to address my weaknesses.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="leadership"></category><category term="personal development"></category><category term="manager"></category><category term="soft-skills"></category></entry><entry><title>Director of Data Science @ adidas</title><link href="/2021-07-01-director-data-science-adidas.html" rel="alternate"></link><published>2021-07-01T00:00:00+02:00</published><updated>2021-07-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2021-07-01:/2021-07-01-director-data-science-adidas.html</id><summary type="html">&lt;p&gt;Director of Data Science at adidas, responsible for all Trading Sciences global products with focus on our digital channels.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I am currently the Director of Data Science at adidas, responsible for all
Trading Sciences global products with focus on our digital channels. My 3
core responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set the strategic technical vision for Data Science products, both in
terms of performance/added-value and rollout of the products to
different markets;&lt;/li&gt;
&lt;li&gt;Highly technical strategic and operational phases of developing a
Machine Learning platform for Data Scientists in AWS;&lt;/li&gt;
&lt;li&gt;People manager of 3 teams of internal and external Data Scientists
and Machine Learning engineers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some extra details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manage contracting and strategy with external partners (e.g. AWS);&lt;/li&gt;
&lt;li&gt;In charge of +1M yearly budget for external capacity;&lt;/li&gt;
&lt;li&gt;Added value impact of +50M;&lt;/li&gt;
&lt;li&gt;Technical involvement, sometimes hands-on to teach and explain
technical concepts that the team needs to adapt;&lt;/li&gt;
&lt;li&gt;Start a collaboration with AWS ML Labs for a high-risk / high-reward
cutting edge Data Science use case based on graph neural
networks;&lt;/li&gt;
&lt;li&gt;Lead the creation of hackathons to solve out-of-the-box business
problems;&lt;/li&gt;
&lt;li&gt;Establish DRY principles for code and data;&lt;/li&gt;
&lt;li&gt;Very strong collaboration with the Data Platform team to ensure the
adidas platform components address Data Science requirements.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="SageMaker"></category><category term="AWS"></category><category term="deep learning"></category><category term="PyTorch"></category><category term="MLOps"></category><category term="Spark"></category></entry><entry><title>Director Development Experience</title><link href="/2021-07-01-director-development-experience.html" rel="alternate"></link><published>2021-07-01T00:00:00+02:00</published><updated>2021-07-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2021-07-01:/2021-07-01-director-development-experience.html</id><summary type="html">&lt;p&gt;Took an intense 6 months course to become inspirational and inclusive leader in my day-to-day role. DDE focus on enabling the execution of strategy and driving a winning culture by building and leading high performance teams.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="leadership"></category><category term="personal development"></category><category term="manager"></category><category term="soft-skills"></category><category term="innovation"></category></entry><entry><title>Lead Data Scientist @ VodafoneZiggo</title><link href="/2020-02-01-lead-data-scientist-vodafoneziggo.html" rel="alternate"></link><published>2020-02-01T00:00:00+01:00</published><updated>2020-02-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2020-02-01:/2020-02-01-lead-data-scientist-vodafoneziggo.html</id><summary type="html">&lt;p&gt;Lead Data Scientist of a team of 14 people in VodafoneZiggo.&lt;/p&gt;</summary><content type="html">&lt;p&gt;VodafoneZiggo is one of the biggest telecom companies in The Netherlands, it provides internet, mobile and video on demand services. I worked as the Lead Data Scientist for the Advanced Analytics department with 16 people, a combination of Data Scientist and Data Engineers. Some of my accountabilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find, assess and kickstart use cases in the company;&lt;/li&gt;
&lt;li&gt;Elevate the WoW of the team with best practices;&lt;/li&gt;
&lt;li&gt;Guide the Cloud Migration to AWS and cloud cost forecasting;&lt;/li&gt;
&lt;li&gt;Assess 3rd party AI partnerships in the company;&lt;/li&gt;
&lt;li&gt;Hiring of internal and external Data Scientists and Engineers;&lt;/li&gt;
&lt;li&gt;Technical roadmap for the team;&lt;/li&gt;
&lt;li&gt;Point of contact for other teams in VodafoneZiggo (e.g. BICC);&lt;/li&gt;
&lt;li&gt;1 on 1 hands-on development sessions with the team;&lt;/li&gt;
&lt;li&gt;Data acquisition strategy;&lt;/li&gt;
&lt;li&gt;Delivery of technical products;&lt;/li&gt;
&lt;li&gt;Developed the AI environment in the cloud;&lt;/li&gt;
&lt;li&gt;GDPR related procedures to ensure compliance in our use cases;&lt;/li&gt;
&lt;li&gt;Establish DRY principles for code and data.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="AWS"></category><category term="deep learning"></category><category term="GDPR"></category><category term="cloud strategy"></category><category term="AI hiring"></category></entry><entry><title>Career coach for development of people and leadership skills</title><link href="/2020-01-01-career-coach.html" rel="alternate"></link><published>2020-01-01T00:00:00+01:00</published><updated>2020-01-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2020-01-01:/2020-01-01-career-coach.html</id><summary type="html">&lt;p&gt;Hired a career coach to focus on the development of my people and leadership skills.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="leadership"></category><category term="personal development"></category><category term="manager"></category><category term="soft-skills"></category></entry><entry><title>Lead of Artificial Intelligence @ Talpa Network</title><link href="/2019-01-15-lead-artificial-intelligence-talpa-network.html" rel="alternate"></link><published>2019-10-01T00:00:00+02:00</published><updated>2019-10-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2019-10-01:/2019-01-15-lead-artificial-intelligence-talpa-network.html</id><summary type="html">&lt;p&gt;I started and built the AI department in the company.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Talpa Network is one of the biggest media companies in The Netherlands with many brands offering content over radio, television, magazines, Ecommerce, podcasts, video-on-demand, and radio-on-demand. I started and built the AI department in the company. Some of my accountabilities were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hire and built the team using my vast network;&lt;/li&gt;
&lt;li&gt;Built the AI development platform;&lt;/li&gt;
&lt;li&gt;Kickstart AI related projects focused on value creation;&lt;/li&gt;
&lt;li&gt;Assess AI partnerships for all brands;&lt;/li&gt;
&lt;li&gt;Point-of-contact for the team;&lt;/li&gt;
&lt;li&gt;Create AI awareness in the company;&lt;/li&gt;
&lt;li&gt;Collaborate daily with the Data and DevOps team to create an
end-to-end AI strategy;&lt;/li&gt;
&lt;li&gt;Part of the architecture board;&lt;/li&gt;
&lt;li&gt;GDPR related procedures to ensure compliance in our use cases;&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="AI"></category><category term="AWS"></category><category term="Spark"></category><category term="JupyterHub"></category><category term="AI Roadmap"></category><category term="CI/CD"></category><category term="IaC"></category><category term="PyData stack"></category><category term="3rd party AI partnerships"></category><category term="AI hiring."></category></entry><entry><title>Keras: multi-label classification with ImageDataGenerator</title><link href="/keras-multi-label.html" rel="alternate"></link><published>2019-01-31T00:00:00+01:00</published><updated>2019-01-31T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2019-01-31:/keras-multi-label.html</id><summary type="html">&lt;p&gt;Multi-label classification is a useful functionality of deep neural networks. I recently added this functionality into Keras' &lt;code&gt;ImageDataGenerator&lt;/code&gt; in order to train on data that does not fit into memory. This blog post shows the functionality and runs over a complete example using the VOC2012 dataset.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.com/rod-keras-multi-label"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Multi-label classification is a useful functionality of deep neural networks. I recently added this functionality into Keras' &lt;code&gt;ImageDataGenerator&lt;/code&gt; in order to train on data that does not fit into memory. This blog post shows the functionality and runs over a complete example using the VOC2012 dataset.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gist.github.com/rragundez/ae3a17428bfec631d1b35dcdc6296a85"&gt;Shut up and show me the code!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="city" src="/images/blog/tech/keras-multi-label/city.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;Images taken in the wild are extremely complex. In order to really "understand" an image there are many factors that play a role, like the amount of objects in the image, their dynamics, the relation between frames, the positions of the objects, etc. In order to make AI capable of understanding images in the wild as we do, we must empower AI with all those capabilities. This empowerment may come in different ways, such like multi-class classification, multi-label classification, object detection (bounding boxes), segmentation, pose estimation, optical flow, etc.&lt;/p&gt;
&lt;p&gt;After a small discussion with collaborators of the &lt;code&gt;keras-preprocessing&lt;/code&gt; package we decided to start empowering &lt;code&gt;Keras&lt;/code&gt; users with some of these use cases through the known &lt;code&gt;ImageDataGenerator&lt;/code&gt; class. In particular, thanks to the flexibility of the &lt;code&gt;DataFrameIterator&lt;/code&gt; class added by &lt;a href="https://github.com/Vijayabhaskar96"&gt;@Vijayabhaskar&lt;/a&gt; this should be possible.&lt;/p&gt;
&lt;p&gt;Then, during our last GDD Friday at GoDataDriven I decided to go ahead and start adding the multi-class classification use case.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; The end result was this &lt;a href="https://github.com/keras-team/keras-preprocessing/pull/136"&gt;PR&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But first... What is multi-label classification?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Not to be confused with multi-class classification, in a multi-label problem some observations can be associated with 2 or more classes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This functionality has just been released in PyPI yesterday in the &lt;code&gt;keras-preprocessing&lt;/code&gt; &lt;a href="https://github.com/keras-team/keras-preprocessing/releases/tag/1.0.6"&gt;1.0.6 version.&lt;/a&gt; You can update &lt;code&gt;keras&lt;/code&gt; to have the newest version by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install -U keras
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Multi-class classification in 3 steps&lt;/h2&gt;
&lt;p&gt;In this part will quickly demonstrate the use of &lt;code&gt;ImageDataGenerator&lt;/code&gt; for multi-class classification.&lt;/p&gt;
&lt;h4&gt;1. Image metadata to pandas dataframe&lt;/h4&gt;
&lt;p&gt;Ingest the metadata of the multi-class problem into a pandas dataframe. The labels for each observation should be in a list or tuple. The filenames of the images can be ingested into the dataframe in two ways as shown in the image below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Relative paths: If you only state the filenames of the images you will have to use the &lt;code&gt;directory&lt;/code&gt; argument later on when calling the method &lt;code&gt;flow_from_dataframe&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Absolute paths: In this case you can ditch the &lt;code&gt;directory&lt;/code&gt; argument. &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="dataframe" src="/images/blog/tech/keras-multi-label/dataframe.png"&gt;&lt;/p&gt;
&lt;h4&gt;2. Instantiate &lt;code&gt;DataFrameIterator&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Create the generator of the images batches. This is done by instantiating &lt;code&gt;DataFrameIterator&lt;/code&gt; via the &lt;code&gt;flow_from_dataframe&lt;/code&gt; method of &lt;code&gt;ImageDataGenerator&lt;/code&gt;. Supposing we ingested the filenames as relative paths, the simplest instantantiation would look like this:&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.preprocessing.image&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ImageDataGenerator&lt;/span&gt;

&lt;span class="n"&gt;img_iter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ImageDataGenerator&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flow_from_dataframe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;img_metadata_df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/home/rodrigo/.keras/datasets&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;x_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;y_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;labels&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;class_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;categorical&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The actual logic of creating the batches and handling data augmentation is managed by the &lt;code&gt;DataFrameIterator&lt;/code&gt; class. You can look up other available arguments in &lt;a href="https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/dataframe_iterator.py"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;3. Train the model&lt;/h4&gt;
&lt;p&gt;Train the model using the &lt;code&gt;fit_generator&lt;/code&gt; method.&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_generator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_iter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will yield batches directly from disk, allowing you to train on much more data than it can fit in your memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;That's it!&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Rundown example with VOC2012&lt;/h2&gt;
&lt;p&gt;In this part I'll walk you through a multi-class classification problem step by step. The example will use the &lt;a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/"&gt;VOC2012&lt;/a&gt; dataset which consist of ~17,000 images and 20 classes.&lt;/p&gt;
&lt;p&gt;Just by looking at the images below you can quickly observe that this is a quite diverse and difficult dataset. Perfect! The closer to a real-life example the better.&lt;/p&gt;
&lt;p&gt;&lt;img alt="VOC2012 images" src="/images/blog/tech/keras-multi-label/images.png"&gt;&lt;/p&gt;
&lt;p&gt;Let's start by downloading the data into &lt;code&gt;~/.keras/datasets&lt;/code&gt; from &lt;a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;~/.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;datasets&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;VOC2012&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;Annotations&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000002.&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000003.&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2011_000002.&lt;/span&gt;&lt;span class="n"&gt;xml&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;ImageSets&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;Action&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;Layout&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;Main&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="n"&gt;Segmentation&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;JPEGImages&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000002.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000003.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2011_000002.&lt;/span&gt;&lt;span class="n"&gt;jpg&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;SegmentationClass&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000002.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000003.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="mf"&gt;2011_000003.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="n"&gt;SegmentationObject&lt;/span&gt;
    &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000002.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
    &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="mf"&gt;2010_000003.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
    &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We will use the &lt;code&gt;Annotations&lt;/code&gt; directory to extract the images metadata. Each image can also have repeated associated labels, the argument &lt;code&gt;unique_labels&lt;/code&gt; of the function below regulates if we keep repeated labels. We will not, trust me, the problem is hard enough.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;xml.etree.ElementTree&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;ET&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;xml_to_labels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xml_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;unique_labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ET&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;XML&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xml_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;unique_labels&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;labels_add&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;unique_labels&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt; &lt;span class="c1"&gt;# speeds up method lookup&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;img_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;object&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;subchild&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;child&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;subchild&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;labels_add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;subchild&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;img_filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_labels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annotations_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;unique_labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;annotation_file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;annotations_dir&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterdir&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annotation_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;xml_to_labels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;unique_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;annotations_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;~/.keras/datasets/VOC2012/Annotations&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;img_metadata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_labels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;annotations_dir&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;labels&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After extraction we end up with a dataframe with relative paths as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="VOC2012 images" src="/images/blog/tech/keras-multi-label/dataframe_0.png"&gt;&lt;/p&gt;
&lt;p&gt;The filenames are then relative to&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;images_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;~/.keras/datasets/VOC2012/JPEGImages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;Scan the dataset&lt;/h4&gt;
&lt;p&gt;Let's now have a quick look at how the labels are distributed accross the dataset. These counts can be easily be computed with a &lt;code&gt;Counter&lt;/code&gt; object.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;
&lt;span class="n"&gt;labels_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;lbs&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;img_metadata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;labels&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;lbs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;From here we can easily compute the &lt;code&gt;class_weights&lt;/code&gt; for later use.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;total_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels_count&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;class_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="bp"&gt;cls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;total_count&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="bp"&gt;cls&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;labels_count&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's now plot the labels count.&lt;/p&gt;
&lt;p&gt;&lt;img alt="VOC2012 images" src="/images/blog/tech/keras-multi-label/count_vs_labels.png"&gt;&lt;/p&gt;
&lt;p&gt;No bueno, no bueno at all! There are two types of imbalances in the dataset. Imbalance across different classes, and imbalance between positive and negative examples in some classes. The former imbalance type can produce overfitting to highly represented classes, &lt;code&gt;person&lt;/code&gt; in this case. The latter imbalance type can produce that a class is always flagged as negative i.e. if &lt;code&gt;cow&lt;/code&gt; will always be flagged negative this will yield a 97% accuracy on that class.&lt;/p&gt;
&lt;p&gt;So what can we do about it?... pray. I won't go into detail but one way to counter the imbalances is with a combination of class weights and sample weights.&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Next step is to look at the shape and size distribution across the different images.&lt;/p&gt;
&lt;p&gt;&lt;img alt="VOC2012 images" src="/images/blog/tech/keras-multi-label/images_size.png"&gt;&lt;/p&gt;
&lt;p&gt;As illustrated above, the dataset contains images of different heights and widths. I won't go into detail, but this is not really a problem if at the end of the feature extraction via convolutional layers a &lt;a href="https://keras.io/layers/pooling/"&gt;global pooling layer&lt;/a&gt; is applied. Unfortunately, there is another problem, when using &lt;code&gt;flow_from_dataframe&lt;/code&gt; all images need to be standardized  to the same width and height.&lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7"&gt;7&lt;/a&gt;&lt;/sup&gt; This is specified via the &lt;code&gt;target_size&lt;/code&gt; parameter.&lt;/p&gt;
&lt;p&gt;The lower histogram plot is good to have because it can give us an approximate indication of the maximum batch and &lt;a href="https://keras.io/models/model/#fit_generator"&gt;queue&lt;/a&gt; size our memory can fit when using the generator. In this example, I don't really use the plot though.&lt;/p&gt;
&lt;h4&gt;Training the model&lt;/h4&gt;
&lt;p&gt;First, we need to instantiate the &lt;code&gt;ImageDataGenerator&lt;/code&gt;. I'll do this with a simple setup just normalizing the pixel values. I also included a validation split to use it for validation stats during training after each epoch.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;img_gen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ImageDataGenerator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rescale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;validation_split&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can now create the training and validation &lt;code&gt;DataFrameIterator&lt;/code&gt; by specifying &lt;code&gt;subset&lt;/code&gt; as &lt;code&gt;"training"&lt;/code&gt; or &lt;code&gt;"validation"&lt;/code&gt; respectively. In the case of multi-label classification the &lt;code&gt;class_mode&lt;/code&gt; should be &lt;code&gt;"categorical"&lt;/code&gt; (the default value).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;img_iter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img_gen&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flow_from_dataframe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;img_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;images_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;x_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;y_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;labels&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;class_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;categorical&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;target_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;subset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;training&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;img_iter_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img_gen&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flow_from_dataframe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;img_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;directory&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;images_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;x_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;filename&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;y_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;labels&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;class_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;categorical&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;target_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;subset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;validation&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I will use the &lt;code&gt;ResNet50&lt;/code&gt; pre-trained model in this example. I will replace the last fully connected layers of the network by an output layer with 20 neurons, one for each class.&lt;sup id="fnref:8"&gt;&lt;a class="footnote-ref" href="#fn:8"&gt;8&lt;/a&gt;&lt;/sup&gt; In addition, pay attention to the output activation function, I won't go into detail, but for multi-class classification the probability of each class should be independent, hence the use of the &lt;code&gt;sigmoid&lt;/code&gt; function and not the &lt;code&gt;softmax&lt;/code&gt; function which is used for multi-class problems.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;base_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ResNet50&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;include_top&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;pooling&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;avg&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;layer&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;base_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;layer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;trainable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;

&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sigmoid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;base_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;base_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next we compile the model using &lt;code&gt;"binary_crossentropy"&lt;/code&gt; loss. Why binary cross-entropy and not categorical cross-entropy you ask? well, again, I won't go into detail, but if you use &lt;code&gt;categorical_crossentropy&lt;/code&gt; you are basically not penalizing for false positives (if you are more of a code person than a math person &lt;a href="https://github.com/keras-team/keras/blob/f42d9e0179f11871179bc9ee4e8c138cd016612b/keras/backend/numpy_backend.py#L333"&gt;here you go&lt;/a&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;binary_crossentropy&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Even though I just said that for &lt;code&gt;multi-label&lt;/code&gt; the math dictates sigmoid and binary cross-entropy, there are cases out there where softmax and categorical cross-entropy worked better. &lt;a href="https://research.fb.com/wp-content/uploads/2018/05/exploring_the_limits_of_weakly_supervised_pretraining.pdf?"&gt;Like this one&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Train the model already! Not yet... patience, "&lt;a href="https://translate.google.com/#view=home&amp;amp;op=translate&amp;amp;sl=es&amp;amp;tl=en&amp;amp;text=lento%20pero%20seguro"&gt;lento pero seguro&lt;/a&gt;". Let's talk about metrics for a multi-label problem like this. I hope it is obvious that accuracy is not the way to go. Instead, let's use &lt;code&gt;f1_score&lt;/code&gt;, &lt;code&gt;recall_score&lt;/code&gt; and &lt;code&gt;precision_score&lt;/code&gt;. There is a slight problem though, yes life is a bitch, these metrics were removed from the keras metrics with a good &lt;a href="https://github.com/keras-team/keras/issues/5794"&gt;reason&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The correct way to implement these metrics is to write a callback function that calculates them at the end of each epoch over the validation data. Something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tee&lt;/span&gt;  &lt;span class="c1"&gt;# finally! I found something useful for it&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Callback&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;validation_generator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;validation_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;validation_generator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;validation_generator&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;validation_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;validation_steps&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;validation_generator&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_train_begin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_f1_scores&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_recalls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_precisions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;on_epoch_end&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{}):&lt;/span&gt;
        &lt;span class="c1"&gt;# duplicate generator to make sure y_true and y_pred are calculated from the same observations&lt;/span&gt;
        &lt;span class="n"&gt;gen_1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gen_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tee&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;validation_generator&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;y_true&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gen_1&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;validation_steps&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_generator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gen_2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;validation_steps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;int&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;f1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f1_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;weighted&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;precision&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;precision_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;weighted&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;recall&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recall_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;weighted&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_f1_scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_recalls&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;val_precisions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; - val_f1_score: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.5f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - val_precision: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;precision&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.5f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; - val_recall: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;recall&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.5f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally! we are ready to train the model. FYI: I did little to no effort to optimize the model.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;metrics&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Metrics&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_iter_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;validation_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_generator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;img_iter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;steps_per_epoch&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;class_weight&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;class_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;callbacks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;During the training time you should see validation metrics at the end of each epoch, something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Epoch 10/10
250/250 [==============================] - 261s 1s/step - loss: 5.0277 - val_f1_score: 0.28546 - val_precision: 0.21283 - val_recall: 0.58719
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If your memory melts during training reduce the &lt;code&gt;batch_size&lt;/code&gt;, the &lt;code&gt;target_size&lt;/code&gt; or the &lt;code&gt;max_queue_size&lt;/code&gt; parameters.&lt;/p&gt;
&lt;h4&gt;Post-mortem investigation&lt;/h4&gt;
&lt;p&gt;In the case of a multi-class problem, it is already of big help to plot the confusion matrix, in that way we can identify very clearly where the model is "confusing" one class for another and address the problems directly. Due to the multi-label nature of the problem makes no sense to do the same. Instead a confusion matrix per class can be reviewed.&lt;sup id="fnref:9"&gt;&lt;a class="footnote-ref" href="#fn:9"&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This functionality is only in the development version of &lt;code&gt;scikit-learn&lt;/code&gt;, you can get that version by&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pip install git+https://www.github.com/scikit-learn/scikit-learn.git --upgrade
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;after that you should be able to&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;multilabel_confusion_matrix&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I wrote a wrapper plot function &lt;code&gt;plot_multiclass_confusion_matrix&lt;/code&gt; around &lt;code&gt;multilabel_confusion_matrix&lt;/code&gt;, which you can find in the &lt;a href="https://gist.github.com/rragundez/ae3a17428bfec631d1b35dcdc6296a85"&gt;code&lt;/a&gt;. The output from it looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="VOC2012 images" src="/images/blog/tech/keras-multi-label/confusion_matrices.png"&gt;&lt;/p&gt;
&lt;p&gt;That's it folks! As you can see the model sucks. Your mission, should you choose to accept it...&lt;/p&gt;
&lt;p&gt;&lt;img alt="VOC2012 images" src="/images/blog/tech/keras-multi-label/keep_calm.png"&gt;&lt;/p&gt;
&lt;h2&gt;Adios&lt;/h2&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/blog/tech/ml-pyapp/dog_developer.jpg" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;I hope you found this blog post useful. I went through many concepts rather quickly but I think there are some valuable tips in there.&lt;/p&gt;
&lt;p&gt;You can find the code &lt;a href="https://gist.github.com/rragundez/ae3a17428bfec631d1b35dcdc6296a85"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any other questions just ping me on twitter &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;This was possible before but in a hacky not very API friendly way. You can read about it &lt;a href="https://github.com/keras-team/keras-preprocessing/issues/135"&gt;here&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Tha absolute path format gives you more flexibility as you can build a dataset from several directories.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;In the case of multi-class classification make sure to use &lt;code&gt;class_mode='categorical'&lt;/code&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;For multi-class classification make sure the output layer of the model has a &lt;code&gt;sigmoid&lt;/code&gt; activation function and that the loss function is &lt;code&gt;binary_crossentropy&lt;/code&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;I hope you appreciate the simplicity of it :)&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;Sample weights are not yet implemented in &lt;code&gt;flow_from_dataframe&lt;/code&gt;. I'm waiting on &lt;a href="https://github.com/keras-team/keras-preprocessing/issues/147"&gt;this person&lt;/a&gt;, but if you would like to contribute please do!&amp;#160;&lt;a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;This is a requirement because each batch of images is loaded into a numpy array, therefore each loaded image should have the same array dimensions. Moreover, this will be a great feature to have, a PR would be quite cumbersome though, but go for it!&amp;#160;&lt;a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:8"&gt;
&lt;p&gt;The output layer from &lt;code&gt;ResNet50&lt;/code&gt; if &lt;code&gt;include_top=False&lt;/code&gt; has size 2048, I wouldn't normally followed with a fully connected layer of 20 neurons, but for this example is sufficient to show functionality. Normally I try dropping the output units by 1/3 on every layer or 1/10 if 1/3 is not sufficient.&amp;#160;&lt;a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:9"&gt;
&lt;p&gt;There are several things that a confusion matrix per class will miss but it's a good first approach.&amp;#160;&lt;a class="footnote-backref" href="#fnref:9" title="Jump back to footnote 9 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="deep learning"></category><category term="keras"></category><category term="multi-label"></category></entry><entry><title>Collaborator / committer @ Keras</title><link href="/2019-10-01-keras-preprocessing-collaborator.html" rel="alternate"></link><published>2019-01-15T00:00:00+01:00</published><updated>2019-01-15T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2019-01-15:/2019-10-01-keras-preprocessing-collaborator.html</id><summary type="html">&lt;p&gt;Part of the core development team of the keras preprocessing component of the Keras framework.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Keras is one of the most used Deep Learning frameworks and I am a part of the core development team for the keras preprocessing component of the framework. The responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Participate in the discussions concerning the API.&lt;/li&gt;
&lt;li&gt;Discuss and assess on how to solve issues from the community.&lt;/li&gt;
&lt;li&gt;Solve issues from the community by offering advice or building / coding a solution.&lt;/li&gt;
&lt;li&gt;Review/merge pull requests from contributors.&lt;/li&gt;
&lt;li&gt;Improve the framework by building software features.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="deep learning"></category><category term="keras."></category></entry><entry><title>Big Data Expo 2018: Deep Learning, the Engine of the AI Revolution</title><link href="/big-data-expo-2018.html" rel="alternate"></link><published>2018-10-05T00:00:00+02:00</published><updated>2018-10-05T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-10-05:/big-data-expo-2018.html</id><summary type="html">&lt;p&gt;We all remember the boom of Internet companies in the late 90s, then in the late 2000s mobile companies took center stage and have been dominating ever since. A new type is taken the spotlight, this is the era of AI companies, and like it has been before there are two options: adapt or fade away.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.combig-data-expo-2018"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Two weeks ago I had the opportunity to present a talk about Deep Learning at the &lt;a href="https://www.bigdata-expo.nl/en"&gt;Big Data Expo 2018&lt;/a&gt;. This was a non-technical talk trying to demystify Deep Learning and explain why Deep Learning is driving the AI tech revolution forward.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The title of my talk was &lt;em&gt;Deep Learning, the Engine of the AI Revolution&lt;/em&gt;, and when I say revolution I don't mean just an advance in technology but a technology that changes society.&lt;/p&gt;
&lt;p&gt;This blog post is an attempt to summarize my talk. It's a bit choppy because the talk had a lot of storytelling to link concepts together, but I hope this post still delivers some value for those not present during the talk.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;Tech revolutions&lt;/h2&gt;
&lt;p&gt;In the late 90s/beginning of the 00s we had the internet revolution where companies like Google, Facebook, Youtube, Netflix, and Airbnb started. We also saw some companies adapt to the internet era and release new products such as MSN Messenger, Hotmail, and the iTunes store.&lt;/p&gt;
&lt;p&gt;Then, after the release of the iPhone in 2007, the mobile revolution started. Great wealth was created with users engaging much more with products through mobile applications. Companies like Uber, Tinder, Snapchat, and Instagram were created. Savvy companies from the internet era established dominance by launching mobile applications like Facebook, YouTube, LinkedIn, and Spotify.&lt;/p&gt;
&lt;p&gt;The next wave will be the artificial intelligence revolution. AI is ready to create disruptions in different sectors and markets, in some cases, it has driven new products already, like Google Translate or &lt;a href="https://www.cnet.com/news/lg-puts-the-cute-cloi-at-the-center-of-its-thinking-appliances/"&gt;LG Cloi&lt;/a&gt;. Technology is changing the customer experience because recently AI has been able to take a stab at problems that relate to human interactions, problems related to text, speech, audio, vision, coordination and understanding of the environment.&lt;/p&gt;
&lt;p&gt;Everyone is familiar with the big companies like Google (&lt;a href="https://waymo.com/"&gt;Waymo&lt;/a&gt;) and Tesla, racing to create the perfect self-driving car using AI, and with smart assistants like Alexa, but AI powered by deep learning is also embedded in many other sectors through smaller companies. Take &lt;a href="https://lyrebird.ai/"&gt;Lyrebird&lt;/a&gt; for example, a company based in Canada which can synthesize your voice, or &lt;a href="https://viecure.com/"&gt;Viecure&lt;/a&gt; and &lt;a href="http://www.medicx.ai/"&gt;MedicX.AI&lt;/a&gt; which bring AI to the medical sector, or &lt;a href="https://www.captainai.com/"&gt;CaptainAI&lt;/a&gt; trying to disrupt the boat and ship industry. There are many more examples, but the wave is clearly coming and my question to you is: is your organization prepared to adapt to this new AI era?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/00_revolutions.png"&gt;&lt;/p&gt;
&lt;h2&gt;How does deep learning fit in the artificial intelligence ecosystem?&lt;/h2&gt;
&lt;p&gt;Let's start by looking at the concepts of artificial intelligence, machine learning, and deep learning.&lt;/p&gt;
&lt;p&gt;Artificial intelligence as defined by John McCarthy, who coined the term in 1956, is "the science and engineering of making intelligent machines". Notice that there is no specification on how machines mimic intelligence; it can be done through business rules, brute-force algorithms, symbol manipulation, or statistical learning.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/01_AI.png"&gt;&lt;/p&gt;
&lt;p&gt;Machine learning is a concept within artificial intelligence. Arthur Samuel defined the term machine learning in 1959 as "the ability to learn without being explicitly programmed". The main idea is that data goes into a learning algorithm and out comes a model which is able to perform predictions given new, as-yet-unseen data.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/02_ML.png"&gt;&lt;/p&gt;
&lt;p&gt;Deep learning is a concept within machine learning and artificial intelligence. It uses machine learning algorithms inspired by the human brain, those containing the concepts of neuron or synapses.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/03_DL.png"&gt;&lt;/p&gt;
&lt;p&gt;An example of artificial intelligence but not machine learning is a &lt;a href="https://thetax.nl"&gt;tax calculator&lt;/a&gt; for example, which performs a task based on business rules. Another example is the famous &lt;a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)"&gt;Deep Blue&lt;/a&gt; which defeated the chess champion Garry Kasparov in 1996 by using an brute-force algorithm.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/04_AI_examples.png"&gt;&lt;/p&gt;
&lt;p&gt;The old approach to solving spam email which was based on the Naive Bayes technique is an example of machine learning and not deep learning; this I'll call &lt;strong&gt;traditional&lt;/strong&gt; machine learning. In summary, this approach counts the number of times a word appears in a corpus of known spam emails and assigns a probability of being spam if a new email contains this word. Another example of traditional machine learning is applying a model (e.g. Random Forest) to a number of engineered features to make predictions (for example, predicting house prices based on floor area, number of rooms, location, etc.)&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/05_ML_examples.png"&gt;&lt;/p&gt;
&lt;p&gt;A deep learning example is &lt;a href="https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/"&gt;Smart Reply&lt;/a&gt;, which was introduced in Gmail in 2017. Smart Reply is able to understand what is being said in the email and suggest a human-like response which matches the context of the conversation. Another example of deep learning is the identification of the subject in a description or review, or the recent poster boy of deep learning, &lt;a href="https://deepmind.com/research/alphago/"&gt;AlphaGo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/06_DL_examples.png"&gt;&lt;/p&gt;
&lt;h2&gt;Traditional ML vs deep learning&lt;/h2&gt;
&lt;p&gt;Traditional machine learning requires the creation of features. This is normally done by a data scientist in collaboration with a domain expert. These features need to be chosen or hardcoded by a human.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/07_ML_flow.png"&gt;&lt;/p&gt;
&lt;p&gt;On the other hand, deep learning does not require the creation of human-engineered features. The creation of features happens within the learning algorithm itself. One of the advantages of using deep learning is that for use cases where is not easy to create or identify which features to use; the algorithm will figure them out for you. However, one of the drawbacks is that these features will not necessarily be interpretable by humans, therefore making difficult to explain how the model is working and why itis making certain decisions.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/08_ML_flow.png"&gt;&lt;/p&gt;
&lt;p&gt;Do you remember the graph below? With the promise of the power of unstructured data, companies have put a lot of effort and resources into setting state-of-the-art environments and data pipelines. Deep learning is the correct tool to use the full capabilities of unstructured data, if you are using traditional machine learning and creating features on top of unstructured data you are basically turning it into structured, kneecapping the potential value of the unstructured data pipelines. As unstructured data becomes dominant, deep learning is a must in the toolbox.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/09_data_explosion.png"&gt;&lt;/p&gt;
&lt;p&gt;Another advantage of using deep learning models is that, as the amount of data grows, the models keep on learning and are able to capture more complex relations within the data.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/10_data_impact.png"&gt;&lt;/p&gt;
&lt;h2&gt;DL ecosystem&lt;/h2&gt;
&lt;p&gt;Supervised learning is probably the most well-known topic within machine learning and it relates to having a labeled dataset to train on. Semi-supervised learning as the name indicates relates to the situation when we have only part of our dataset labeled. Unsupervised learning is then when the complete dataset has no labels, and most of the time the task is not so much to predict something but to find relations in our data by modeling the probability distribution of the data.&lt;/p&gt;
&lt;p&gt;Transfer learning, in my opinion, is one of the most useful types of techniques for a common project or business. Transfer learning consists of solving a problem and using the knowledge acquired to solve a different problem. These problems can differ on the dataset, for example, training a model to solve a problem with an abundant public dataset and then solving the same problem but with a smaller dataset which belongs to your use case. It can also be the same dataset but two different tasks, and instead of solving the tasks separately the algorithm uses the knowledge from solving one into the other. Transfer learning, in essence, gives a head start to solve a problem.&lt;/p&gt;
&lt;p&gt;Deep reinforcement learning is a very particular type of technique. It consists of learning a task by trying it many times and learning from failed and successful trials. The approach is similar to how a child learns to drive a bike, the exact instructions are so complex that the only way to learn is to try it. The use cases for deep reinforcement learning require simulators most of the time since it is costly to perform many failed trails.&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt; I personally know of only a few actual business cases for deep reinforcement learning, but it is a very hot topic at the moment and certainly state-of-the-art.&lt;/p&gt;
&lt;p&gt;Meta learning, also known as "learning to learn", studies a human's ability to learn new tasks. This is a concept closely related to the holy grail of AI: artificial general intelligence (AGI). Meta learning tries to develop models that achieve intelligence across many different problem domains.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/11_DL_ecosystem.png"&gt;&lt;/p&gt;
&lt;p&gt;Within deep learning there are already many tools available, some of them developed for a specific type of data or a specific use case. The image below illustrates a few, but there are many more and their number is growing. There is the need for deep learning experts that know which tools fit your use case and to know how to tune them to achieve their peak performance.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/13_DL_tools.png"&gt;&lt;/p&gt;
&lt;p&gt;The business cases are currently driven mostly by supervised learning, with transfer learning becoming very important for companies without the resources and technical expertise of the tech giants. Even though the figure below was presented by &lt;a href="https://en.wikipedia.org/wiki/Andrew_Ng"&gt;Andrew Ng&lt;/a&gt; in 2016, it still gives a clear picture of where artificial intelligence stands in industry at the moment.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/12_DL_impact.png"&gt;&lt;/p&gt;
&lt;h2&gt;Just start&lt;/h2&gt;
&lt;p&gt;It is said that to start a deep learning project you need a huge amount of data...this is not necessarily true! If you have an idea for an AI company or project remember that you don't need to hit a homerun at the start. There is a positive feedback loop embedded in any AI project development. For example, with the use of transfer learning, you can already develop a minimum viable product with a small quantity of data, and as your idea gets adopted and user data flows in, you can make an increasingly better model.&lt;/p&gt;
&lt;p&gt;A good example of this is &lt;a href="http://www.bluerivertechnology.com/"&gt;Blue River&lt;/a&gt;, which started training models using pictures they were taking from their smartphones. Blue River was recently &lt;a href="http://fortune.com/2017/09/06/john-deere-blue-river-acquisition/"&gt;sold for 300 million to John Deer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/14_start_flow.png"&gt;&lt;/p&gt;
&lt;h2&gt;The competition for AI dominance&lt;/h2&gt;
&lt;p&gt;Finally, I want to point out there is a war out there, with many of the leading countries heavily investing in AI research centers or AI entrepreneurship, boosting the AI industry in their countries but also trying to retain AI and deep learning talent. I personally live in The Netherlands and I'm sometimes disappointed with the country's lack of vision for an AI-based future. I talk to AI startups here with great ideas which do so much with so little resources, and when I go to San Francisco and see the huge difference in investment it is obvious to me who will end on top. I encourage government, venture capitalists, companies and investors from The Netherlands to take a serious view on the AI situation around the globe.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/big-data-expo-2018/15_goverments.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.slideshare.net/RicardoAgundez/deep-learning-the-engine-of-the-ai-revolution-118298353"&gt;Find the complete slides in here.&lt;/a&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Big Data Expo is a two-day conference in The Netherlands running for several years with an attendance of around 5000 visitors, and best of all it is free! I would say that the conference is business-oriented, with a focus on use cases, inspirational talks and the future for Big Data and AI in business.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="https://www.slideshare.net/RicardoAgundez/deep-learning-the-engine-of-the-ai-revolution-118298353"&gt;Find the slides in here&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Great efforts are currently being made to solve this problem. If you're interested, search for the topic "distillation of deep learning" models.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Think of self-driving cars, you don't want to crash a car with every failed trial!&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="deep learning"></category></entry><entry><title>Data Lead @ Schiphol Royal Group</title><link href="/2018-10-01-data-scientist-schiphol-group.html" rel="alternate"></link><published>2018-10-01T00:00:00+02:00</published><updated>2018-10-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-10-01:/2018-10-01-data-scientist-schiphol-group.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as the data lead for Schiphol Royal Group.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Schiphol group manages the Schiphol airport in Amsterdam. I am the technical lead of the Data Science and Engineering Lab which consist of 20 people. Some of my responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solve technical impediments hands-on or via discussions.&lt;/li&gt;
&lt;li&gt;Establish best practices in the team, technical and nontechnical.&lt;/li&gt;
&lt;li&gt;Make decisions regarding the team’s roadmap.&lt;/li&gt;
&lt;li&gt;Together with the business perform technical assessment.&lt;/li&gt;
&lt;li&gt;Lead technical hiring efforts and interviews.&lt;/li&gt;
&lt;li&gt;Review pull requests sporadically to share knowledge.&lt;/li&gt;
&lt;li&gt;Intervene in projects whenever is required.&lt;/li&gt;
&lt;li&gt;Technical advice at the beginning and during each project.&lt;/li&gt;
&lt;li&gt;Decisions about the data lake and advanced analytics platform.&lt;/li&gt;
&lt;li&gt;Technical exposure of the team to the organization.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="deep learning"></category><category term="spark"></category><category term="pandas"></category><category term="git"></category><category term="numpy"></category><category term="python"></category><category term="azure"></category><category term="databricks"></category><category term="keras"></category><category term="tensorflow"></category></entry><entry><title>Big Data Expo</title><link href="/2018-09-12-big-data-expo.html" rel="alternate"></link><published>2018-09-12T00:00:00+02:00</published><updated>2018-09-12T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-09-12:/2018-09-12-big-data-expo.html</id><summary type="html">&lt;p&gt;Presented deep learning, the engine of the AI revolution.&lt;/p&gt;</summary><content type="html">&lt;p&gt;https://www.bigdata-expo.nl/en/program/deep-learning-engine-ai-revolution&lt;/p&gt;
&lt;p&gt;DEEP LEARNING, THE ENGINE OF THE AI REVOLUTION&lt;/p&gt;
&lt;p&gt;We all remember the boom of Internet companies in the late 90s, then in the late 2000s mobile companies took center stage and have been dominating ever since. A new type is taken the spotlight, this is the era of AI companies, and like it has been before there are two options: adapt or fade away.&lt;/p&gt;
&lt;p&gt;In order to adapt is very important to understand the basic concepts that underpinned Artificial Intelligence and grasp how Deep Learning became the catalyzer of the AI tech revolution.
I’ll take you through a series of explanations with a historical overview of Deep Learning, and shine some light over question like: what’s the difference with classical Machine Learning? What can it do? What can’t it do? Why should my business care?
I’ll give you concrete examples of revolutionary AI that have converge into products in the areas of  health care, drug discovery, Fin Tech, medicine, supply chain, marketing, recruiting, customer experience and e-commerce.&lt;/p&gt;
&lt;p&gt;Finally, I’ll communicate my opinion on how the development of an AI feature, AI application or AI business should flow and give my advice on how you create something of value under the shadow of the AI giants like Google, Microsoft, Apple etc.&lt;/p&gt;</content><category term="talk"></category><category term="deep learning"></category><category term="artificial intellegence"></category></entry><entry><title>Code breakfast transfer learning</title><link href="/2018-06-28-code-breakfast-transfer-learning.html" rel="alternate"></link><published>2018-06-28T00:00:00+02:00</published><updated>2018-06-28T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-06-28:/2018-06-28-code-breakfast-transfer-learning.html</id><summary type="html">&lt;p&gt;Gave a free 3 hour workshop about transfer learning.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="python"></category><category term="deep learning"></category><category term="transfer learning"></category><category term="keras"></category></entry><entry><title>Spark Summit + AI 2018</title><link href="/spark-summit-ai-2018.html" rel="alternate"></link><published>2018-06-07T00:00:00+02:00</published><updated>2018-06-07T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-06-07:/spark-summit-ai-2018.html</id><summary type="html">&lt;p&gt;This week I was at the Spark+AI Summit 2018 conference in San Francisco. This post is a summary of my experience and highlights of the talks I attended.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.com/rod-spark-summit-ai-2018"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Last Tuesday and Wednesday &lt;a href="https://godatadriven.com/players/ivo-everts"&gt;Ivo Everts&lt;/a&gt; and I attended the Spark+AI Summit 2018 conference in San Francisco. Ivo gave a presentation about &lt;a href="https://databricks.com/session/predictive-maintenance-at-the-dutch-railways"&gt;Predictive Maintenance at the Dutch Railways&lt;/a&gt; and I presented the AI case GDD implemented at Royal FloraHolland &lt;a href="https://databricks.com/session/operation-tulip-using-deep-learning-models-to-automate-auction-processes"&gt;Operation Tulip: Using Deep Learning Models to Automate Auction Processes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Spark+AI Summit" src="images/blog/tech/spark-summit-ai-2018/keynotes.jpg"&gt;&lt;/p&gt;
&lt;p&gt;As a data scientist, I really appreciated that there was a data science track, a deep learning track, and an AI track. Initially, expected to be mostly engineering, but as you will see below, there was plenty of good data science around.&lt;/p&gt;
&lt;p&gt;Here are the highlights of the talks I attended each day. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Note: for those non-technical readers I list some non-tech talks.&lt;/p&gt;
&lt;h1&gt;Day 1&lt;/h1&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/databricks-keynote-2"&gt;Project Hydrogen: Unifying State-of-the-art AI and Big Data in Apache Spark&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Reynold Xin (Co-founder and Chief Architect @ Databricks)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Databricks unveiled project Hydrogen, which aims to solve the fact that distributed ETL Spark jobs don't play well together with deep learning frameworks. As Databricks Chief Architect Reynold Xin says, there's a fundamental incompatibility between the Spark scheduler and the way distributed machine learning frameworks work. &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; Project Hydrogen introduces &lt;a href="https://en.wikipedia.org/wiki/Gang_scheduling"&gt;gang scheduling&lt;/a&gt; which makes possible to have a single framework for ETL data pipelines and deep learning models. In addition, it aims to provide hardware awareness at the task level such that the ETL data pipeline runs in commodity CPU but the deep learning model runs in GPUs for example.&lt;/p&gt;
&lt;p&gt;&lt;img alt="project hydrogen" src="images/blog/tech/spark-summit-ai-2018/project_hydrogen.png"&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/unifying-data-and-ai-for-better-data-products"&gt;Infrastructure for the Complete ML Lifecycle&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Matei Zaharia (Co-founder and CTO @ Databricks &amp;amp; creator of Spark)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This was quite an exciting keynote talk. CTO Matei Zaharia, unveiled and demoed the new open source project &lt;a href="https://github.com/databricks/mlflow"&gt;mlflow&lt;/a&gt;. Mlflow aims to help data scientists track experiments, deploy models and best of all it supports a vast variety of machine learning tools. You can read more in the &lt;a href="https://databricks.com/blog/2018/06/05/introducing-mlflow-an-open-source-machine-learning-platform.html"&gt;blog post&lt;/a&gt; from Matei this week.&lt;/p&gt;
&lt;p&gt;&lt;img alt="mlflow" src="images/blog/tech/spark-summit-ai-2018/mlflow.png"&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/keynote-from-dawn-song"&gt;The Future of AI and Security&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Dawn Song (Professor @ UC Berkeley)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Professor Dawn Song talked about three vulnerabilities of AI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Attacks to AI models&lt;/li&gt;
&lt;li&gt;Misuse of AI&lt;/li&gt;
&lt;li&gt;Data leaks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;She gave nice examples of the three and demonstrated adversarial attacks in real life like the image and video shows.
&lt;img alt="adversarial" src="images/blog/tech/spark-summit-ai-2018/adversarial.jpg"&gt;&lt;/p&gt;
&lt;video width="100%" controls&gt;
  &lt;source src="images/blog/tech/spark-summit-ai-2018/adversarial.mp4" type="video/mp4"&gt;
Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;She then talked about how to resolve some of the open questions and how we can move forward while having these 3 aspects into account.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/time-series-forecasting-using-recurrent-neural-network-and-vector-autoregressive-model-when-and-how"&gt;Time Series Forecasting Using Recurrent Neural Network and Vector Autoregressive Model: When and How&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Jeffrey Yau (Chief Data Scientist @ AllianceBernstein)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Jeffrey's talk was of great value for many Data Scientist that deal with time series. He started explaining the difference from univariate vs multivariate analysis in the dynamics of time series, followed by a quick explanation of why is better to use vector autoregressive models instead of ARIMA models. He included two examples and showed how to actually do it.&lt;/p&gt;
&lt;p&gt;&lt;img alt="VAR" src="images/blog/tech/spark-summit-ai-2018/var.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Then he showed how &lt;a href="https://github.com/twosigma/flint"&gt;Flint&lt;/a&gt; (a time series library for Spark) can be used to preserve the natural order of time-series data when using Spark. He then showed how you can mix Spark and &lt;a href="http://www.statsmodels.org/dev/tsa.html"&gt;StatsModel time series module&lt;/a&gt; to tunned hyperparameters.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/blog/tech/spark-summit-ai-2018/flint.jpg" width="50%" align="left" height="250"&gt;
&lt;img src="images/blog/tech/spark-summit-ai-2018/hyperparameters.jpg" width="50%" align="right" height="250"&gt;&lt;/p&gt;
&lt;p&gt;He then finalized by introducing LSTMS using Keras and making a comparison with a many-to-many model vs VARs models with a prediction of 16 steps ahead.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/graph-representation-learning-to-prevent-payment-collusion-fraud"&gt;Graph Representation Learning to Prevent Payment Collusion Fraud aud Prevention in Paypal&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Venkatesh Ramanathan (Data Scientist @ PayPal)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This talk was actually pretty cool, the use case was to catch a type of fraud transaction that involves several people, from the seller and buyer side. The talk started by explaining how to map the transactions to a graph-based representation of sellers and buyers. Then he proposed several solutions to detect the fraud, for example, he explained how to use &lt;a href="https://snap.stanford.edu/node2vec/"&gt;node2vec&lt;/a&gt; to find a vector representation for the nodes in the graph and then use those representations in different ML models. He also touched in more advanced algorithms where a temporal component in the graph was introduced and touched into &lt;a href="https://tkipf.github.io/graph-convolutional-networks/"&gt;graph convolutions&lt;/a&gt; as well.&lt;/p&gt;
&lt;h1&gt;Day 2&lt;/h1&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/keynote-from-michael-i-jordan"&gt;ML Meets Economics: New Perspectives and Challenges&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Michael I. Jordan (Professor @  UC Berkeley)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I actually like these type of talks a lot, where AI and especially Deep Learning gets put in a much broader and impactful perspective. Professor Jordan gave very interesting points of how new economic markets can arise from AI if we change our approach to its monetization. He gave a clear example with the music industry among others and provided a list of topics he believes AI practitioners should follow when creating AI systems. He also heavily criticized the current way of AI development.&lt;/p&gt;
&lt;p&gt;&lt;img alt="AI Economics" src="images/blog/tech/spark-summit-ai-2018/ai_economics.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I didn't really agree with several of his points of view but it is always extremely beneficial to hear both sides and rock the boat a little bit.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/fireside-chat-with-marc-andreessen-and-ali-ghodsi"&gt;Fireside Chat with Marc Andreessen and Ali Ghodsi&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Marc Andreessen (Co-founder and partner @ Andreessen Horowitz), Ali Ghodsi (CEO @ Databricks)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This was a sitdown where the Ali sort of interviews Marc (an influential venture capitalist). It's the perfect talk to hear during getting ready in the morning or on your way to work. They touched a bit on the history of tech companies and how company pitches have evolved with the rising of AI. Also, Marc gave some helpful pointers to startups on what is a venture capitalist looking for. A particular discussion that stuck was if AI is a truly revolutionary technology or just an add-on feature?&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/keynote-from-tesla"&gt;Building the Software 2.0 Stack&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Andrej Karpathy (Director of AI @ Tesla)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I really liked this one, Andrej encapsulated in a concept what we all have experienced after productionazing several machine learning models. He talked about Software 2.0, this concept basically tells us that the programming in AI is now being done by labelers. What we as data scientist do is just choose a big chunk of the solution space and the data then finds the best program for our case in that space using the data.&lt;/p&gt;
&lt;p&gt;&lt;img alt="software2" src="images/blog/tech/spark-summit-ai-2018/software2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Given that belief, he mentioned how in Tesla he has been spending most of this time making sure that the dataset labels are of very high quality. He gave some funny examples of extremely rare data he has come across and reiterated the importance of having a robust and quality labeling system.&lt;/p&gt;
&lt;p&gt;&lt;img alt="labeling flow" src="images/blog/tech/spark-summit-ai-2018/labeling.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I really liked how genuine his comments were and to see that even at Tesla they have these sort of "mortal" issues that I also face.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/deep-learning-for-recommender-systems"&gt;Deep Learning for recommender systems&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Nick Pentreath (Principal Engineer @ IBM)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Together with the time-series talk the most beneficial for a data scientist. The talk from Nick was very well structured and explained. He started from the basic methods like item-item and matrix factorization which are based on feature and explicit interactions or events. He then set the landscape of the current most common case which involves explicit, implicit, social and intent events. He then addressed the cold start problem and explained why the standard/old collaborative filtering models break down with the current need of applications.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/blog/tech/spark-summit-ai-2018/implicit.jpg" width="50%" align="left" height="250"&gt;
&lt;img src="images/blog/tech/spark-summit-ai-2018/cold_start.jpg" width="50%" align="right" height="250"&gt;&lt;/p&gt;
&lt;p&gt;Then deep learning approaches were covered and explained how implicit events can be used in the loss function of a neural network. Then he followed by showing the state-of-the-art deep learning implementations like &lt;a href="https://arxiv.org/abs/1703.04247"&gt;DeepFM&lt;/a&gt;.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="images/blog/tech/spark-summit-ai-2018/mf_dl.jpg" width="50%" align="left" height="250"&gt;
&lt;img src="images/blog/tech/spark-summit-ai-2018/dl_rec.jpg" width="50%" align="right" height="250"&gt;&lt;/p&gt;
&lt;p&gt;The next part was even sort of new to me, he added session-based recommendations plus the content discussed before by using recurrent neural networks on top of the networks before.&lt;/p&gt;
&lt;p&gt;I was happily relieved that I was up to date with most of the state-of-the-art deep learning applications to recommendation systems, but also learned something new after a chat with Nick and a data scientist from Nike dealing with the same problems.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://databricks.com/session/nandeska-say-what-learning-visualizing-and-understanding-multilingual-word-embeddings"&gt;Nandeska? Say What? Learning, Visualizing, and Understanding Multilingual Word Embeddings&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;sup style="top:-1.75em;"&gt;Ali Zaidi (Data Scientist @ Microsoft)&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This talked discussed how to find similar embedding spaces for words with the same meaning regardless of the language, pretty cool stuff. Ali started by noticing that big datasets for domain-specific NLP are quite scarce, so he shared some of them.&lt;/p&gt;
&lt;p&gt;&lt;img alt="NLP Datasets" src="images/blog/tech/spark-summit-ai-2018/nlp_datasets.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Ali then showcased how to learn Word2Vec embeddings at scale with Spark via the &lt;a href="https://docs.microsoft.com/en-us/python/api/overview/azure-machine-learning/textanalytics?view=azure-ml-py-latest"&gt;Azure text analytics package&lt;/a&gt; (tatk). Then he moved on to explain how by calculating the embeddings individually for each language and then throwing them into a domain adaptation using an adversarial objective you can achieve the desired objective. He showed this for Spanish and Russian.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/blog/tech/spark-summit-ai-2018/transfer_embeddings.jpg" width="50%" align="left" height="250"&gt;
&lt;img src="images/blog/tech/spark-summit-ai-2018/russian_emb.jpg" width="50%" align="right" height="250"&gt;&lt;/p&gt;
&lt;p&gt;I don't know how well did the algorithm worked for most of the words in general but the approach and little sample result shown was quite nice.&lt;/p&gt;
&lt;h2&gt;Adiós&lt;/h2&gt;
&lt;p&gt;In conclusion I was happy with the content of the conference and will recommended to data scientist to take a look next year, also the network I made during discussing is priceless.&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;It was also fun to talk at the conference, I left with a good feeling and was able to deliver some good jokes 😉.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/blog/tech/spark-summit-ai-2018/ivo.jpg" width="50%" align="left" height="225"&gt;
&lt;img src="images/blog/tech/spark-summit-ai-2018/rod.jpeg" width="50%" align="right" height="225"&gt;&lt;/p&gt;
&lt;p&gt;But of to be honest the best of everything was the place we found with authentic Mexican food! I almost cried of the excitement... they even had &lt;a href="https://www.culinaryhill.com/agua-de-horchata-rice-water/"&gt;agua de horchata&lt;/a&gt; 😂&lt;/p&gt;
&lt;p&gt;&lt;img alt="Mexican food" src="images/blog/tech/spark-summit-ai-2018/mexican_food.png"&gt;&lt;/p&gt;
&lt;p&gt;As always I'm happy to discuss and answer any further questions about the conference or other things, just ping me on twitter &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt; or LinkedIn.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;The slides and presentations haven't been uploaded yet. I'll update the links once they are released.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Spark divides jobs into independent tasks (embarrassingly parallel), this differs from how distributed machine learning frameworks work, which sometimes use &lt;a href="https://en.wikipedia.org/wiki/Message_Passing_Interface"&gt;MPI&lt;/a&gt; or custom &lt;a href="https://en.wikipedia.org/wiki/Remote_procedure_call"&gt;RPCs&lt;/a&gt; for doing communication.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;I would recommend you to first start with the LightFM implementation described &lt;a href="https://arxiv.org/abs/1507.08439"&gt;here&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;As a side note, in the talks of the big companies I saw a LOT of tensorflow inside Spark. It made me wish that NL companies would have that much volume of data.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="spark"></category><category term="time-series"></category><category term="recommendation systems"></category><category term="fraud detection"></category></entry><entry><title>Spark + AI Summit</title><link href="/2018-06-06-spark-ai-summit.html" rel="alternate"></link><published>2018-06-06T00:00:00+02:00</published><updated>2018-06-06T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-06-06:/2018-06-06-spark-ai-summit.html</id><summary type="html">&lt;p&gt;Presented Operation Tulip: Using Deep Learning Models to Automate Auction Processes.&lt;/p&gt;</summary><content type="html">&lt;p&gt;https://databricks.com/session/operation-tulip-using-deep-learning-models-to-automate-auction-processes&lt;/p&gt;
&lt;p&gt;Operation Tulip: Using Deep Learning Models to Automate Auction Processes
We are using Deep Learning models to help Royal Flora Holland automate their auction processes. With over 100,000 transactions per day and 400,000 different types of flowers and plants, Royal Flora Holland is the biggest horticulture marketplace and knowledge center in the world. An essential part of their process is having the correct photographs of the flower or plants uploaded by suppliers. These photos are uploaded daily and could have requirements.&lt;/p&gt;
&lt;p&gt;For example, some images require a ruler to be visible or a tray to be present. Manual inspection is practically impossible. Using Keras with a Tensorflow backend we implemented a Deep Neural Network (DNN) using transfer learning for each screening criteria. We also apply heuristics and business rules. The goal is to give real-time feedback at upload time, this challenged us to run multiple deep learning models in real-enough-time.&lt;/p&gt;
&lt;p&gt;During the journey of building the Image Detection system we have used specific implementations that can be insightful and helpful to the audience. For example, our models are not only trained in parallel but transfer learning allows us to engineer a single 1st component for all models and then having the flow distribute over each of the DNN (~90% of the work is shared among the DNNs). Our models achieve above 95% accuracy and because of the component-like architecture it’s very flexible.&lt;/p&gt;
&lt;p&gt;Session hashtag: #AISAIS11&lt;/p&gt;</content><category term="talk"></category><category term="deep learning"></category><category term="transfer learning"></category><category term="classification"></category><category term="keras"></category><category term="tensorflow"></category></entry><entry><title>Unsupervised and Reinforcement Learning</title><link href="/2018-06-02-unsupervised-and-reinforcement-learning.html" rel="alternate"></link><published>2018-06-02T00:00:00+02:00</published><updated>2018-06-02T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-06-02:/2018-06-02-unsupervised-and-reinforcement-learning.html</id><summary type="html">&lt;p&gt;Took a 2 day course of Unsupervised and Reinforcement Learning in San Francisco.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="python"></category><category term="keras"></category><category term="tensorflow, openai, deep learning"></category><category term="reinforcement learning"></category><category term="unsupervised learning"></category></entry><entry><title>Dutch Data Science Week</title><link href="/2018-05-29-dutch-data-science-week.html" rel="alternate"></link><published>2018-05-29T00:00:00+02:00</published><updated>2018-05-29T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-05-29:/2018-05-29-dutch-data-science-week.html</id><summary type="html">&lt;p&gt;Gave an advanced deep learning workshop with a focus on RNNs and LSTMs.&lt;/p&gt;</summary><content type="html">&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/msUqbcWz6n0?rel=0&amp;amp;showinfo=0&amp;amp;start=10" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;https://www.eventbrite.nl/e/tickets-training-special-deep-learning-dutch-data-science-week-2018-44832464107#&lt;/p&gt;
&lt;p&gt;Deep learning Special with Python, Tensorflow and Keras with a focus on Recurrent Neural Networks and LSTMs.
Every theory part is complemented by a hands-on session, the goal is that you become familiar with the theory but also learn the how to apply the theory in practice with several exercises.&lt;/p&gt;
&lt;p&gt;Curriculum
Deep Learning basics (Theory)&lt;/p&gt;
&lt;p&gt;Keras API with image classification (Hands-on)&lt;/p&gt;
&lt;p&gt;Neural networks in practice (Theory)&lt;/p&gt;
&lt;p&gt;Predicting bank term deposits (Hands-on)&lt;/p&gt;
&lt;p&gt;Recurrent Neural Networks (Theory)&lt;/p&gt;
&lt;p&gt;Forecasting airline passengers with RNNs (Hands-on)&lt;/p&gt;
&lt;p&gt;Long short-term memory (Theory)&lt;/p&gt;
&lt;p&gt;Human activity recognition with LSTMs (Hands-on)&lt;/p&gt;
&lt;p&gt;NLP sentiment classification with LSTMs (Hands-on)&lt;/p&gt;
&lt;p&gt;Introduction to Gated recurrent units (Theory)&lt;/p&gt;
&lt;p&gt;Q&amp;amp;A&lt;/p&gt;
&lt;p&gt;Some of the things you will learn are:
The Keras API&lt;/p&gt;
&lt;p&gt;Pragmatic best practices when using Deep Learning models&lt;/p&gt;
&lt;p&gt;Recognize cases when Recurrent Neural Networks are useful&lt;/p&gt;
&lt;p&gt;Pre-process time-series data for an RNN or LSTM&lt;/p&gt;
&lt;p&gt;Combine several time-series for a single RNN or LSTM model&lt;/p&gt;
&lt;p&gt;Use many-to-one RNN and LSTM models&lt;/p&gt;
&lt;p&gt;Use many-to-many RNN and LSTM models&lt;/p&gt;
&lt;p&gt;Process text data for an RNN or LSTM model&lt;/p&gt;
&lt;p&gt;Prerequisites
Experience in Python is advised for the hands-on sessions&lt;/p&gt;
&lt;p&gt;Experience with Machine Learning concepts (e.g. regularization, overfitting, feature scaling, hyperparameter optimization)&lt;/p&gt;
&lt;p&gt;Basic familiarity with Deep Learning&lt;/p&gt;
&lt;p&gt;Activities
The course is dynamic with ideas exchanging and open communication. There are also some fun activities based on the course content.&lt;/p&gt;
&lt;p&gt;Instructor
The workshop will be given by Rodrigo Agundez. Data Maverick at GoDataDriven. Rodrigo has been giving training sessions and workshops for several years now, he gave a Deep Learning Tensorflow workshop during the Data Science Summit Europe 2016 in Israel, is one of the current trainers for the Data Science with Python, the time-series lecture and Deep Learning training (GoDataDriven).&lt;/p&gt;
&lt;p&gt;In addition, as a consultant, he has seen many use cases and can help you with specific questions that relate to using Data Science in practice, productizing models, etc.&lt;/p&gt;
&lt;p&gt;TAGS&lt;/p&gt;</content><category term="workshop"></category><category term="deep learning"></category><category term="time-series"></category><category term="nlp"></category><category term="lstm"></category><category term="rnn"></category><category term="cnn"></category></entry><entry><title>PyData Amsterdam</title><link href="/2018-05-26-pydata-amsterdam.html" rel="alternate"></link><published>2018-05-26T00:00:00+02:00</published><updated>2018-05-26T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-05-26:/2018-05-26-pydata-amsterdam.html</id><summary type="html">&lt;p&gt;Gave a deep learning introductory workshop to Keras.&lt;/p&gt;</summary><content type="html">&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/BBIA6Wcu2j4?rel=0&amp;amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;https://pydata.org/amsterdam2018/schedule/presentation/30/&lt;/p&gt;
&lt;p&gt;Hands-on introduction to Deep Learning with Keras and Tensorflow&lt;/p&gt;
&lt;p&gt;Audience level:
Novice
Description
Deep Learning has already conquered areas such as image recognition, NLP, voice recognition, and is a must-know tool for every Data Practitioner. This tutorial for aspiring Deep Learners will consist of a quick blunt Deep Learning overview followed by a hands-on tutorial that will teach you how to get started using Keras and Tesorflow.&lt;/p&gt;
&lt;p&gt;Abstract
Deep Learning has already conquered areas such as image recognition, NLP, voice recognition, and is a must-know tool for every Data Practitioner. This tutorial for aspiring Deep Learners will consist of a quick blunt Deep Learning overview followed by a hands-on tutorial that will teach you how to get started using Keras and Tesorflow.&lt;/p&gt;
&lt;p&gt;This tutorial is for people that
know the fundamentals of machine learning
have a worked with the PyData stack
have no deep learning hands-on experience with Keras
Curriculum
Deep Learning landscape
Deep Learning tools in Python
Blunt review of the Keras API (Hands-on)
Build a deep learning model for an easy image classification dataset (Hands-on)
Play around and optimize deep learning model for a harder dataset (Hands-on)
Prerequisites
Experience with Python and jupyter notebooks
Keras or Tensroflow (version &amp;gt;= 1.4) installed
Note: Some of the material is a repeat of the Code Breakfast Deep Learning session of January 17, 2018&lt;/p&gt;</content><category term="workshop"></category><category term="deep learning"></category><category term="keras"></category><category term="transfer learning"></category><category term="tensorflow"></category></entry><entry><title>Deep learning to Deloitte</title><link href="/2018-05-20-deep-learning-deloitte.html" rel="alternate"></link><published>2018-05-20T00:00:00+02:00</published><updated>2018-05-20T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-05-20:/2018-05-20-deep-learning-deloitte.html</id><summary type="html">&lt;p&gt;Gave a deep learning training to Deloitte with a focus on RNNs.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="deep learning"></category><category term="rnn"></category><category term="lstm"></category></entry><entry><title>Elitist shuffle for recommendation systems</title><link href="/elitist-shuffle.html" rel="alternate"></link><published>2018-05-13T00:00:00+02:00</published><updated>2018-05-13T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-05-13:/elitist-shuffle.html</id><summary type="html">&lt;p&gt;In today's high pace user experience it is expected that new recommended items appear every time the user opens the application, but what to do if your recommendation system runs every hour or every day? I give a solution that you can plug &amp;amp; play without having to re-engineer your recommendation system.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.com/rod-elitist-shuffle"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In today's high pace user experience it is expected that new recommended items appear every time the user opens the application, but what to do if your recommendation system runs every hour or every day? I give a solution that you can plug &amp;amp; play without having to re-engineer your recommendation system.&lt;/p&gt;
&lt;p&gt;&lt;img alt="card shuffling" src="/images/blog/tech/elitist-shuffle/shuffle.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The common practice to update recommended items is to have the recommendation system re-score the available items every period of time &lt;code&gt;T&lt;/code&gt;. This means that for a whole period &lt;code&gt;T&lt;/code&gt;, the end-user faces the same content in the application's entry screen. In today's high pace user experience if &lt;code&gt;T&lt;/code&gt; is even a few hours, let alone a day, the user can get bored of the same content displayed every time it opens the application during the period &lt;code&gt;T&lt;/code&gt;. There can be many ways this scenario can happen but imagine the user opens the application and doesn't like the recommended items and is too lazy or busy to scroll or search for something else. If the user opens the application again some minutes later to find exactly the same content as before this might have a big (negative) impact on the retention for this user.&lt;/p&gt;
&lt;p&gt;An obvious solution to this problem is to shuffle the content in such a way that it remains relevant to the user while new content appears on the screen each time the user re-opens the application.&lt;/p&gt;
&lt;p&gt;Below there are two screen shots from my YouTube account a couple of seconds apart with no interaction, just clicking the refresh button. We can notice several things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Content is still relevant.&lt;/li&gt;
&lt;li&gt;Content is not the same.&lt;/li&gt;
&lt;li&gt;Some content has changed position.&lt;/li&gt;
&lt;li&gt;Some new content has appeared.&lt;/li&gt;
&lt;/ul&gt;
&lt;div&gt;
    &lt;div style="float: left; width: 50%;"&gt;
        &lt;img src="/images/blog/tech/elitist-shuffle/recommendations_0.png" style="width:100%"&gt;
    &lt;/div&gt;
    &lt;div style="float: left; width: 50%;"&gt;
        &lt;img src="/images/blog/tech/elitist-shuffle/recommendations_1.png" style="width:100%"&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;This can be because YouTube re-scores items in a very short time &lt;code&gt;T&lt;/code&gt; or runs an online algorithm.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; What can you do to achieve something similar if your recommendation system has a &lt;code&gt;T&lt;/code&gt; in the order of hours?&lt;/p&gt;
&lt;p&gt;In this blog post, I propose a simple solution based on a non-uniform shuffling algorithm that you can basically plug &amp;amp; play or build on top off.&lt;/p&gt;
&lt;h3&gt;Example scenario&lt;/h3&gt;
&lt;p&gt;Suppose you have 10,000 items in total that can be recommended to your user, you run the recommendation system over all the items and those 10,000 items get ranked in order of relevance of the content.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The application shows 5 items on the entry screen. The first time the user opens the application after the re-scoring process the top 5 ranked items are shown. It is decided that from now on (based on user control groups, investigation, AB testing, etc.) until the next re-scoring process the entry screen should not be the same every time and remain relevant for the user.&lt;/p&gt;
&lt;p&gt;Based on an investigation from the data scientist it turns out that somewhat relevant items appear until item 100.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt; Then the idea is to somehow shuffle those 100 items such that the top 5 items shown are still relevant but not the same.&lt;/p&gt;
&lt;p&gt;In order for the figures of this blog post to be more readable and understandable, I'll use a hypothetical threshold of &lt;strong&gt;20&lt;/strong&gt; items and not 100.&lt;/p&gt;
&lt;h3&gt;Fisher–Yates shuffle / uniform&lt;/h3&gt;
&lt;p&gt;Shuffling in Python is a very common action and can be done using the &lt;code&gt;random&lt;/code&gt; module which contains the &lt;a href="https://github.com/python/cpython/blob/master/Lib/random.py#L286"&gt;&lt;code&gt;shuffle&lt;/code&gt; function&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inspect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getsource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Shuffle list x in place, and return None.&lt;/span&gt;

&lt;span class="sd"&gt;    Optional argument random is a 0-argument function returning a&lt;/span&gt;
&lt;span class="sd"&gt;    random float in [0.0, 1.0); if it is the default None, the&lt;/span&gt;
&lt;span class="sd"&gt;    standard random.random will be used.&lt;/span&gt;

&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;randbelow&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_randbelow&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))):&lt;/span&gt;
            &lt;span class="c1"&gt;# pick an element in x[:i+1] with which to exchange x[i]&lt;/span&gt;
            &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;randbelow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;_int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;reversed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))):&lt;/span&gt;
            &lt;span class="c1"&gt;# pick an element in x[:i+1] with which to exchange x[i]&lt;/span&gt;
            &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This shuffle method uses the optimized &lt;a href="https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle"&gt;Fisher–Yates algorithm&lt;/a&gt; introduced by Richard Durstenfield in 1964 which reduced the running time from $O(n^2)$ to $O(n)$. By default the algorithm produces a uniform shuffle of an array in which every permutation is equally likely. This means that an item has equal probability to end up in any position.&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt; Below you can find an animation of the results of the &lt;code&gt;random.shuffle&lt;/code&gt; default algorithm. I show the initial position of an item in red and the expected probability distribution of landing in any position after &lt;strong&gt;5000&lt;/strong&gt; shuffling simulations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="random uniform shuffle" src="/images/blog/tech/elitist-shuffle/random_uniform_shuffle.gif"&gt;&lt;/p&gt;
&lt;p&gt;This type of shuffle is not beneficial for our purpose as there is the same probability of the least recommended item to appear on top than any other, this is definitely not the way to go since we can end up with very poor recommendations on top.&lt;/p&gt;
&lt;h3&gt;Fisher–Yates shuffle / non-uniform&lt;/h3&gt;
&lt;p&gt;Notice that the &lt;a href="https://github.com/numpy/numpy/blob/d7d5cb3feccc1fc6cf57159e8b9fe0a733968706/numpy/random/mtrand/mtrand.pyx#L4778"&gt;&lt;code&gt;shuffle&lt;/code&gt; function&lt;/a&gt; shown above has the parameter &lt;code&gt;random&lt;/code&gt; which is described in the docstring as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Shuffle list x in place, and return None.&lt;/span&gt;

&lt;span class="sd"&gt;    Optional argument random is a 0-argument function returning a&lt;/span&gt;
&lt;span class="sd"&gt;    random float in [0.0, 1.0); if it is the default None, the&lt;/span&gt;
&lt;span class="sd"&gt;    standard random.random will be used.&lt;/span&gt;

&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you try to &lt;a href="https://eli.thegreenplace.net/2010/05/28/the-intuition-behind-fisher-yates-shuffling/"&gt;understand the Fisher-Yates algorithm&lt;/a&gt; and then look at the source code, you notice that the &lt;code&gt;random&lt;/code&gt; parameter affects the location where intermediate swaps will happen and that the effect of a non-uniform &lt;code&gt;random&lt;/code&gt; distribution parameter is quite difficult to predict. It kept my mind busy for some hours.&lt;/p&gt;
&lt;p&gt;I tried different functions to pass to the &lt;code&gt;random&lt;/code&gt; parameter but they all behaved strange and unexpected in one way or another, for example let's try a &lt;a href="https://en.wikipedia.org/wiki/Beta_distribution"&gt;$\beta$ distribution&lt;/a&gt; such that the first draws are very likely to be swapped with elements at the end (higher probability near 1.0).&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="beta distribution" src="/images/blog/tech/elitist-shuffle/beta_distribution.png"&gt;&lt;/p&gt;
&lt;p&gt;The simulation below uses the $\beta$-distribution as the &lt;code&gt;random&lt;/code&gt; parameter. This approach does allocate higher probabilities towards higher positions for higher initially ranked items, but the distribution is highly non-symmetrical and very different for different initial positions. I find it surprising that at some point the initial position does not have the maximum probability.&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6"&gt;6&lt;/a&gt;&lt;/sup&gt; Also, I find it very hard to explain the relation between the given $\beta$-distribution and the resulting probability distribution . I played with the parameters and other distributions but still noticed strange behavior. This will make it quite difficult to explain the expected impact on the recommended items to the user.&lt;/p&gt;
&lt;p&gt;&lt;img alt="random uniform shuffle" src="/images/blog/tech/elitist-shuffle/random_non_uniform_shuffle.gif"&gt;&lt;/p&gt;
&lt;h3&gt;Elitist shuffle&lt;/h3&gt;
&lt;p&gt;This is actually a simple approach, I shuffle the items by choosing items with a weighted probability (this is the same as sampling from a &lt;a href="https://en.wikipedia.org/wiki/Multinomial_distribution"&gt;multinomial distribution&lt;/a&gt; without replacement). I won't go into the details but the function &lt;a href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.choice.html"&gt;&lt;code&gt;numpy.random.choice&lt;/code&gt;&lt;/a&gt; with the parameter &lt;code&gt;replace=False&lt;/code&gt; does what we want, it is just a matter of choosing the appropriate weight probabilities. In this case I choose to set the weights by transforming the reverse position as &lt;code&gt;np.linspace(1, 0, num=len(items), endpoint=False)&lt;/code&gt;.&lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7"&gt;7&lt;/a&gt;&lt;/sup&gt; Then I introduce a parameter called &lt;code&gt;inequality&lt;/code&gt; as a knob to tune the weight probability difference between positions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inspect&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getsource&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;elitist_shuffle&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;elitist_shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inequality&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Shuffle array with bias over initial ranks&lt;/span&gt;

&lt;span class="sd"&gt;    A higher ranked content has a higher probability to end up higher&lt;/span&gt;
&lt;span class="sd"&gt;    ranked after the shuffle than an initially lower ranked one.&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;        items (numpy.array): Items to be shuffled&lt;/span&gt;
&lt;span class="sd"&gt;        inequality (int/float): how biased you want the shuffle to be.&lt;/span&gt;
&lt;span class="sd"&gt;            A higher value will yield a lower probabilty of a higher initially&lt;/span&gt;
&lt;span class="sd"&gt;            ranked item to end up in a lower ranked position in the&lt;/span&gt;
&lt;span class="sd"&gt;            sequence.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;endpoint&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;inequality&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;ord&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As the simulation below shows, this approach gives a clearer picture of what's going on and it let us tune the algorithm using the &lt;code&gt;inequality&lt;/code&gt; parameter according to the requirements of our application. This is an animation based on &lt;code&gt;5000&lt;/code&gt; simulations with &lt;code&gt;inequality=10&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="elitist shuffle" src="/images/blog/tech/elitist-shuffle/elitist_shuffle.gif"&gt;&lt;/p&gt;
&lt;p&gt;From the animation we notice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The maximum probability remains on the initial position.&lt;/li&gt;
&lt;li&gt;Probability decays monotonically with the distance from the initial position.&lt;/li&gt;
&lt;li&gt;The distribution is non-symmetrical but smoother than the previous example.&lt;/li&gt;
&lt;li&gt;Higher ranked items have a higher chance of being moved from their initial position.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A big win is that the &lt;code&gt;inequality&lt;/code&gt; parameter has a direct understandable impact on the resulting distributions, want higher items to be more probable to remain on top? Increase inequality. In addition, the behavior translates into the desired functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Top content would still be relevant after shuffle.&lt;/li&gt;
&lt;li&gt;Content is not the same.&lt;/li&gt;
&lt;li&gt;Some content has changed position.&lt;/li&gt;
&lt;li&gt;Some new content has appeared.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Drawback&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;elitist_shuffle&lt;/code&gt; function is much slower than &lt;code&gt;np.random.shuffle&lt;/code&gt;, but still fast for a common application. Coming back to the example scenario where the items to shuffle are &lt;strong&gt;100&lt;/strong&gt;, the &lt;code&gt;elitist_shuffle&lt;/code&gt; function takes around &lt;strong&gt;1.8ms&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If this is too slow for you I would recommend to first try &lt;a href="https://numba.pydata.org/"&gt;numba&lt;/a&gt; with the &lt;code&gt;no_python&lt;/code&gt; parameter enabled and then if necessary try a &lt;a href="http://cython.org/"&gt;Cython&lt;/a&gt; implementation.&lt;/p&gt;
&lt;h3&gt;Adiós&lt;/h3&gt;
&lt;p&gt;As final remarks, I advise you to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, discuss with your team if you need a feature like this. There are applications where the user might be expecting to find the same items it saw last time. Perhaps trigger this behavior if more than x seconds have passed.&lt;/li&gt;
&lt;li&gt;Add the recommendation system scores to the calculation of the weight probabilities. This could just be setting the weights to the scores before the exponentiation and $l^1$ normalization 😉.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/blog/tech/elitist-shuffle/dog_developer.jpg" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;As always I'm happy to discuss and answer any questions, just ping me on twitter &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can find the code &lt;a href="https://github.com/rragundez/elitist-shuffle"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Some other user similar to me might have done some actions that affect my recommendations, or simply not clicking on the items affects my own recommendations.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;There can be an exploration-exploitation step after.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;It can also be a dynamic threshold based on the scores from the recommendation system.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;This algorithm is also used by &lt;a href="https://github.com/numpy/numpy/blob/master/numpy/random/mtrand/mtrand.pyx#L4852"&gt;numpy&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;This is what we want since the algorithm first swaps elements from the end (look at &lt;code&gt;reversed&lt;/code&gt; in &lt;a href="https://github.com/python/cpython/blob/master/Lib/random.py#L303"&gt;line 303&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;It is not a matter of increasing the number of simulations. I did that and found the same behavior.&amp;#160;&lt;a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;You might be tempted to use &lt;code&gt;np.arange(len(items), 0, step=-1)&lt;/code&gt; which is not numerically robust for a big &lt;code&gt;inequality&lt;/code&gt; parameter.&amp;#160;&lt;a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="recommendation systems"></category><category term="python"></category><category term="multi-arm bandit"></category></entry><entry><title>How Deep Learning Will Change Customer Experience</title><link href="/dl-customer-experience.html" rel="alternate"></link><published>2018-05-07T00:00:00+02:00</published><updated>2018-05-07T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-05-07:/dl-customer-experience.html</id><summary type="html">&lt;p&gt;Co-author of article written by Ronald van Loon about the impact of Deep Learning on the customer experience&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://www.linkedin.com/pulse/how-deep-learning-change-customer-experience-ronald-van-loon"&gt;I was co-author to this article and was originally published by Ronald van Loon&lt;/a&gt;&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/hcSwC_CBiZI?rel=0&amp;amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;img alt="title image" src="/images/blog/tech/dl-customer-experience/title.png"&gt;&lt;/p&gt;
&lt;p&gt;Deep learning is a sub-category within machine learning and artificial intelligence. It is inspired by and based on the model of the human brain to create artificial neural networks for machines. Deep learning will allow machines and devices to function in some ways as humans do.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.linkedin.com/in/rodrigo-agundez-2b727258/?lipi=urn%3Ali%3Apage%3Ad_flagship3_pulse_read%3BNgl%2FbDfnT6uf6m904VZ%2FoA%3D%3D"&gt;Dr. Rodrigo Agundez&lt;/a&gt; of GoDataDriven is co-author of this article and very enthusiastic about the improvements that deep learning can offer. He’s been involved in the data science and analysis field for some time, and is already working on implementing models for practical applications.&lt;/p&gt;
&lt;p&gt;Rodrigo notes that the new generation of users wants to interact with devices and appliances in a human-like manner. Take the example of Apple’s Siri, which allows for voice command and voice recognition. Communicating with Siri is similar to interacting with a human.&lt;/p&gt;
&lt;p&gt;The user interface for Siri seems simple enough. However, the A.I. algorithms that are designed on the back-end are quite complex.&lt;/p&gt;
&lt;p&gt;Designing this kind of interaction with a machine was not possible a few years ago. System designers now have access to complex deep learning algorithms that makes it possible to integrate such behavior into machines.&lt;/p&gt;
&lt;p&gt;Importance of Deep Learning
Artificial Intelligence will never truly come of age without giving machines the powerful capabilities of deep learning.&lt;/p&gt;
&lt;p&gt;The idea of designing deep learning models can be difficult to grasp for many people. This is because understanding human concepts comes naturally to us. But giving the same ability to machines is a very complex process of design.&lt;/p&gt;
&lt;p&gt;One way to do it is by structuring data in a way that makes it easier to process for machines. Take the word “fat” for instance. If we say to a friend, “This burger has too much fat,” they would understand what we mean and the word would have a negative connotation here. But if we told a friend that “I would love to get fat from this meal any day,” the word would mean something entirely different.&lt;/p&gt;
&lt;p&gt;Creating machines that are capable of understanding minute differences in words embedded in a context may seem like a very small thing, but requires a very large set of data and complex algorithms to execute.&lt;/p&gt;
&lt;p&gt;Difference from Traditional Machine Learning
One way to differentiate between traditional machine learning and deep learning is through the use of features. These are the characteristics of the data that help us differentiate and identify one entity from another.&lt;/p&gt;
&lt;p&gt;To understand features better, take the example of a normal bank transaction. Features of the transaction help us identify the timing of the transaction, the value transferred, names of the parties to the transaction, and other important information.&lt;/p&gt;
&lt;p&gt;In a traditional machine learning model, features have to be designed by humans. In a deep learning model, features are identified by the A.I. itself.&lt;/p&gt;
&lt;p&gt;We can take another example of differences between a cat and a dog. If we showed a person a cat and a dog and asked them to point to the cat, they would immediately identify it. However, if the same person was asked to identify the exact features that differentiate the two, they would have a problem. Both creatures have four legs, a body, a tail, and a head. They appear very similar in terms of features. Humans can distinguish one from the other in an instant. Yet, they would have trouble identifying the features that differentiate any pair of a cat and a dog.&lt;/p&gt;
&lt;p&gt;This is a problem that data scientists and A.I. developers hope to solve with deep learning. Features can be found even in unstructured data with the help of deep learning algorithms.&lt;/p&gt;
&lt;p&gt;Benefit from Deep Learning for the Customer Experience
Rodrigo states that deep learning models are superior at certain A.I. characteristics than any traditional machine learning models, as the models has shown its effectiveness. This can be traced back to 2012 where in a known online image recognition challenge, a deep learning algorithm proved to be twice as effective as any other algorithm before.&lt;/p&gt;
&lt;p&gt;If an A.I. model reaches an accuracy of 50%, the device would not be very practical for use. Take the example of automobiles. A person would not trust getting in a car where brakes work 50% of the time.&lt;/p&gt;
&lt;p&gt;However, if the accuracy of an A.I. system reaches values around 95%, it would be much more reliable and robust for practical use. Rodrigo believes that this level of accuracy for human-like tasks can only be achieved with deep learning algorithms.&lt;/p&gt;
&lt;p&gt;Deep learning can be applied to speech recognition to improve customer experience. Speech recognition technology has been around for quite some time, but it didn’t cross the accuracy boundary to become a marketable product until the introduction of deep learning models.&lt;/p&gt;
&lt;p&gt;Home automation systems and devices work through voice command. This is an area where deep learning can significantly improve customer experience.&lt;/p&gt;
&lt;p&gt;Royal FloraHolland Case
Royal FloraHolland is the biggest horticulture marketplace and knowledge center in the world. An essential part of their process is having the correct photographs of the flower or plants uploaded by suppliers. These photos need to have a plant, some images require a ruler to be visible or a tray to be present.&lt;/p&gt;
&lt;p&gt;The task of sorting through all these photographs manually and quickly is basically impossible, therefore it was decided to implement A.I. for the process.&lt;/p&gt;
&lt;p&gt;GoDataDriven designed a system with deep learning algorithms to automate the checking of the images. The system can accurately identify and sort pictures taken from different angles and devices.&lt;/p&gt;
&lt;p&gt;The system removed the need for manual human review and completely automated the process for the company.&lt;/p&gt;
&lt;p&gt;University Medical Centrum Groningen (UMCG)
Deep learning algorithms were developed for UMCG with collaboration from GoDataDriven, Google and Siemens. This involved the use of MRI data in a 4D format (volume + time). Using deep learning models, the team calculated the heart ventricles volumes evolution over time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="UMCG case" src="/images/blog/tech/dl-customer-experience/umcg.png"&gt;&lt;/p&gt;
&lt;p&gt;One of the project goals is to assist in the decision making regarding pace makers and treatments. For example, it could take the heart cycle and volumes into consideration for prognosis and heart failure.&lt;/p&gt;
&lt;p&gt;More than 400 images were taken per patient for different hearth depths across time. The team at GoDataDriven and Siemens developed multiple models, including binary and multi-class segmentation.&lt;/p&gt;
&lt;p&gt;&lt;img alt="UMCG case" src="/images/blog/tech/dl-customer-experience/umcg2.png"&gt;&lt;/p&gt;
&lt;p&gt;The model based on the U-Net deep learning architecture takes the MRI scan as input and outputs the corresponding volumes.&lt;/p&gt;
&lt;p&gt;Traditionally, the process is done manually by looking at the scans and interpreting the results through hand-drawn diagrams.&lt;/p&gt;
&lt;p&gt;Future of Deep Learning
Deep learning provides a way for companies to develop life-long learning modules. When more complex and richer algorithms are developed on top of pre-existing ones, companies will be able to achieve incremental growth.&lt;/p&gt;
&lt;p&gt;Rodrigo believes that deep learning has a bright future because of its open source community and accessible platforms. Major corporations such as Apple which had built their systems on secrecy are finally coming around to the open-source model.&lt;/p&gt;
&lt;p&gt;The main reason they are switching now is because they find deep learning talent acquisition more difficult in comparison with open source companies, such as Google's Deep Mind for example. A company could have developed the most amazing and efficient deep learning system but if they don't publish their research and share the knowledge online, talented data scientists and deep learning practitioners will not apply to this companies.&lt;/p&gt;
&lt;p&gt;Currently deep learning teams like Google Brain, Google Deep Mind and companies like Facebook and Baidu find it much easier to hire talented deep learning practitioners. They continuously publish research and open source the related implementations, such that the deep learning is reminded that these companies are at the cutting edge of these technologies.&lt;/p&gt;
&lt;p&gt;Since the shift is towards open source and global adaptation of this technology, deep learning is likely to do well in the future and impact vast sectors of in our society. To learn more about Deep Learning and join the Dutch Data Science week  click here.&lt;/p&gt;</content><category term="tech"></category><category term="deep learning"></category></entry><entry><title>Python masterclass to Restart Network</title><link href="/2018-05-02-python-masterclass-restart-network.html" rel="alternate"></link><published>2018-05-02T00:00:00+02:00</published><updated>2018-05-02T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-05-02:/2018-05-02-python-masterclass-restart-network.html</id><summary type="html">&lt;p&gt;Gave a nonprofit Python masterclass to Restart Network which supports refugees in The Netherlands.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="python"></category></entry><entry><title>Advanced deep learning to bol.com, Delhaize and AHOL group</title><link href="/2018-04-01-advanced-deep-learning-ahol.html" rel="alternate"></link><published>2018-04-01T00:00:00+02:00</published><updated>2018-04-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-04-01:/2018-04-01-advanced-deep-learning-ahol.html</id><summary type="html">&lt;p&gt;Gave an advanced deep learning training to bol.com, Albert Hijn, Delhaize and AHOL group.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="deep learning"></category><category term="rnn"></category><category term="lstm"></category></entry><entry><title>Multi-threshold Neuron Model</title><link href="/multi-threshold-neuron.html" rel="alternate"></link><published>2018-03-09T00:00:00+01:00</published><updated>2018-03-09T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-03-09:/multi-threshold-neuron.html</id><summary type="html">&lt;p&gt;Inspired by a new biological scientific research, I propose, build and train a Deep Neural Network using a novel neuron model.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.com/rod-multi-threshold-neuron"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Inspired by a new biological scientific research, I propose, build and train a Deep Neural Network using a novel neuron model.&lt;/p&gt;
&lt;p&gt;&lt;img alt="model proposal" src="/images/blog/tech/multi-threshold-neuron/model_proposal.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;sup&gt;Figure 0. Schematic diagrams of two neuron models. (Central-threshold neuron) The model on the left is the current employed model in artificial neural networks where the input signals are propagated if their sum is above a certain threshold. (Multi-threshold neuron) In contrast, in the right I show the new proposed model where each input signal goes through a threshold filter before summing them.&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;In this blog post I construct and train a simple Deep Neural Network based on a novel experimental driven neuron model proposed last year (2017) in July. This blog is separated as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scientific background&lt;ul&gt;
&lt;li&gt;Summarize the article that lead me to this idea and explain some of the theory.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Concepts&lt;ul&gt;
&lt;li&gt;Relate Deep Learning technical concepts to Neuroscience concepts mentioned in the paper.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approximations&lt;ul&gt;
&lt;li&gt;Introduce approximations I will make on the multi-threshold neuron model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Discussion&lt;ul&gt;
&lt;li&gt;Overview of mathematical and Deep Learning implications as a consequence of the multi-threshold neuron model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Model &amp;amp; training&lt;ul&gt;
&lt;li&gt;Tensorflow implementation and training of a simple fully-connected Deep Neural Network using the multi-threshold neuron model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Results&lt;ul&gt;
&lt;li&gt;Briefly show and explain results from training and testing the proposed model vs the commonly used one in Deep Neural Networks (DNNs).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Scientific background&lt;/h2&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="article_title" src="/images/blog/tech/multi-threshold-neuron/article.png"&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;S. Sardi &lt;em&gt;et al.&lt;/em&gt; published in July last year (2017) an experimental work in &lt;a href="https://www.nature.com/articles/s41598-017-18363-1"&gt;Nature scientific reports&lt;/a&gt; which contradicts a century old assumption about how neurons work. The work was a combined effort between the Physics, Life Sciences and Neuroscience departments of Bar-Ilan University in Tel Aviv, Israel.&lt;/p&gt;
&lt;p&gt;The authors proposed three different neuron models which they put to the test with different types of experiments. They describe each neuron model with, what they call, &lt;em&gt;neuronal equations&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="neuron" src="/images/blog/tech/multi-threshold-neuron/neuron.jpg"&gt;&lt;/center&gt;
&lt;sup&gt;Figure 1. Schematic representation of a neuron. The signal in a neural network flows from a neuron's axon to the dendrites of another one. That is, the signal in any neuron is incoming from its dendrites and outgoing to its axon.&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Below I describe two of these neuron models in the paper. In particular the commonly used neuron model which I call "central-threshold" and the neuron model proposal in this blog "multi-threshold".&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Central-threshold neuron&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is the current adopted computational description of neurons (&lt;a href="https://en.wikipedia.org/wiki/Artificial_neuron"&gt;artificial neurons&lt;/a&gt;), and the corner stone of Deep Learning. "A neuron consists of a unique centralized excitable mechanism". The signal reaching the neuron consists of a linear sum of the incoming signals from all the dendrites connected to the neuron, if this sum reaches a threshold, a spike signal is propagated through the axon to the other connected neurons.&lt;/p&gt;
&lt;p&gt;The neuronal equation of this model is:&lt;/p&gt;
&lt;p&gt;$$I = \Theta\Big(\sum_{i=1}^NW_i\cdot I_i - t\Big)$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$i$: identifies any connected neuron&lt;/li&gt;
&lt;li&gt;$N$: total number of connected neurons&lt;/li&gt;
&lt;li&gt;$W_i$: is the weight (strength) associated to the connection with neuron $i$&lt;/li&gt;
&lt;li&gt;$I_i$: is the signal coming out of neuron $i$&lt;/li&gt;
&lt;li&gt;$t$: is the centralized single neuron threshold&lt;/li&gt;
&lt;li&gt;$\Theta$: is the &lt;a href="https://en.wikipedia.org/wiki/Heaviside_step_function"&gt;Heaviside step function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;$I$: signal output from the neuron&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Multi-threshold neuron&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this model the centralized threshold ($\Theta$) is removed. The neuron can be independently excited by any signal coming from a dendrite given that this signal is above a threshold. This model describes a multi-threshold neuron and the mathematical representation can be written as:&lt;/p&gt;
&lt;p&gt;$$I=\sum_{i=1}^N\Theta(W_i\cdot I_i - t_i)$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$i$: identifies any connected neuron&lt;/li&gt;
&lt;li&gt;$N$: total number of connected neurons&lt;/li&gt;
&lt;li&gt;$W_i$: is the weight (strength) associated to the connection with neuron $i$&lt;/li&gt;
&lt;li&gt;$I_i$: is the signal coming out of neuron $i$&lt;/li&gt;
&lt;li&gt;$t_i$: is the threshold value for each neuron $i$&lt;/li&gt;
&lt;li&gt;$\Theta$: is the &lt;a href="https://en.wikipedia.org/wiki/Heaviside_step_function"&gt;Heaviside step function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;$I$: signal output from the neuron&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Study conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Based on their experiments the authors conclude that the &lt;strong&gt;multi-threshold neuron&lt;/strong&gt; model explains best the data. The authors mention that the main reason for adopting the central-threshold neuron as the main model, is that technology did not allow for direct excitation of single neurons, which other model experiments require. Moreover, they state that these results could have been discovered using technology that existed since the 1980s.&lt;/p&gt;
&lt;h2&gt;Concepts&lt;/h2&gt;
&lt;p&gt;There are some main concepts in the Deep Learning domain that you should be familiar with before proceeding. If you are familiar with them skip this part.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;img align='left' src="/images/blog/tech/multi-threshold-neuron/artificial_neuron.png" width="300px"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Artificial neuron&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A mathematical representation of a biological neuron. They are the corner stone of artificial neural networks and Deep Learning. The idea is that the artificial neuron receives input signals from other connected artificial neurons and via a non-linear transmission function emits a signal itself.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;img align='left' src="/images/blog/tech/multi-threshold-neuron/relu.png" width="300px"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Activation function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The current understanding of a neuron is that it will transmit some signal only if the sum from incoming signals from other neurons exceeds a threshold. For an artificial neuron this threshold filter is applied via an activation function. There are many &lt;a href="https://en.wikipedia.org/wiki/Activation_function"&gt;activation functions&lt;/a&gt; but the &lt;a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"&gt;Rectified Linear unit&lt;/a&gt; (ReLu) is one of the most broadly used in the Deep Learning community, and it's the one I will use in this notebook. The mathematical definition of the function is:&lt;/p&gt;
&lt;p&gt;$$R(z) = max(0, z) =
     \begin{cases}
       0 &amp;amp;\quad\text{for } z\leq0 \
       z &amp;amp;\quad\text{for } z &amp;gt; 0
     \end{cases}$$&lt;/p&gt;
&lt;p&gt;You can check its implementation in the &lt;a href="https://github.com/tensorflow/tensorflow/blob/48be6a56d5c49d019ca049f8c48b2df597594343/tensorflow/compiler/tf2xla/kernels/relu_op.cc#L37"&gt;Tensorflow source code&lt;/a&gt; or in the &lt;a href="https://github.com/tensorflow/playground/blob/718a6c8f2f876d5450b105e269534ae58e70223d/nn.ts#L120"&gt;Tensorflow playground code&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Approximations&lt;/h2&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="cow" src="/images/blog/tech/multi-threshold-neuron/spherical_cow.gif"&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;I am a theoretical physicist and as such it's impossible for me to resist the &lt;a href="https://en.wikipedia.org/wiki/Spherical_cow"&gt;spherical cow&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single threshold value&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The multi-threshold neuron model contains different threshold parameter values ($t_i$). Mathematically a threshold has the same effect if I take it as a constant and instead the input signal is moved up or down by the connecting weight parameters. Hence, the neuronal equation becomes: &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;$$I=\sum_{i=1}^N\Theta(W_i\cdot I_i - t)$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ReLu activation function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I'll replace the Heaviside step function ($\Theta$) with threshold $t$ by a &lt;a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"&gt;Rectified Linear unit&lt;/a&gt; ($\mathcal{R}$).&lt;/p&gt;
&lt;p&gt;$$I=\sum_{i=1}^N\mathcal{R}(W_i\cdot I_i)$$&lt;/p&gt;
&lt;p&gt;In general any activation function could replace the Heaviside step function.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bias&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Notice that the proposed model equation contains no bias terms. I'll add a bias term to the equation since it's known to help neural networks fit better. It can also help with the threshold approximation, tuning the biases instead of the thresholds.&lt;/p&gt;
&lt;p&gt;$$I=\sum_{i=1}^N\mathcal{R}(W_i\cdot I_i) + b$$&lt;/p&gt;
&lt;h3&gt;Discussion&lt;/h3&gt;
&lt;p&gt;The idea is to take the multi-threshold neuron model and try to write a Deep Learning implementation, a neural network consisting of multi-threshold neurons. Tensorflow is quite flexible and allows for writing user defined implementations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Backpropagation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order for my neural network to be trained I need backpropagation, this means that the derivative of whatever I introduce is necessary. Luckily, I'm not changing the activation function itself, I can just use the already derivative of the ReLu function in Tensorflow:&lt;/p&gt;
&lt;p&gt;$$\frac{d}{dz}\mathcal{R}(z)=
     \begin{cases}
       0 &amp;amp;\quad\text{for } z\leq0 \
       1 &amp;amp;\quad\text{for } z &amp;gt; 0
     \end{cases}$$&lt;/p&gt;
&lt;p&gt;You can check it out in the &lt;a href="https://github.com/tensorflow/tensorflow/blob/48be6a56d5c49d019ca049f8c48b2df597594343/tensorflow/compiler/tf2xla/kernels/relu_op.cc#L63"&gt;Tensorflow source code&lt;/a&gt; or in the &lt;a href="https://github.com/tensorflow/playground/blob/718a6c8f2f876d5450b105e269534ae58e70223d/nn.ts#L121"&gt;Tensorflow playground code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tensor multiplication&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What I'm really changing is the architecture of the artificial neural network as seen in Figure 0, the activation function is no longer applied on the sum of all the inputs from the connected neurons, but instead on the input arriving from every single connected neuron. The sum operation is going from inside the activation function to outside of it:&lt;/p&gt;
&lt;p&gt;$$\mathcal{R}\Big(\sum_{i=1}^NW_i\cdot I_i\Big) \rightarrow \sum_{i=1}^N\mathcal{R}(W_i\cdot I_i)$$&lt;/p&gt;
&lt;p&gt;Do you see the implementation problem described by the equation above?&lt;/p&gt;
&lt;p&gt;In the central-threshold model (left equation) the input to the activation function $\sum_iW_i\cdot I_i$ is exactly the dot product between vectors $(W_1, W_2,\dots,W_N)$ and $(I_1, I_2,\dots,I_N)$ and it's this fact which allows fast computation of input signals for many neurons and observations at once via a single matrix multiplication.&lt;/p&gt;
&lt;p&gt;In the multi-threshold model this is no longer possible. I think this will be the biggest challenge when coming up with an implementation which can be trained efficiently and fast.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Suppose I have the following weight matrix connecting two neuron layers, the first layer has 3 neurons the second has 2:&lt;/p&gt;
&lt;p&gt;$$W=
\begin{bmatrix}
    3 &amp;amp; -4 \
    -2&amp;amp; 2\
    0&amp;amp; 4
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;and that the output signal from the neurons in the first layer are&lt;/p&gt;
&lt;p&gt;$$I_0=
\begin{bmatrix}
    2 &amp;amp; 5 &amp;amp; 1
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;with bias terms&lt;/p&gt;
&lt;p&gt;$$b=
\begin{bmatrix}
    2 &amp;amp; -1
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;Using the standard central-threshold neuron model, the output signal of the second layer is:&lt;/p&gt;
&lt;p&gt;$$\mathcal{R}\Big(I_0\cdot W + b\Big) = \mathcal{R}\Big(
\begin{bmatrix}
    2 &amp;amp; 5 &amp;amp; 1
\end{bmatrix}
\cdot
\begin{bmatrix}
    3 &amp;amp; -4 \
    -2&amp;amp; 2\
    0&amp;amp; 4
\end{bmatrix}
+
\begin{bmatrix}
    2 &amp;amp; -1
\end{bmatrix}
\Big)
=
$$
$$
\mathcal{R}\Big(
\begin{bmatrix}
    -2 &amp;amp; 5
\end{bmatrix}
\Big)
=
\begin{bmatrix}
    \mathcal{R}(-2)&amp;amp; \mathcal{R}(5)
\end{bmatrix}
\Big)
=
\begin{bmatrix}
    0 &amp;amp; 5
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;In the case of the multi-threshold neuron model proposed the output is&lt;/p&gt;
&lt;p&gt;$$
[\sum_{i=1}^N\mathcal{R}(W_{i1}\cdot I_i) + b_1, \sum_{i=1}^N\mathcal{R}(W_{i2}\cdot I_i) + b_2]=
$$
$$
\begin{bmatrix}
    \mathcal{R}(6) + \mathcal{R}(-10) + \mathcal{R}(0) + 2 &amp;amp; \mathcal{R}(-8) + \mathcal{R}(10) + \mathcal{R}(4)  -1
\end{bmatrix}
=
\begin{bmatrix}
    8 &amp;amp; 13
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;As the example shows, a fundamental difference is that in the multi-threshold case if any input output signal times the weight is positive then the output will be positive. This will greatly reduce the sparsity of the neurons firing throughout the network in comparison with the conventional central-threshold model.&lt;/p&gt;
&lt;p&gt;I don't know all the implications but I expect that it will be more difficult for individual neurons (or parts of the network) to singly address a specific feature, therefore in principle reducing overfitting.&lt;/p&gt;
&lt;p&gt;A known issue of most activation functions in Deep Neural Networks is the "vanishing gradient problem", it relates to the decreasing update value to the weights as the errors propagate through the network via backpropagation. In the standard central-threshold model the ReLu partially solves this problem by having a derivative equal to 1 if the neuron fires, this propagates the error without vanishing the gradient. On the other hand, if the neuron signal is negative and squashed by the ReLu (did not fire) the corresponding weights are not updated, since the ReLu derivate is zero i.e. neuron connections are not learning when the connecting neurons didn't fire. In the multi-threshold model, I expect this last issue to be reduced since sparsity reduces, more weights should be updated on each step in comparison with the central-threshold neuron.&lt;/p&gt;
&lt;h2&gt;Model &amp;amp; training&lt;/h2&gt;
&lt;p&gt;I first concentrate in replicating the example above using &lt;code&gt;tensorflow&lt;/code&gt;, it contains two built-in related &lt;code&gt;ReLu&lt;/code&gt; functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;relu_layer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;relu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;relu_layer&lt;/code&gt; function already assumes a layer architecture with central-threshold neurons. The &lt;code&gt;relu&lt;/code&gt; function on the other hand can operate on each entry of a tensor.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;I_0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;I_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;multiply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I_0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;
&lt;span class="n"&gt;I_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Notice that &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;I_0&lt;/code&gt; are one dimensional tensors, this allows me to take advantage of the &lt;code&gt;tensorflow&lt;/code&gt; broadcasting feature. Using the code above I can then define a neural network layer consisting of multi-threshold neurons&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;multi_threshold_neuron_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;multiply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;MNIST - 2 hidden layer multi-threshold neural network&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With this basic implementation, my goal was to see if the model is actually trainable. I just wanted to observe the loss decrease with each iteration. As you probably noticed, the &lt;code&gt;multi_threshold_neuron_layer&lt;/code&gt; can only take 1 example at a time, this is the complication I mentioned, simple matrix multiplication taking several observations is no longer possible for now. In part II of the blog I hope to expand to a more efficient implementation.&lt;/p&gt;
&lt;p&gt;The multi-threshold neural network is then:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Construct model&lt;/span&gt;
&lt;span class="n"&gt;I_0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;float&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_size&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt; &lt;span class="c1"&gt;# input layer&lt;/span&gt;

&lt;span class="n"&gt;W_01&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;hidden_layers_sizes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;input_size&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;b_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;hidden_layers_sizes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],)))&lt;/span&gt;
&lt;span class="n"&gt;I_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multi_threshold_neuron_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I_0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W_01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 1st hidden layer&lt;/span&gt;

&lt;span class="n"&gt;W_12&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;hidden_layers_sizes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;hidden_layers_sizes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="n"&gt;b_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;hidden_layers_sizes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],)))&lt;/span&gt;
&lt;span class="n"&gt;I_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multi_threshold_neuron_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I_1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W_12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 2nd hidden layer&lt;/span&gt;

&lt;span class="n"&gt;W_23&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;number_of_classes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_layers_sizes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="n"&gt;b_3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_normal&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;number_of_classes&lt;/span&gt;&lt;span class="p"&gt;,)))&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W_23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I_2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b_3&lt;/span&gt; &lt;span class="c1"&gt;# output layer&lt;/span&gt;

&lt;span class="c1"&gt;# truth&lt;/span&gt;
&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;float&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;number_of_classes&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Using the digits MNIST data set I ran a comparison between a DNN using the conventional central-threshold neurons and the proposed multi-threshold neurons.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tensorflow.examples.tutorials.mnist&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;input_data&lt;/span&gt;
&lt;span class="n"&gt;mnist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_data_sets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;/tmp&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;one_hot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;It is trainable! I actually though this would just crash and burn so I was very happy to see that loss go down :).&lt;/p&gt;
&lt;p&gt;I calculated the cross-entropy loss and accuracy during training and final accuracy in a test set. It is very important to remember that to keep things fair the calculations for both models are using a batch of 1 observation.&lt;/p&gt;
&lt;p&gt;The training period ran for &lt;code&gt;4 epochs&lt;/code&gt; with a training set of &lt;code&gt;55000 observations&lt;/code&gt;. Normally the loss and accuracy is calculated over the batch, in this case that makes no sense&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt;. Instead what I do is report the average loss and average accuracy over every &lt;code&gt;1100 observations&lt;/code&gt; &lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5"&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The score of my model consisted of calculating the accuracy over a test set of &lt;code&gt;10000 observations&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Training loss and accuracy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="accuracy_vs_rate_and_type" src="/images/blog/tech/multi-threshold-neuron/accuracy_and_loss_curves.png"&gt;&lt;/p&gt;
&lt;p&gt;There are many things that can be discussed from Figure 2 but here are the main points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cross-entropy loss decreases with iterations which means the model is trainable.&lt;/li&gt;
&lt;li&gt;When the &lt;code&gt;central-threshold&lt;/code&gt; model is performing well its loss is much lower than the &lt;code&gt;multi-threshold&lt;/code&gt;. Notice that this is the case since the beginning of the training period, a sort of a shift. This could be because our images contain consistent white areas (edges) where the cross-entropy benefits from having sparse activations in our neural network.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;multi-threshold&lt;/code&gt; model seems to be more robust against higher learning rates. Moreover, it seems to prefer higher learning rates.&lt;/li&gt;
&lt;li&gt;As I mentioned before I would expect the &lt;code&gt;multi-threshold&lt;/code&gt; model to have less sparse activations which in turn should result in a faster learning &lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6"&gt;6&lt;/a&gt;&lt;/sup&gt;. This can be observed for learning rate &lt;code&gt;.0005&lt;/code&gt; and &lt;code&gt;.001&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Test Accuracy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="accuracy_vs_rate_and_type" src="/images/blog/tech/multi-threshold-neuron/accuracy_vs_rate_and_type.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: center;"&gt;Learning rate&lt;/th&gt;
&lt;th style="text-align: center;"&gt;Central-threshold&lt;/th&gt;
&lt;th style="text-align: center;"&gt;Multi-threshold&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;0.0005&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.8571&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.8757&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;0.001&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.8958&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.8879&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;0.005&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.2554&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.9085&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: center;"&gt;0.01&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.1028&lt;/td&gt;
&lt;td style="text-align: center;"&gt;0.773&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As seen in the training report above, the &lt;code&gt;multi-threshold&lt;/code&gt; model seems to be more robust against higher learning rates. It could be that this is just a sort of shift and for even bigger learning rates it will show the same behavior as the &lt;code&gt;central-threshold&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;multi-threshold&lt;/code&gt; model does not overfit in these examples. Even more, for learning rate 0.005 it achieves a loss 2 orders of magnitude higher than the &lt;code&gt;central-threshold&lt;/code&gt; but a higher accuracy in the test set.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Adios&lt;/h2&gt;
&lt;p&gt;This was a pretty fun blog to make. I have some final remarks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The proposed model is trainable, but I cannot say much of the specifics since that requires more investigation that I have not done.&lt;/li&gt;
&lt;li&gt;A very important point is that since at the moment I can only use batches of 1, the training time is painfully slow, definitely not something for realistic applications.&lt;/li&gt;
&lt;li&gt;Finally, I know that Figure 3 seems quite promising but let's not forget that this is done with a batch of a single observation.&lt;/li&gt;
&lt;li&gt;In part II of this blog I'll try to come up with the functionality of having more observations per update and use a convolutional layer to make a more realistic comparison.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/blog/tech/ml-pyapp/dog_developer.jpg" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;You can find the code &lt;a href="https://github.com/rragundez/multi-threshold-neuron"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any other questions just ping me in twitter &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;This is also happening in the current neural network implementations, since in reality there is no reason for different neurons to have the same threshold, nevertheless commonly a single activation function is used on all neurons.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;It is a one line function, I know I know, but I can already sense there will be more to it later since this just works for a single input example.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Since at the moment the multi-threshold neuron model uses only a single example at a time, to make a fair comparison both DNN weights are updated on each example (batches of size 1), &lt;code&gt;x, y = mnist.train.next_batch(1, shuffle=True)&lt;/code&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;If you do that the accuracy and loss will be all over the place as it will be dependent on a single observation. This could make difficult to assess if the model is indeed getting better on each iteration by seeing the loss monotonically decrease.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;You don't want this number to be too high since you expect an average lower loss and higher accuracy for observations at the end. If there are too many observations your standard deviation will increase and the reported average can be meaningless.&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;The weights of a neural network using &lt;code&gt;relu&lt;/code&gt; activations where the neuron output is zero cannot learn because the back-propagated derivative is zero.&amp;#160;&lt;a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="deep learning"></category><category term="tensorflow"></category><category term="research"></category><category term="classification"></category></entry><entry><title>Data Science with python to ATOS</title><link href="/2018-03-01-data-science-with-python-atos.html" rel="alternate"></link><published>2018-03-01T00:00:00+01:00</published><updated>2018-03-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-03-01:/2018-03-01-data-science-with-python-atos.html</id><summary type="html">&lt;p&gt;Gave the 2 days data science with Python training to ATOS consulting group in Belgium.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="python"></category><category term="scikit-learn"></category><category term="pandas"></category><category term="numpy"></category></entry><entry><title>Lead Data Scientist for Nspire project @ KPN</title><link href="/2018-03-01-data-scientist-kpn-nspire.html" rel="alternate"></link><published>2018-03-01T00:00:00+01:00</published><updated>2018-03-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-03-01:/2018-03-01-data-scientist-kpn-nspire.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a lead data scientist for the Nspire project in KPN.&lt;/p&gt;</summary><content type="html">&lt;p&gt;NSPIRE is a mobile application available for download which makes recommendations about what to do in your leisure time. I joined the project since almost the beginning and I was responsible for building the artificial intelligence part of it. Some of my responsibilities were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advise on decisions about the application and technologies used.&lt;/li&gt;
&lt;li&gt;Work closely with an editorial office to fine-tuning the AI system.&lt;/li&gt;
&lt;li&gt;Implement several recommendation models.&lt;/li&gt;
&lt;li&gt;Taking the AI part of the application all the way from development to production.&lt;/li&gt;
&lt;li&gt;Supervise several data scientist during the time of the project.&lt;/li&gt;
&lt;li&gt;Share knowledge and communicate with internal data scientists such that they could take up the project after I leave.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="scikit-learn"></category><category term="Flask"></category><category term="Pandas"></category><category term="git"></category><category term="Tensorflow"></category><category term="Keras"></category><category term="numpy"></category><category term="python"></category></entry><entry><title>Code breakfast deep learning edition</title><link href="/2018-01-17-code-breakfast-deep-learning.html" rel="alternate"></link><published>2018-01-17T00:00:00+01:00</published><updated>2018-01-17T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-01-17:/2018-01-17-code-breakfast-deep-learning.html</id><summary type="html">&lt;p&gt;Gave a free 3 hour workshop about deep learning.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="python"></category><category term="deep learning"></category><category term="keras"></category></entry><entry><title>From PhD to GDD</title><link href="/2018-01-09-phd-to-gdd-vrij-universiteit.html" rel="alternate"></link><published>2018-01-09T00:00:00+01:00</published><updated>2018-01-09T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-01-09:/2018-01-09-phd-to-gdd-vrij-universiteit.html</id><summary type="html">&lt;p&gt;Presented for Master Science, Business &amp;amp; innovation students the story and experiences of going from a PhD to data scientist for GoDataDriven.&lt;/p&gt;</summary><content type="html"></content><category term="talk"></category><category term="motivation"></category><category term="students"></category></entry><entry><title>Advanced Python Mastery</title><link href="/2017-12-04-advanced-python-mastery.html" rel="alternate"></link><published>2017-12-04T00:00:00+01:00</published><updated>2017-12-04T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-12-04:/2017-12-04-advanced-python-mastery.html</id><summary type="html">&lt;p&gt;Took the advanced Python mastery week course with David Beazley in Chicago.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="python"></category></entry><entry><title>Advanced Deep Learning</title><link href="/2017-12-02-advanced-deep-learning.html" rel="alternate"></link><published>2017-12-02T00:00:00+01:00</published><updated>2017-12-02T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-12-02:/2017-12-02-advanced-deep-learning.html</id><summary type="html">&lt;p&gt;Took a 2 day course of advanced deep learning with Python &amp;amp; Tensorflow in San Francisco.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="python"></category><category term="keras"></category><category term="tensorflow, openai, deep learning"></category><category term="reinforcement learning"></category><category term="unsupervised learning"></category></entry><entry><title>"I Pity the fool", Deep Learning style</title><link href="/fool-neural-network.html" rel="alternate"></link><published>2017-11-05T00:00:00+01:00</published><updated>2017-11-05T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-11-05:/fool-neural-network.html</id><summary type="html">&lt;p&gt;With deep learning applications blossoming, it is important to understand what makes these models tick. Here I demonstrate, using simple and reproducible examples, how and why deep neural networks can be easily fooled. I also discuss potential solutions.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.com/rod-fool-neural-network"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With deep learning applications blossoming, it is important to understand what makes these models tick. Here I demonstrate, using simple and reproducible examples, how and why deep neural networks can be easily fooled. I also discuss potential solutions.&lt;/p&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/blog/tech/fooling-dnn/mr_t.png" width="350" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;Several studies have been published on how to fool a deep neural network (DNN). The most famous study, which was published in 2015 used evolutionary
algorithms or gradient ascent to produce the adversarial images.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; A very recent study (October 2017) revealed that fooling a DNN could be achieved by changing a single pixel.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; This subject seems fun and all but has substantial implications on current and future applications of deep learning. I believe that understanding what makes these models tick is extremely important to be able to develop robust deep learning applications (and avoid another event like random forest mania).&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;A comprehensive and complete summary can be found in the &lt;a href="https://blog.acolyer.org/2017/02/28/when-dnns-go-wrong-adversarial-examples-and-what-we-can-learn-from-them/"&gt;When DNNs go wrong&lt;/a&gt; blog, which I recommend you to read.&lt;/p&gt;
&lt;p&gt;All these amazing studies use state of the art deep learning techniques, which makes them (in my opinion) difficult to reproduce and to answer questions we might have as non-experts in this subject.&lt;/p&gt;
&lt;p&gt;My intention in this blog is to bring the main concepts down to earth, to an easily reproducible setting where they are clear and actually visible. In addition, I hope this short blog can provide a better understanding of the limitations of discriminative models in general. The complete code used in this blog post can be found &lt;a href="https://gist.github.com/rragundez/9399f28a96541e00d02d23f2e3b86338"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Discriminative what?&lt;/h2&gt;
&lt;p&gt;Neural networks belong to the family of discriminative models, they model the dependence of an unobserved variable (target) based on observed input (features). In the language of probability this scenario is represented by the conditional probability and it is expressed as:&lt;/p&gt;
&lt;p&gt;$$p(target|features)$$&lt;/p&gt;
&lt;p&gt;it reads: the probability of the target given the features (e.g. the probability that it will rain based on yesterday's weather, temperature and pressure measurements).&lt;/p&gt;
&lt;p&gt;Multinomial logistic regression models are also part of these discriminative models and they basically are a neural network without a hidden layer. Please don't be disappointed but I will start by demonstrating some concepts using multinomial logistic regression. Then I'll expand the concepts to a deep neural network.&lt;/p&gt;
&lt;h2&gt;Fooling multinomial logistic regression&lt;/h2&gt;
&lt;p&gt;As mentioned before a multinomial logistic regression can be seen as a neural network without a hidden layer. It models the probability of the target ($Y$) being a certain category ($c$), as a function ($F$) that depends on the linear combination of the features ($X=(X_1, X_2,...,X_N)$). We write this as&lt;/p&gt;
&lt;p&gt;$$P(Y=c|X)=F(\theta_{c}^T\cdot X)$$&lt;/p&gt;
&lt;p&gt;where $\theta_c$ are the coefficients of the linear combination for each category. The predicted class by the model is the one which gives the highest probability.&lt;/p&gt;
&lt;p&gt;When the target $Y$ is binary, $F$ is taken to be some &lt;a href="https://en.wikipedia.org/wiki/Sigmoid_function"&gt;sigmoid function&lt;/a&gt;, the most common being the &lt;a href="https://en.wikipedia.org/wiki/Logistic_function"&gt;logistic function&lt;/a&gt;. When $Y$ is multiclass we commonly use $F$ as the &lt;a href="https://en.wikipedia.org/wiki/Softmax_function"&gt;softmax function&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Apart from the conceptual understanding of discriminative models, the linear combination of the features ($\theta_{c}^T\cdot X$) is what makes classification models vulnerable as I will demonstrate. In the own words of Master Jedi Goodfellow: "Linear behavior in high-dimensional spaces is sufficient to cause adversarial examples".&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h4&gt;Iris dataset&lt;/h4&gt;
&lt;p&gt;When I was thinking on how to do this blog post and actually visualize the concepts, I concluded I needed two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A 2-dimensional feature space.&lt;/li&gt;
&lt;li&gt;A model with high accuracy on this space.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The 2-dimensional space because I wanted to generate plots which directly show the concepts. High accuracy because it's meaningless if I am able to fool a bad model.&lt;/p&gt;
&lt;p&gt;Lucky for me, it turns out that a good accuracy can be obtained on the &lt;a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"&gt;Iris dataset&lt;/a&gt; by just keeping two features: petal length and petal width.&lt;/p&gt;
&lt;p&gt;Putting everything into shape this is how the data looks like&lt;/p&gt;
&lt;p&gt;&lt;img alt="iris dataset sample" src="/images/blog/tech/fooling-dnn/iris_df_sample.png"&gt;&lt;/p&gt;
&lt;p&gt;This dataset contains only 150 observations, I will fit the model to all the data using a cross-entropy loss function and a L2 regularization term. This is just a plug and play from the amazing scikit-learn.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;solver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;lbfgs&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;multi_class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;multinomial&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;penalty&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;l2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;flower&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;iris&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flower&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The mean accuracy of the model is $96.6\%$. This score is based on the training data and can be misleading, even if I am using a regularization term I can still be overfitting.&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Let's now look at our predictions and at how our model is drawing the classification boundaries.&lt;/p&gt;
&lt;p&gt;&lt;img alt="iris predictions" src="/images/blog/tech/fooling-dnn/iris_predictions.png"&gt;&lt;/p&gt;
&lt;p&gt;In Figure 0 the red outer circles indicate those observations that were wrongly classified. The setosa flowers are easily identified and there is a region where the versicolor and virginica observations are close together. In Figure 1 we can see the different regions for each flower category. The regions are separated by a linear boundary, this is a consequence of the linear combination model used $P(Y=c|X)=F(\theta_{c}^T\cdot X)$. As mentioned, in the case of a logistic regression (binary classification) $F$ is the logistic function&lt;/p&gt;
&lt;p&gt;$$F(\theta_{c}^T\cdot X)=\frac{1}{1 + e^{-\theta_{c}^T\cdot X}}$$&lt;/p&gt;
&lt;p&gt;and the classification boundary is given by $P(Y=c|X)=\frac{1}{2}$ when $\theta_{c}^T\cdot X=0$. If the features are in one dimension then the boundary will be a single value, for two features the boundary is a single line and for three features a plane and so on. In our multinomial case we use the softmax function&lt;/p&gt;
&lt;p&gt;$$F(\theta_{c}^T\cdot X)=\frac{e^{\theta_{c}^T\cdot X}}{\Sigma_{i=1}^Ne^{\theta_{i}^T\cdot X}}$$&lt;/p&gt;
&lt;p&gt;where the sum over $i$ in the denominator runs over all the possible classes of the target. In the regions where only two classes have a non-negligible probability the softmax function simplifies to the logistic function. Therefore the linear classification boundaries between two regions is given by the contour $P(Y=c|X)=\frac{1}{2}$ as shown in Figure 3. In addition, when none of the classes have a negligible probability the boundary approaches the contour $P(Y=c|X)=\frac{1}{3}$ where the uncertainty of our prediction is maximum. This region is illustrated in Figure 2.&lt;/p&gt;
&lt;p&gt;A thing to note is that the regions extend to values which can be very far from the observations, which means we can grab a petal length of 1 and petal width of 4 and still be classified as a setosa. Even more, Figure 4 shows that even far away from our observations we can find regions with extremely high probability. We can even use a negative petal length!&lt;/p&gt;
&lt;p&gt;&lt;img alt="iris regions" src="/images/blog/tech/fooling-dnn/iris_regions.png"&gt;&lt;/p&gt;
&lt;p&gt;Let's pick some points from Figure 4 and see if I am able to fool the multinomial logistic classifier:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Point: (.1, 5)&lt;ul&gt;
&lt;li&gt;Prediction: setosa&lt;/li&gt;
&lt;li&gt;Probability: 0.998&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Point: (10, 10)&lt;ul&gt;
&lt;li&gt;Prediction: virginica&lt;/li&gt;
&lt;li&gt;Probability: 1.0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Point: (5, -5)&lt;ul&gt;
&lt;li&gt;Prediction: versicolor&lt;/li&gt;
&lt;li&gt;Probability: 0.992&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The three points give a high probability on the prediction but are not even remotely like the observations in our dataset.&lt;/p&gt;
&lt;p&gt;Ok, now to the good stuff.&lt;/p&gt;
&lt;h2&gt;Fooling a Deep Neural Network&lt;/h2&gt;
&lt;p&gt;As I said before, in order for me to demonstrate the concepts and have a comprehensive visualization I need two things&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A 2-dimensional feature space.&lt;/li&gt;
&lt;li&gt;A model with high accuracy on this space.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the case of a deep neural network it makes no sense to attack a problem with 2 features, as the intent of neural network is to throw a bunch of features as the input layer and let the hidden layers figure out and construct new features which are relevant to my classification problem. So my reasoning as how to solve my first requirement goes as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build a DNN where the last hidden layer has two units.&lt;/li&gt;
&lt;li&gt;Then do the space analysis on the features from that layer.&lt;/li&gt;
&lt;li&gt;Pick a point on that layer space which is far from the propagated observations but still is classified with a high probability.&lt;/li&gt;
&lt;li&gt;Invert all the operations made from the input layer to that last hidden layer and apply them to my selected 2D point from step 3.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If I can perform those steps I should end with an input which is nothing like my observations but still is classified with high probability by the DNN, giving me an adversarial example.&lt;/p&gt;
&lt;h4&gt;MNIST&lt;/h4&gt;
&lt;p&gt;I chose the &lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;MNIST&lt;/a&gt; digits since it is a straight forward dataset to perform classification and it is complex enough to apply a DNN. I only take 4 classes, the numbers ${0, 1, 2, 3}$. The final dataset consists of a bit more than 28,000 observations with 28x28=784 features.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;digits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fetch_mldata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;MNIST original&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;in1d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Number of observations: 28911
Nr. observations per class:
1.0    7877
3.0    7141
2.0    6990
0.0    6903
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A sample view of our observations:&lt;/p&gt;
&lt;p&gt;&lt;img alt="digits sample" src="/images/blog/tech/fooling-dnn/digits_sample.png"&gt;&lt;/p&gt;
&lt;h4&gt;DNN configuration&lt;/h4&gt;
&lt;p&gt;The challenge here is to find the correct configuration such that the training of the DNN converges and has a good performance on the training set.&lt;/p&gt;
&lt;p&gt;In addition, in order to be able to invert all the operations from the input layer to the last hidden layer then all functions applied must have an inverse. This means that if I decide to use any of the activation functions provided: logistic, tanh and relu, I need to keep track and impose restrictions on my nodes activation so that they are in the codomain of the activation function. This is not trivial and in my opinion does not add much to the concepts I'm trying to get across. Therefore I use the identity activation which can make the convergence a bit more tricky. &lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The final configuration of the DNN consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3 hidden layers with sizes {50, 20, 2}.&lt;/li&gt;
&lt;li&gt;Identity activation function (no activation function).&lt;/li&gt;
&lt;li&gt;Stochastic gradient descent optimizer (sgd).&lt;/li&gt;
&lt;li&gt;Adaptive learning rate.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;dnn_identity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MLPClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;hidden_layer_sizes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;identity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;solver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;sgd&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;adaptive&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate_init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;.00005&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The DNN achieved close to 95% accuracy and reached conversion quite nicely as shown in Figure 6. For comparison and for use in my arguments I built another DNN with an activation function $tanh$ using the Adam optimizer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;dnn_tanh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MLPClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;hidden_layer_sizes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tanh&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;solver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;learning_rate_init&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;.0001&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The second DNN with the activation function achieved an accuracy of 98%, the loss curve in Figure 7 reveals that the training can be further improved but for now this is good enough.&lt;/p&gt;
&lt;p&gt;&lt;img alt="loss curve" src="/images/blog/tech/fooling-dnn/loss_curve.png"&gt;&lt;/p&gt;
&lt;h4&gt;Extract feature encoding from the last hidden layer&lt;/h4&gt;
&lt;p&gt;Once the model is trained we can retrieve the coefficients connecting all the layers. We use these coefficients to "manually" propagate our observations input up to the last hidden layer and then plot some of them in a 2D graph. This small function propagates the input layer up to a specified layer.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;propagate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_layer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_nr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation_function&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Obtain the activation values of any intermediate layer of the deep neural network.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input_layer&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;intercepts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercepts_&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;layer_nr&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefs_&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;layer_nr&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
        &lt;span class="n"&gt;layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;activation_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;intercepts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;layer&lt;/span&gt;

&lt;span class="n"&gt;hl_identity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;propagate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dnn_identity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;hl_tanh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;propagate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dnn_tanh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tanh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The representation of the observations under the encoding of the last 2D hidden layer is shown on Figure 8 and 9. The identity DNN, as shown in Figure 8, has encoded our observations by creating hidden features which separate them in the hidden layer dimensionality (2D in this case). The more sophisticated $tanh$ DNN achieves better performance because it is capable of coming up with hidden features which separate in a better way our observations as shown in Figure 9. Nevertheless Figures 10 and 11 reveal that in both cases linear classification boundaries are being constructed to separate our category regions. Similar to the multinomial logistic regression, this is caused by the dot product (linear Kernel) between the last hidden layer and the final weights which connect the hidden layer with the output layer. This means that these regions extend far away from where our observations lie, even more these regions have a high probability as shown in Figure 12 and 13.&lt;/p&gt;
&lt;p&gt;So now the only thing to do is to grab a point from Figure 8 (for example: -200, 200), do all the inverse operations to bring back the encoding to the input layer and reshape the vector into an image which of course will look nothing like a $1$ but will be classified as a $1$ with very high probability by our DNN.&lt;/p&gt;
&lt;p&gt;&lt;img alt="dnn predictions" src="/images/blog/tech/fooling-dnn/dnn_predictions.png"&gt;&lt;/p&gt;
&lt;h4&gt;Brief tangent&lt;/h4&gt;
&lt;p&gt;Before proceeding I would like to have a more conceptual discussion regarding the implications of the arguments presented for figure 8 and 9. The DNN creates hidden features which separate our observations as best as possible. This means that such hidden features will concentrate on capturing differences between our classes. For example, let's say we want to classify dogs and horses&lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7"&gt;7&lt;/a&gt;&lt;/sup&gt;. According to our reasoning, will a feature that captures the amount of legs be created? I don't think so, because having such a feature doesn't add to the purpose of separating our classes. We can send a horse with 5 legs and this fact will not raise any flags on our DNN. I believe this is the underlying concept when we say that discriminative models do not capture the essence of the objects to be classified. Here is where generative models come to the rescue, they recently have shown amazing results by capturing the underlying "context" of the objects. In a probability framework they shift from modelling the conditional probability to model the joint probability.&lt;/p&gt;
&lt;p&gt;Notice that the probability near the boundaries grows exponentially with the product $\theta_c\cdot X$ following the sigmoid function. This means that if we take an observation which lies close to a boundary, it takes a small perturbation to take it to another region. This is the principle behind the study of fooling a DNN with a single pixel change&lt;sup id="fnref2:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Finally notice that all our analysis is in a 2D space and as such the regions extend in a surface. In a 3D space these regions will become volumes, hence increasing the region size where adversarial examples can be found. Just like Master Jedi Goodfellow said: "Linear behavior in high-dimensional spaces is sufficient to cause adversarial examples" &lt;sup id="fnref2:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4&gt;Pity the fool&lt;/h4&gt;
&lt;p&gt;A bit of linear algebra. Two consecutive layers can be described by a set of linear equations which in matrix notation can be represented by&lt;sup id="fnref:8"&gt;&lt;a class="footnote-ref" href="#fn:8"&gt;8&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;p&gt;$$L_{N}^i\times \Theta_{N\times M}=L_{M}^{i+1}$$&lt;/p&gt;
&lt;p&gt;where $i$ is a certain layer number, $N$ and $M$ the number of units in the layer and $\Theta$ the coefficients representing the connections between layers. In our DNN each layer reduces in size, this means that $N&amp;gt;M$. In order to find the layer $i$ from the layer $i+1$ we need to find the inverse of $\Theta_{N\times M}$ and compute&lt;/p&gt;
&lt;p&gt;$$L_{N}^i=L_{M}^{i+1}\times \Theta_{N\times M}^{-1}$$&lt;/p&gt;
&lt;p&gt;The problem (of course) is that non-square matrices do not have an inverse. In the DNN context, what is happening is that we are losing information by compacting our observations in a lower dimensional space. This means there is no way to exactly trace back layers, simply because we don't have enough information. This does not mean that we cannot find a vector representing $L^i_N$ which satisfies $L_{N}^i\times \Theta_{N\times M}=L_{M}^{i+1}$ given the layer $L^{i+1}&lt;em M N_times="N\times"&gt;M$ and the coefficients $\Theta&lt;/em&gt;$, which means that such vector is not unique.&lt;/p&gt;
&lt;p&gt;A solution for the layer $L_{N}^i$ can be derived using the pseudoinverse, in particular the &lt;a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse"&gt;Moore–Penrose inverse&lt;/a&gt; is adequate for our type of problem, and best of all it is implemented in Numpy!&lt;/p&gt;
&lt;p&gt;Below I define a function which inverts the propagation from a hidden layer to the input layer with an identity activation function.&lt;sup id="fnref:9"&gt;&lt;a class="footnote-ref" href="#fn:9"&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;invert_propagation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden_layer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_nr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Obtain the input layer from a hidden layer of a deep neural network&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hidden_layer&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;intercepts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intercepts_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;layer_nr&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;coefs_&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;layer_nr&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
        &lt;span class="n"&gt;inv_weight&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pinv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;layer&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;intercepts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inv_weight&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;layer&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, the moment of truth. I choose a nonsense value for each region by looking at Figures 10 and 12. In particular I choose:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Region 0: (1200, -300)&lt;/li&gt;
&lt;li&gt;Region 1: (-500, 500)&lt;/li&gt;
&lt;li&gt;Region 2: (100,400)&lt;/li&gt;
&lt;li&gt;Region 3: (-1000, 900)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now I invert the propagation for each point, obtain the input layer, reshape the input to a 28x28 image and show it together with the prediction from the DNN and the probability of such prediction.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pity_the_fool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden_vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;input_vector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;invert_propagation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden_vector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dnn_identity&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;probability&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dnn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vector&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Prediction: &lt;/span&gt;&lt;span class="si"&gt;{:.0f}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
                 &lt;span class="s2"&gt;&amp;quot;Probability: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
                 &lt;span class="s2"&gt;&amp;quot;Hiden vector: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prediction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_vector&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;off&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="adversarial examples" src="/images/blog/tech/fooling-dnn/adversarial_examples_1.png"&gt;&lt;/p&gt;
&lt;p&gt;The figures above clearly show that I have managed to fool the DNN. It is like the DNN had some Mexican peyote or something. The labels are consistent with the regions we took the points from and are classified with almost 100% probability. There is no way a human eye can tell that those images are a 0, a 1, a 2 and a 3. Not even to tell that there are numbers.&lt;/p&gt;
&lt;h2&gt;Light at the end of the tunnel&lt;/h2&gt;
&lt;p&gt;I have stated that the main problem is the linear classification boundaries, is there a way we can avoid this? Well, I left a hint out there when I mentioned that the dot product presented is nothing more than a linear kernel. I will not go into the details of how the &lt;a href="https://en.wikipedia.org/wiki/Kernel_method"&gt;kernel trick&lt;/a&gt; works, but in summary it lets us perform dot products in higher dimensional spaces of our features without ever computing the new features in that high-dimensional space. If you never heard about it, it can be a bit of a weird thing. Just to mess more with your cerebro, if for example we were to use the &lt;a href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel"&gt;Gaussian kernel&lt;/a&gt;, this is equal to performing calculations in an infinite high-dimensional space, yes infinite! &lt;sup id="fnref:10"&gt;&lt;a class="footnote-ref" href="#fn:10"&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;By using these kernels the model is not restricted to linear classification boundaries. Below I compare a support vector machine model (SVM) with a linear kernel and a Gaussian kernel using the iris dataset.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;svm_linear&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;linear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;svm_gaussian&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;rbf&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;probability&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Both SVM models obtain an accuracy of $\approx 96.6%$.&lt;/p&gt;
&lt;p&gt;&lt;img alt="svm predictions" src="/images/blog/tech/fooling-dnn/svm_predictions.png"&gt;&lt;/p&gt;
&lt;p&gt;Figure 18 shows that the SVM with the linear kernel also suffers from the issues discussed. In general any discriminative model that is trying to model the conditional probability via some transformation of the dot product $\Theta\cdot X$ is doomed to be susceptible to adversarial examples attacks.&lt;/p&gt;
&lt;p&gt;Figure 19 is beautiful, shows exactly how getting rid of the linearity ($\Theta\cdot X$) allows for non-linear classification boundaries and hence the regions with high probability do not extend indefinitely. In this case all points with high probability are close to our observations, so in principle they should "look" like our observations.&lt;/p&gt;
&lt;p&gt;A SVM with a Gaussian kernel can't accomplish the extremely complicated tasks that deep neural networks can, but an idea could be to find a way to implement a non-linear kernel between the last hidden layer and the output layer. This discussion is outside the of scope of this article, but hopefully I will find the time to look into it and write about my findings.&lt;/p&gt;
&lt;p&gt;Another solution to the above discussed issues lies in a completely different perspective, instead of trying to model the conditional probability, try to model the joint probability with generative models. These models should capture the underlying "context" of our observations and not only what makes them different.  This fundamental difference allows generative algorithms to do things which are impossible for a DNN. Such as producing never seen examples which have a striking resemblance to original observations, and even more to tune the context of these examples. A super nice &lt;a href="https://houxianxu.github.io/assets/project/dfcvae"&gt;demonstration&lt;/a&gt; is the generation of never seen faces where the degree of smiling and sunglasses is tuned.&lt;/p&gt;
&lt;h2&gt;Adios&lt;/h2&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/blog/tech/ml-pyapp/dog_developer.jpg" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;Well that took much more work than I expected. I hope you enjoyed reading this blog post and got excited about deep learning.&lt;/p&gt;
&lt;p&gt;You can find the code &lt;a href="https://gist.github.com/rragundez/9399f28a96541e00d02d23f2e3b86338"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any other questions just ping me in twitter &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="http://www.evolvingai.org/files/DNNsEasilyFooled_cvpr15.pdf"&gt;Deep Neural Networks are Easily Fooled&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1710.08864.pdf"&gt;One pixel attack for fooling deep neural networks&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;a class="footnote-backref" href="#fnref2:2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;This should be the case not only for Deep Learning models but all models in general. I increasingly see pseudo Data Scientist making outrageous claims or using models with a one-fits-all mentality. I understand there are juniors in the organizations but that's why you should have a strong Lead Data Scientist to provide guidance or hire GoDataDriven to make your team blossom, not only on their technical abilities but also in their mentality when attacking a problem.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;a class="footnote-backref" href="#fnref2:3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1412.6572.pdf"&gt;Explaining and harnessing adversarial examples&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;For the demonstration I decided to train on all the data since the dataset is so small (150 observations). In the deep neural network case I will use a much larger dataset and a test set.&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;It is known that no activation function can lead to exploiting activations values which in turn affect the convergence of the Deep Neural Network.&amp;#160;&lt;a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;I don't like cats.&amp;#160;&lt;a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:8"&gt;
&lt;p&gt;This is taking into account the intercept into the coefficients and adding a unit to layer $i$ with an activation of 1.&amp;#160;&lt;a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:9"&gt;
&lt;p&gt;If you were to use an activation function here is where you need to be careful that activation stay in the codomain of activation function. Since we cannot exactly reconstruct the previous layer we cannot be sure that the pseudo inverse will yield values which are outside the codomain therefore generating an exception. I tried a little bit with the &lt;code&gt;tanh&lt;/code&gt; activation function but at least for me it was not straight forward.&amp;#160;&lt;a class="footnote-backref" href="#fnref:9" title="Jump back to footnote 9 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:10"&gt;
&lt;p&gt;This is because of the Taylor expansion of the exponential function.&amp;#160;&lt;a class="footnote-backref" href="#fnref:10" title="Jump back to footnote 10 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="deep learning"></category><category term="python"></category><category term="adversarial attacks"></category><category term="scikit-learn"></category><category term="neural networks"></category><category term="support vector machines"></category><category term="classification"></category></entry><entry><title>Senior Data Scientist @ Unilever</title><link href="/2017-11-01-data-scientist-unilever.html" rel="alternate"></link><published>2017-11-01T00:00:00+01:00</published><updated>2017-11-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-11-01:/2017-11-01-data-scientist-unilever.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a senior data scientist for Unilever.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked developing a fuzzy name matching algorithm for entity data of all countries within the Unilever market. Data coming from different sources has been unavoidably duplicated. The goal was to create golden records which will be enriched from all matching ones. This is a known problem since already with 1 million records yields a cartesian product of 10^12 comparisons, which is unfeasible. I was able to produce a high performance approach which mixed machine learning, distributed computing and highly optimized algorithms, this approach yield a run-time of 1.5hrs for ~10 million records across 50 countries. The algorithm was put in place in production by data engineers.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Spark"></category><category term="Python"></category><category term="C++"></category><category term="Cython"></category><category term="Jupyter"></category><category term="TF-IDF"></category><category term="n-grams"></category><category term="Azure"></category><category term="ssh"></category><category term="git"></category></entry><entry><title>Machine Learning Application Skeleton</title><link href="/ml-pyapp.html" rel="alternate"></link><published>2017-08-23T00:00:00+02:00</published><updated>2017-08-23T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-08-23:/ml-pyapp.html</id><summary type="html">&lt;p&gt;The need of the business to interact and understand the output from custom built machine learning models is increasing, here I provide an application skeleton to do just that with your Python made models.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this blog post I provide an overview of a Python skeleton application I made. This skeleton can help you bridge the gap between your model and a machine learning application.&lt;/p&gt;
&lt;p&gt;For example, you can use your existing Flask application, import it in &lt;code&gt;run_app.py&lt;/code&gt; as &lt;code&gt;app&lt;/code&gt;, and this will add the production ready features of &lt;a href="http://gunicorn.org/"&gt;Gunicorn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/rragundez/app-skeleton"&gt;Take me to the code&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Why bother?&lt;/h3&gt;
&lt;p&gt;The times when business saw machine learning models as black boxes with no hope of understanding are long gone.&lt;/p&gt;
&lt;p&gt;It use to be that the data analytics or data science department of a company produced results in a silo kind of environment. Little or no interaction took place between these departments and the business side making the decisions (marketing, sales, client support, etc.). Advice coming from machine learning models consisted of reports, which were nice to have if they supported ideas from the business.&lt;/p&gt;
&lt;p&gt;&lt;img style="float: left;" src="/images/blog/tech/ml-pyapp/cat_peeking.jpg" width="350" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;As data driven decisions demonstrated their value, the business side started peeking behind the curtain.&lt;/p&gt;
&lt;p&gt;Paper/files reports have been substituted by static reporting dashboards, which themselves are being replaced by interactive ones. The business end users want to interact with the models, understand why certain predictions are made and evenmore, they want to be capable of performing predictions on the fly (imagine simultaneously having a customer on the phone and updating the probabilities of him/her buying certain products, or a marketing department tuning campaigns themselves depending on regional features).&lt;/p&gt;
&lt;p&gt;In short, I had some time during a rainy weekend and a GDD Friday&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;, already did something similar for a client and I think it is important to bring machine learning models to the business side.&lt;/p&gt;
&lt;p&gt;Also, as a bonus they will stop bothering you every time they need insights or a slightly different prediction.&lt;/p&gt;
&lt;h3&gt;What's in the goody bag?&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Template to extend a &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; application using &lt;a href="http://gunicorn.org/"&gt;Gunicorn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This allows the application to be run in a more production ready environment (multiple workers and threads for example). In &lt;a href="http://docs.gunicorn.org/en/stable/settings.html"&gt;here&lt;/a&gt; you can find a complete list of all the possible &lt;a href="http://gunicorn.org/"&gt;Gunicorn&lt;/a&gt; settings. I added the possibility to use some of them as command line arguments. Some relevant ones are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;host&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workers&lt;/code&gt; - define number of workers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;threads&lt;/code&gt; - number of threads on each worker.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;daemon&lt;/code&gt; - run application in the background.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;access-logfile&lt;/code&gt; - save access logs to a file.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;forwarded-allow-ips&lt;/code&gt; - list allowed IP addresses.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dummy application which demonstrates how to ingest several types of &lt;a href="https://www.w3schools.com/html/html_form_input_types.asp"&gt;user inputs&lt;/a&gt; into your Python application.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Dummy Application" src="/images/blog/tech/ml-pyapp/dummy.png"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Debug mode which (similar to Flask) will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run a single process&lt;/li&gt;
&lt;li&gt;logging to debug level&lt;/li&gt;
&lt;li&gt;restart process on code change&lt;/li&gt;
&lt;li&gt;reload html and jinja templates on change&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dockerfile template to containerize the application.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Docker whale" src="/images/blog/tech/ml-pyapp/docker.png"&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interactive application which runs a classifier model, outputs predictions and information about the machine learning model.&lt;/p&gt;
&lt;p&gt;&lt;img src="/images/blog/tech/ml-pyapp/iris_prediction.png" width="520"&gt;
&lt;img src="/images/blog/tech/ml-pyapp/iris_insights.png" width="800"&gt;
&lt;img src="/images/blog/tech/ml-pyapp/iris_performance.png" width="580"&gt;&lt;/p&gt;
&lt;p&gt;The model can be run by using the UI or by directly making a post request to the endpoint.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A more complete description, a set of instructions and the code can be found in &lt;a href="https://github.com/rragundez/app-skeleton"&gt;this repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note: I also include a &lt;code&gt;setup.py&lt;/code&gt; file that you should use to install your package used in the application.&lt;/p&gt;
&lt;h3&gt;Adios&lt;/h3&gt;
&lt;p&gt;If you structure your project following the &lt;a href="https://blog.godatadriven.com/how-to-start-a-data-science-project-in-python"&gt;advice&lt;/a&gt; from &lt;a href="https://godatadriven.com/players/henk-griffioen"&gt;Henk Griffioen&lt;/a&gt; (A.K.A. El Chicano), the integration of this ML application skeleton to your project should be straight forward.&lt;/p&gt;
&lt;p&gt;&lt;img style="float: right;" src="/images/blog/tech/ml-pyapp/dog_developer.jpg" hspace="20"&gt;&lt;/p&gt;
&lt;p&gt;I hope this work can help you bring your models into a machine learning application, it certainly helped and will help me in the future. You can find the code &lt;a href="https://github.com/rragundez/app-skeleton"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any other questions just ping me in twitter &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;One Friday a month when we get to do whatever we want, it is awesome.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tech"></category><category term="python"></category><category term="flask"></category><category term="docker"></category><category term="gunicorn"></category><category term="front-end"></category></entry><entry><title>GoDataDriven Go video</title><link href="/2017-07-01-godatadriven-go.html" rel="alternate"></link><published>2017-07-01T00:00:00+02:00</published><updated>2017-07-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-07-01:/2017-07-01-godatadriven-go.html</id><summary type="html">&lt;p&gt;Had fun making the GoDataDriven Go video.&lt;/p&gt;</summary><content type="html">&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/fva1H-w8XdU?rel=0&amp;amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;</content><category term="extras"></category><category term="godatadriven"></category></entry><entry><title>Senior Data Scientist @ KPN</title><link href="/2017-07-01-data-scientist-kpn.html" rel="alternate"></link><published>2017-06-01T00:00:00+02:00</published><updated>2017-06-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-06-01:/2017-07-01-data-scientist-kpn.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a senior data scientist for biggest telecom company in The Netherlands, KPN.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked in the commercial analytics department of KPN (Telecom). I had several roles, I was doing the work of a senior data scientist by giving advice and direction to several projects, at the same time he helped the analytics team build better models. In addition he built a tool where analysts could easily extract insights from the predictions, specially for the predictive drivers of classification models. Such insights are in production and are used to guide marketing campaigns.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="R"></category><category term="Python"></category><category term="Javascript"></category><category term="Jupyter"></category><category term="RandomForest"></category><category term="ssh"></category><category term="ForestFloor"></category><category term="git"></category><category term="Teradata"></category><category term="Flask"></category><category term="Gunicorn"></category><category term="Jenkins"></category></entry><entry><title>Senior Data Scientist @ Nederlandse Energie Maatschappij</title><link href="/2017-05-01-data-scientist-nle.html" rel="alternate"></link><published>2017-05-01T00:00:00+02:00</published><updated>2017-05-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-05-01:/2017-05-01-data-scientist-nle.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for the Dutch energy company (Nederlandse Energie Maatschappij).&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this project I was responsible for adding a model to an existing Spark pipeline. This model assigns customer conversion probabilities to different price offering strategies. The type of model does not exist in Spark, therefore a customized implementation was built which could integrate seemingly to the already existing SparkML pipeline.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Spark"></category><category term="Python"></category><category term="Pandas"></category><category term="ssh"></category><category term="git"></category><category term="S3"></category><category term="PyMC3"></category><category term="SparkML"></category></entry><entry><title>Facebook's Prophet: Forecasting Stores Transactions</title><link href="/prophet-quicklook.html" rel="alternate"></link><published>2017-02-25T00:00:00+01:00</published><updated>2017-02-25T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-02-25:/prophet-quicklook.html</id><summary type="html">&lt;p&gt;Quick look into the Prophet API for predicting the number of transactions in a shop.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://blog.godatadriven.com/prophet-quicklook"&gt;This post was originally published in the GoDataDriven blog&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Yesterday &lt;a href="https://godatadriven.com/players/giovanni-lanzani"&gt;Giovanni&lt;/a&gt;, our Chief Scientist, mentioned this recently released (2 days ago in &lt;a href="https://github.com/facebookincubator/prophet"&gt;github&lt;/a&gt;) open source forecasting API by Facebook’s Core Data Science team, so I decided to give it a try during one of our famous GDD Fridays.&lt;/p&gt;
&lt;p&gt;In Prophet's own words: "&lt;a href="https://facebookincubator.github.io/prophet/"&gt;Prophet&lt;/a&gt; is a procedure for forecasting time series data. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers". Prophet's algorithm explanation can be found in this &lt;a href="https://facebookincubator.github.io/prophet/static/prophet_paper_20170113.pdf"&gt;article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Prophet offers a R and Python API, I used the Pythton API of course.&lt;/p&gt;
&lt;h2&gt;Why bother?&lt;/h2&gt;
&lt;p&gt;The data belongs to a customer for which models are alreading in production. I wanted to see how Prophet's forecasts behave using the same data we use in one of these models developed by &lt;a href="https://godatadriven.com/players/rogier-vandergeer"&gt;Rogier&lt;/a&gt; and me.&lt;/p&gt;
&lt;p&gt;In reality, the forecast of the number of transactions in a shop is used as a part of an ensemble to predict products sales. Since Prophet does not accept features, it would be unfair to make a comparison at that level since, for example, price is a very important factor.&lt;/p&gt;
&lt;h2&gt;Data: transactions and holidays&lt;/h2&gt;
&lt;p&gt;The data is of a current client, therefore I won't be disclosing any details of it.&lt;/p&gt;
&lt;p&gt;Our models make forecasts for different shops of this company. In particular I took 2 shops, one which contains the easiest transactions to predict from all shops, and another with a somewhat more complicated history.&lt;/p&gt;
&lt;p&gt;The data consists of real transactions since 2014. Data is daily with the target being the number of transactions executed during a day. There are missing dates in the data when the shop closed, for example New Year's day and Christmas.&lt;/p&gt;
&lt;p&gt;The holidays provided to the API are the same I use in our model. They contain from school vacations or large periods, to single holidays like Christmas Eve. In total, the data contains 46 different holidays.&lt;/p&gt;
&lt;h2&gt;Code&lt;/h2&gt;
&lt;p&gt;If the data is in a nice format (this is a big if), Prophet provides a very easy to use API. In particular, once I cleaned, aggregated and dumped the data, the calculation consisted on these two pieces of code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tseries&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predict_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;holidays&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Prophet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;holidays&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;holidays&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# train on data until 3 days before&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tseries&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tseries&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict_date&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))])&lt;/span&gt;
    &lt;span class="n"&gt;forecast&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_future_dataframe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;periods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;forecast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;forecast&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;predict_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ds&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;yhat&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;

&lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;pred_holidays&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;date&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;date_range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;2016-1-1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;2016-12-31&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tseries_shop&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;pred_holidays&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tseries_shop&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;holidays&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;holidays&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pred_holidays&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                       &lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ds&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;how&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;inner&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;suffixes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;_hol&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The forecast is done for 2016 with and without holiday data. Our production model gets trained daily via an &lt;a href="https://airflow.incubator.apache.org/"&gt;Airflow&lt;/a&gt; job, to make a fair comparison, I train a Prophet model for each date in 2016 using the data until 3 days before the date to be forecast. This is because the order for a product needs to be submitted 2 days before, which means it uses the data available until then.&lt;/p&gt;
&lt;p&gt;Prophet leveraged the full capacity of my laptop using all 8 cores. The calculation took around 45 minutes per shop, which means a single day with or without holidays takes around 4 seconds.&lt;/p&gt;
&lt;h2&gt;Metric&lt;/h2&gt;
&lt;p&gt;The metric I used to measure the forecast performance is the &lt;a href="https://en.wikipedia.org/wiki/Coefficient_of_determination"&gt;coefficient of determination ($R^2$ score)&lt;/a&gt;. The $R^2$ score gives the proportion of the variance in the data that is explained by the forecast. A perfect forecast will give 1.0 and a constant prediction for every day will give 0.0.&lt;/p&gt;
&lt;h2&gt;Easy shop: Widushop&lt;/h2&gt;
&lt;p&gt;Using &lt;a href="https://godatadriven.com/players/vincent-warmerdam"&gt;Vincent's&lt;/a&gt; awesome &lt;a href="http://tnaas.com/"&gt;Pokemon name generator&lt;/a&gt;, I will call this shop Widushop. This is the transaction data for the 3 years,&lt;/p&gt;
&lt;p&gt;&lt;img alt="Widushop transaction history" src="/images/blog/tech/prophet-quicklook/widushop_history.png"&gt;&lt;/p&gt;
&lt;p&gt;The image shows a very similar pattern each year. Also, it shows some days that are definitely holidays where transactions drop or increase dramatically.&lt;/p&gt;
&lt;p&gt;Prophet produces a very accurate forecast, it scores 0.89 without using holidays and &lt;strong&gt;0.94&lt;/strong&gt; using holidays. Below I show a comparison between the transactions (truth) and the forecast using holidays.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Widushop forecast" src="/images/blog/tech/prophet-quicklook/widushop_forecast.png"&gt;&lt;/p&gt;
&lt;p&gt;Pretty nice!&lt;/p&gt;
&lt;p&gt;Overall it produces very good results, for holidays seems to overestimate (look at Christmas Eve), nevertheless that can be tuned by the parameter &lt;code&gt;holidays.prior.scale&lt;/code&gt; as stated in the &lt;a href="https://facebookincubator.github.io/prophet/docs/holiday_effects.html"&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Difficult shop: Qumashop&lt;/h2&gt;
&lt;p&gt;This time the shop name generated is Qumashop. The transaction history of Qumashop is more chaotic than the one for Widushop. Below I show the transaction history of Qumashop.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Qumashop transaction history" src="/images/blog/tech/prophet-quicklook/qumashop_history.png"&gt;&lt;/p&gt;
&lt;p&gt;Holidays have a much greater impact. Look at that peak in the middle of July, this is a known event that draws a lot of people to the city (it is in the holidays data). Notice that transactions in 2016 are considerably higher than other years, specially from July until September. Not catching this uprise trend would mean losing a lot of potential sales.&lt;/p&gt;
&lt;p&gt;This time the Prophet forecast is not as good as for Widushop giving 0.64 without holiday data and a solid &lt;strong&gt;0.82&lt;/strong&gt; using holidays. Below I show a comparison between the transactions (truth) and the forecast using holidays for Qumashop.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Qumashop forecast" src="/images/blog/tech/prophet-quicklook/qumashop_forecast.png"&gt;&lt;/p&gt;
&lt;p&gt;Look at that! very nice. I am specially happy that it catched the mentioned trend between July and September. Moreover, the residuals on the week following the big peak in July, the second week in September and the two weeks at the end of October are too high.
Remember that in practice this is just a model of an ensemble, is better to have a little overall bigger residual that can reduced by other models, than having weeks with such big errors.&lt;/p&gt;
&lt;p&gt;Perhaps the forecasts for the week after the big peak in July can improve by introducing a &lt;a href="https://facebookincubator.github.io/prophet/docs/trend_changepoints.html"&gt;&lt;code&gt;changepoint&lt;/code&gt;&lt;/a&gt; the last day of the peak holiday week.&lt;/p&gt;
&lt;h2&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;Prophet's out of the box results were impressive. The quality of the forecasts are comparable with those from our current model in production for these 2 shops.&lt;/p&gt;
&lt;p&gt;Calculations were parallelized over all 8 cores of my machine. Training plus prediction time for each date was about 4 seconds.&lt;/p&gt;
&lt;p&gt;The API is ridiculously easy to use and the documentation seems sufficient.&lt;/p&gt;
&lt;p&gt;For what I can read in the &lt;a href="https://facebookincubator.github.io/prophet/docs/quick_start.html"&gt;documentation&lt;/a&gt;, Prophet does not accept features. Nevertheless, Prophet's forecasts can be part of an ensemble that produces predictions with a higher granularity.&lt;/p&gt;
&lt;p&gt;It would be interesting to make a comparison for every shop. I was surprised by the result on the difficult shop history.&lt;/p&gt;
&lt;p&gt;There are also several hyperparameters that would be interesting to look into, among several, these in particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://facebookincubator.github.io/prophet/docs/forecasting_growth.html"&gt;&lt;code&gt;cap&lt;/code&gt;&lt;/a&gt;: the maximum possible value of the target.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://facebookincubator.github.io/prophet/docs/trend_changepoints.html"&gt;&lt;code&gt;changepoint&lt;/code&gt;&lt;/a&gt;: indicate where do we expect an abrupt change in the time series.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://facebookincubator.github.io/prophet/docs/trend_changepoints.html"&gt;&lt;code&gt;changepoint_prior_scale&lt;/code&gt;&lt;/a&gt;: related to how strongly should the model adjust to trends.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://facebookincubator.github.io/prophet/docs/holiday_effects.html"&gt;&lt;code&gt;holidays_prior_scale&lt;/code&gt;&lt;/a&gt;: adjust the importance of holiday effects.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://facebookincubator.github.io/prophet/docs/uncertainty_intervals.html"&gt;&lt;code&gt;interval_width&lt;/code&gt;&lt;/a&gt;: sets the uncertainty interval to produce a confidence interval around the forecast. This could be very useful for monitoring the quality of the forecast. Defaults to 80%.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To anyone starting a project using time-series for forecasting, I really recommend taking a close look at this tool.&lt;/p&gt;
&lt;p&gt;Great work &lt;a href="https://facebookincubator.github.io/prophet/"&gt;Prophet!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I hope this blog has been helpful and please bother me &lt;a href="https://twitter.com/rragundez"&gt;@rragundez&lt;/a&gt; with your results of playing around with Prophet.&lt;/p&gt;</content><category term="tech"></category><category term="time-series"></category><category term="prophet"></category><category term="regression"></category></entry><entry><title>Data Scientist / Engineer @ Knab</title><link href="/2017-02-01-data-scientist-engineer-knab.html" rel="alternate"></link><published>2017-02-01T00:00:00+01:00</published><updated>2017-02-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-02-01:/2017-02-01-data-scientist-engineer-knab.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist and data engineer for the Knab bank.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked in the insurance department building and productionizing a ranking algorithm. This model matches the best insurances to the customer needs and characteristics. I wrapped the model in an API to make it accessible to a future application in production, this implies continuous integration and automation of ETL processes. As a second project I built and automated ETL and cross-reference process that required encryption due to security measures. Both projects were used to provide a solution in production.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="data engineering"></category><category term="Python"></category><category term="Pandas"></category><category term="Airflow"></category><category term="HDFS"></category><category term="S3"></category><category term="Postgres"></category><category term="ssh"></category><category term="git"></category><category term="Flask"></category><category term="gpg encryption"></category><category term="Jupyter"></category></entry><entry><title>Data Scientist @ Bakkersland</title><link href="/2016-08-01-data-scientist-bakkersland.html" rel="alternate"></link><published>2016-08-01T00:00:00+02:00</published><updated>2016-08-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-08-01:/2016-08-01-data-scientist-bakkersland.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for Bakkersland.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked as the data scientist optimizing an existing shelf-replenisher prediction system for shops across The Netherlands, such system is used in production to maximize profit and minimize waste. I also developed a customer predictive algorithm to use as an input to improve the shelf-replenisher predictions. In addition I migrated all scheduled jobs to Airflow, and helped built a dashboard to monitor the model performance in production.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Python"></category><category term="Pandas"></category><category term="Airflow"></category><category term="R"></category><category term="dplyr"></category><category term="Shiny"></category><category term="Postgres"></category><category term="ssh"></category><category term="git"></category><category term="FBProphet"></category></entry><entry><title>Data Scientist @ GoDataDriven</title><link href="/2016-07-04-data-scientist-godatadriven.html" rel="alternate"></link><published>2016-07-04T00:00:00+02:00</published><updated>2016-07-04T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-07-04:/2016-07-04-data-scientist-godatadriven.html</id><summary type="html">&lt;p&gt;Started working as a data scientist for GoDataDriven.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Apart from working with customers Rodrigo has been involved in the
development of the GoDataDriven accelerator training program. He has
been the trainer of several topics: data science with python, making things
scale, time-series and deep learning.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="scikit-learn"></category><category term="PyMC3"></category><category term="Pandas"></category><category term="Keras"></category></entry><entry><title>Data Science Summit Europe</title><link href="/2016-06-06-data-science-summit-europe.html" rel="alternate"></link><published>2016-06-06T00:00:00+02:00</published><updated>2016-06-06T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-06-06:/2016-06-06-data-science-summit-europe.html</id><summary type="html">&lt;p&gt;Gave a face recognition workshop with opencv and tensorflow.&lt;/p&gt;</summary><content type="html"></content><category term="workshop"></category><category term="deep learning"></category><category term="opencv"></category><category term="face recognition"></category><category term="keras"></category><category term="transfer learning"></category><category term="tensorflow"></category></entry><entry><title>Seminar Data Science &amp; Sports 2016</title><link href="/2016-04-07-seminar-data-science-and-sports.html" rel="alternate"></link><published>2016-04-07T00:00:00+02:00</published><updated>2016-04-07T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-04-07:/2016-04-07-seminar-data-science-and-sports.html</id><summary type="html">&lt;p&gt;Presented predicting Sports Outcomes based on Rankings.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Tools for Predicting Sports Outcomes based on Rankings&lt;/p&gt;
&lt;p&gt;https://www.universiteitleiden.nl/nieuws/2016/04/data-science-and-sports-a-smart-combination&lt;/p&gt;</content><category term="talk"></category><category term="elo rating"></category><category term="sports"></category><category term="R"></category></entry><entry><title>PyData Amsterdam</title><link href="/2016-03-12-pydata-amsterdam.html" rel="alternate"></link><published>2016-03-12T00:00:00+01:00</published><updated>2016-03-12T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-03-12:/2016-03-12-pydata-amsterdam.html</id><summary type="html">&lt;p&gt;Presented building a face recognition system with OpenCV.&lt;/p&gt;</summary><content type="html">&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/MDaZtJPv3Ik?rel=0&amp;amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;https://pydata.org/amsterdam2016/schedule/presentation/21/index.html&lt;/p&gt;
&lt;p&gt;Building a face recognition system with OpenCV&lt;/p&gt;
&lt;p&gt;Description
In this tutorial we will create a face recognition application from scratch, it will provide you hands-on experience on the basics of Face Recognition. We will use the OpenCV library which makes the tutorial accessible to beginners. Together, we'll go from building our face dataset to recognizing faces in a live video. If time permits we will use this face recognition system to classify banking da&lt;/p&gt;
&lt;p&gt;Abstract
Building a live face recognition system in the blink of a very slow eye&lt;/p&gt;
&lt;p&gt;In this hands-on tutorial we will build a live face recognition system from scratch with the use of the OpenCV methods. Since face recognition is the main goal of this tutorial we will form teams of 2-3 people and recognize the faces in a live feed. We will make use of the OpenCV computer vision and machine learning library. OpenCV includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to:&lt;/p&gt;
&lt;p&gt;Detect Faces
Recognize Faces
Identify Objects
Classify human actions in videos
Track camera movement
Track moving objects&lt;/p&gt;
&lt;p&gt;Extract 3D models of objects
Produce 3D point clouds from stereo cameras
Stitch images together to produce a high resolution image of an entire scene
Find similar images from an image database
Remove red eyes from images taken using flash
Follow eye movements
OpenCV is a great tool to have in hand when dealing with data problems related to media. In the case you want to create your own tuned algorithm, due to its simplicity it lets you use the majority of your resources on developing the algorithm itself and not on the manipulation of the data, which can be a pain in the … .&lt;/p&gt;
&lt;p&gt;OpenCV is not limited to Python but has C++, C, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS.&lt;/p&gt;
&lt;p&gt;Syllabus
Basics of image and video manipulations
Let’s take a picture
OpenCV and Pyplot formats: GBR vs RGB
Let’s take a video
Write and read picture from file
Detecting faces
Using OpenCV methods to recognize faces in a video
Draw output rectangle to recognize face
Let’s take a video
Extract the face detected
Build our data set
Defining image and video manipulation classes
Normalizing the dataset
Creating the directory skeleton with our data
Take pictures of each person in the team
Train the face recognition algorithm
Brief in-depth description of algorithm
Use dataset to train classification algorithm
Recognize faces in a live video feed
Apply trained model on detected face in live feed
Remarks on other OpenCV face recognition methods
Playing with the OpenCV face recognition algorithm on banking data
Requiered Packages to follow hands-on
cv2 (OpenCV)
Numpy
os
matpotlib
sys
time
IPython.display&lt;/p&gt;
&lt;p&gt;To get the most of the tutorial is highly recommended to have OpenCV installed since compilation from source is required. See you there!&lt;/p&gt;</content><category term="talk"></category><category term="opencv"></category><category term="face recognition"></category><category term="python"></category><category term="classification"></category></entry><entry><title>Data Scientist @ Leiden University / Infostrada</title><link href="/2016-01-01-data-scientist-leiden-university-infostrada.html" rel="alternate"></link><published>2016-01-01T00:00:00+01:00</published><updated>2016-01-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-01-01:/2016-01-01-data-scientist-leiden-university-infostrada.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for a joint project between Lieden University and Infostrada.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Rodrigo was the lead data scientist in the development of a machine
learning algorithm on top of a multiplayer Elo ranking system to assess the
expected performance of athletes in different sports. The algorithm was
capable of calculating probabilities of outcomes in matches, predicting
placings in tournaments and identificating future sport talents.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="R"></category><category term="RStudio"></category><category term="Shiny"></category><category term="dplyr"></category><category term="MySQL"></category></entry><entry><title>Data Scientist @ Qualogy</title><link href="/2015-12-01-data-scientist-qualogy.html" rel="alternate"></link><published>2015-12-01T00:00:00+01:00</published><updated>2015-12-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2015-12-01:/2015-12-01-data-scientist-qualogy.html</id><summary type="html">&lt;p&gt;Started working as a data scientist for Qualogy.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Most of the time Rodrigo worked at the client, internally he took the role of
presenting what the newly data science department was about to the rest
of the company. He also created with two more colleagues a Cloudera
Hadoop workshop which was given during a week to IT employees from
other departments.&lt;/p&gt;
&lt;p&gt;He also worked on the development of a face recognition system in the
context of a smart-office. He was the core developer of the machine
learning algorithm and also worked on cleaning and preparing the image
data. He also contributed to a user interface prototype.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Python"></category><category term="Flask"></category><category term="Pandas"></category><category term="OpenCV"></category><category term="HTML"></category><category term="CSS"></category><category term="git"></category><category term="ssh"></category></entry><entry><title>PhD in Theoretical Physics</title><link href="/2015-12-01-phd-theoretical-physics.html" rel="alternate"></link><published>2015-12-01T00:00:00+01:00</published><updated>2015-12-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2015-12-01:/2015-12-01-phd-theoretical-physics.html</id><summary type="html">&lt;p&gt;Obtained a PhD in theoretical physics from Delft Technical University.&lt;/p&gt;</summary><content type="html"></content><category term="study"></category><category term="physics"></category><category term="quantum computing"></category><category term="one-dimensional systems"></category></entry></feed>