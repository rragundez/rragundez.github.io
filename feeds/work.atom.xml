<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Rodrigo Agundez - work</title><link href="/" rel="alternate"></link><link href="/feeds/work.atom.xml" rel="self"></link><id>/</id><updated>2019-01-15T00:00:00+01:00</updated><entry><title>Collaborator/committer @ Keras</title><link href="/2019-01-15-keras-preprocessing-collaborator.html" rel="alternate"></link><published>2019-01-15T00:00:00+01:00</published><updated>2019-01-15T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2019-01-15:/2019-01-15-keras-preprocessing-collaborator.html</id><summary type="html">&lt;p&gt;Part of the core development team of the keras preprocessing component of the Keras framework.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Keras is one of the most used Deep Learning frameworks and I am a part of the core development team for the keras preprocessing component of the framework. The responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Participate in the discussions concerning the API.&lt;/li&gt;
&lt;li&gt;Discuss and assess on how to solve issues from the community.&lt;/li&gt;
&lt;li&gt;Solve issues from the community by offering advice or building / coding a solution.&lt;/li&gt;
&lt;li&gt;Review/merge pull requests from contributors.&lt;/li&gt;
&lt;li&gt;Improve the framework by building software features.&lt;/li&gt;
&lt;/ul&gt;</content><category term="data science"></category><category term="deep learning"></category><category term="keras"></category></entry><entry><title>Data Lead @ Schiphol Royal Group</title><link href="/2018-10-01-data-scientist-schiphol-group.html" rel="alternate"></link><published>2018-10-01T00:00:00+02:00</published><updated>2018-10-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-10-01:/2018-10-01-data-scientist-schiphol-group.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as the data lead for Schiphol Royal Group.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Schiphol group manages the Schiphol airport in Amsterdam. I am the technical lead of the Data Science and Engineering Lab which consist of 20 people. Some of my responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solve technical impediments hands-on or via discussions.&lt;/li&gt;
&lt;li&gt;Establish best practices in the team, technical and nontechnical.&lt;/li&gt;
&lt;li&gt;Make decisions regarding the teamâ€™s roadmap.&lt;/li&gt;
&lt;li&gt;Together with the business perform technical assessment.&lt;/li&gt;
&lt;li&gt;Lead technical hiring efforts and interviews.&lt;/li&gt;
&lt;li&gt;Review pull requests sporadically to share knowledge.&lt;/li&gt;
&lt;li&gt;Intervene in projects whenever is required.&lt;/li&gt;
&lt;li&gt;Technical advice at the beginning and during each project.&lt;/li&gt;
&lt;li&gt;Decisions about the data lake and advanced analytics platform.&lt;/li&gt;
&lt;li&gt;Technical exposure of the team to the organization.&lt;/li&gt;
&lt;/ul&gt;</content><category term="data science"></category><category term="deep learning"></category><category term="spark"></category><category term="pandas"></category><category term="git"></category><category term="numpy"></category><category term="python"></category><category term="azure"></category><category term="databricks"></category><category term="keras"></category><category term="tensorflow"></category></entry><entry><title>Lead Data Scientist for Nspire project @ KPN</title><link href="/2018-03-01-data-scientist-kpn-nspire.html" rel="alternate"></link><published>2018-03-01T00:00:00+01:00</published><updated>2018-03-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-03-01:/2018-03-01-data-scientist-kpn-nspire.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a lead data scientist for the Nspire project in KPN.&lt;/p&gt;</summary><content type="html">&lt;p&gt;NSPIRE is a mobile application available for download which makes recommendations about what to do in your leisure time. I joined the project since almost the beginning and I was responsible for building the artificial intelligence part of it. Some of my responsibilities were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advise on decisions about the application and technologies used.&lt;/li&gt;
&lt;li&gt;Work closely with an editorial office to fine-tuning the AI system.&lt;/li&gt;
&lt;li&gt;Implement several recommendation models.&lt;/li&gt;
&lt;li&gt;Taking the AI part of the application all the way from development to production.&lt;/li&gt;
&lt;li&gt;Supervise several data scientist during the time of the project.&lt;/li&gt;
&lt;li&gt;Share knowledge and communicate with internal data scientists such that they could take up the project after I leave.&lt;/li&gt;
&lt;/ul&gt;</content><category term="data science"></category><category term="scikit-learn"></category><category term="Flask"></category><category term="Pandas"></category><category term="git"></category><category term="Tensorflow"></category><category term="Keras"></category><category term="numpy"></category><category term="python"></category></entry><entry><title>Senior Data Scientist @ Unilever</title><link href="/2017-11-01-data-scientist-unilever.html" rel="alternate"></link><published>2017-11-01T00:00:00+01:00</published><updated>2017-11-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-11-01:/2017-11-01-data-scientist-unilever.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a senior data scientist for Unilever.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked developing a fuzzy name matching algorithm for entity data of all countries within the Unilever market. Data coming from different sources has been unavoidably duplicated. The goal was to create golden records which will be enriched from all matching ones. This is a known problem since already with 1 million records yields a cartesian product of 10^12 comparisons, which is unfeasible. I was able to produce a high performance approach which mixed machine learning, distributed computing and highly optimized algorithms, this approach yield a run-time of 1.5hrs for ~10 million records across 50 countries. The algorithm was put in place in production by data engineers.&lt;/p&gt;</content><category term="data science"></category><category term="Spark"></category><category term="Python"></category><category term="C++"></category><category term="Cython"></category><category term="Jupyter"></category><category term="TF-IDF"></category><category term="n-grams"></category><category term="Azure"></category><category term="ssh"></category><category term="git"></category></entry><entry><title>Senior Data Scientist @ KPN</title><link href="/2017-07-01-data-scientist-kpn.html" rel="alternate"></link><published>2017-06-01T00:00:00+02:00</published><updated>2017-06-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-06-01:/2017-07-01-data-scientist-kpn.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a senior data scientist for biggest telecom company in The Netherlands, KPN.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked in the commercial analytics department of KPN (Telecom). I had several roles, I was doing the work of a senior data scientist by giving advice and direction to several projects, at the same time he helped the analytics team build better models. In addition he built a tool where analysts could easily extract insights from the predictions, specially for the predictive drivers of classification models. Such insights are in production and are used to guide marketing campaigns.&lt;/p&gt;</content><category term="data science"></category><category term="R"></category><category term="Python"></category><category term="Javascript"></category><category term="Jupyter"></category><category term="RandomForest"></category><category term="ssh"></category><category term="ForestFloor"></category><category term="git"></category><category term="Teradata"></category><category term="Flask"></category><category term="Gunicorn"></category><category term="Jenkins"></category></entry><entry><title>Senior Data Scientist @ Nederlandse Energie Maatschappij</title><link href="/2017-05-01-data-scientist-nle.html" rel="alternate"></link><published>2017-05-01T00:00:00+02:00</published><updated>2017-05-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-05-01:/2017-05-01-data-scientist-nle.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for the Dutch energy company (Nederlandse Energie Maatschappij).&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this project I was responsible for adding a model to an existing Spark pipeline. This model assigns customer conversion probabilities to different price offering strategies. The type of model does not exist in Spark, therefore a customized implementation was built which could integrate seemingly to the already existing SparkML pipeline.&lt;/p&gt;</content><category term="data science"></category><category term="Spark"></category><category term="Python"></category><category term="Pandas"></category><category term="ssh"></category><category term="git"></category><category term="S3"></category><category term="PyMC3"></category><category term="SparkML"></category></entry><entry><title>Data Scientist / Engineer @ Knab</title><link href="/2017-02-01-data-scientist-engineer-knab.html" rel="alternate"></link><published>2017-02-01T00:00:00+01:00</published><updated>2017-02-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-02-01:/2017-02-01-data-scientist-engineer-knab.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist and data engineer for the Knab bank.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked in the insurance department building and productionizing a ranking algorithm. This model matches the best insurances to the customer needs and characteristics. I wrapped the model in an API to make it accessible to a future application in production, this implies continuous integration and automation of ETL processes. As a second project I built and automated ETL and cross-reference process that required encryption due to security measures. Both projects were used to provide a solution in production.&lt;/p&gt;</content><category term="data science"></category><category term="data engineering"></category><category term="Python"></category><category term="Pandas"></category><category term="Airflow"></category><category term="HDFS"></category><category term="S3"></category><category term="Postgres"></category><category term="ssh"></category><category term="git"></category><category term="Flask"></category><category term="gpg encryption"></category><category term="Jupyter"></category></entry><entry><title>Data Scientist @ Bakkersland</title><link href="/2016-08-01-data-scientist-bakkersland.html" rel="alternate"></link><published>2016-08-01T00:00:00+02:00</published><updated>2016-08-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-08-01:/2016-08-01-data-scientist-bakkersland.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for Bakkersland.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked as the data scientist optimizing an existing shelf-replenisher prediction system for shops across The Netherlands, such system is used in production to maximize profit and minimize waste. I also developed a customer predictive algorithm to use as an input to improve the shelf-replenisher predictions. In addition I migrated all scheduled jobs to Airflow, and helped built a dashboard to monitor the model performance in production.&lt;/p&gt;</content><category term="data science"></category><category term="Python"></category><category term="Pandas"></category><category term="Airflow"></category><category term="R"></category><category term="dplyr"></category><category term="Shiny"></category><category term="Postgres"></category><category term="ssh"></category><category term="git"></category><category term="FBProphet"></category></entry><entry><title>Data Scientist @ GoDataDriven</title><link href="/2016-07-04-data-scientist-godatadriven.html" rel="alternate"></link><published>2016-07-04T00:00:00+02:00</published><updated>2016-07-04T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-07-04:/2016-07-04-data-scientist-godatadriven.html</id><summary type="html">&lt;p&gt;Started working as a data scientist for GoDataDriven.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Apart from working with customers Rodrigo has been involved in the
development of the GoDataDriven accelerator training program. He has
been the trainer of several topics: data science with python, making things
scale, time-series and deep learning.&lt;/p&gt;</content><category term="data science"></category><category term="scikit-learn"></category><category term="PyMC3"></category><category term="Pandas"></category><category term="Keras"></category></entry><entry><title>Data Scientist @ Leiden University / Infostrada</title><link href="/2016-01-01-data-scientist-leiden-university-infostrada.html" rel="alternate"></link><published>2016-01-01T00:00:00+01:00</published><updated>2016-01-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-01-01:/2016-01-01-data-scientist-leiden-university-infostrada.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for a joint project between Lieden University and Infostrada.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Rodrigo was the lead data scientist in the development of a machine
learning algorithm on top of a multiplayer Elo ranking system to assess the
expected performance of athletes in different sports. The algorithm was
capable of calculating probabilities of outcomes in matches, predicting
placings in tournaments and identificating future sport talents.&lt;/p&gt;</content><category term="data science"></category><category term="R"></category><category term="RStudio"></category><category term="Shiny"></category><category term="dplyr"></category><category term="MySQL"></category></entry><entry><title>Data Scientist @ Qualogy</title><link href="/2015-12-01-data-scientist-qualogy.html" rel="alternate"></link><published>2015-12-01T00:00:00+01:00</published><updated>2015-12-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2015-12-01:/2015-12-01-data-scientist-qualogy.html</id><summary type="html">&lt;p&gt;Started working as a data scientist for Qualogy.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Most of the time Rodrigo worked at the client, internally he took the role of
presenting what the newly data science department was about to the rest
of the company. He also created with two more colleagues a Cloudera
Hadoop workshop which was given during a week to IT employees from
other departments.&lt;/p&gt;
&lt;p&gt;He also worked on the development of a face recognition system in the
context of a smart-office. He was the core developer of the machine
learning algorithm and also worked on cleaning and preparing the image
data. He also contributed to a user interface prototype.&lt;/p&gt;</content><category term="data science"></category><category term="Python"></category><category term="Flask"></category><category term="Pandas"></category><category term="OpenCV"></category><category term="HTML"></category><category term="CSS"></category><category term="git"></category><category term="ssh"></category></entry></feed>