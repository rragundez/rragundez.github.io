<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Rodrigo Agundez - work</title><link href="/" rel="alternate"></link><link href="/feeds/work.atom.xml" rel="self"></link><id>/</id><updated>2021-07-01T00:00:00+02:00</updated><entry><title>Director of Data Science @ adidas</title><link href="/2021-07-01-director-data-science-adidas.html" rel="alternate"></link><published>2021-07-01T00:00:00+02:00</published><updated>2021-07-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2021-07-01:/2021-07-01-director-data-science-adidas.html</id><summary type="html">&lt;p&gt;Director of Data Science at adidas, responsible for all Trading Sciences global products with focus on our digital channels.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I am currently the Director of Data Science at adidas, responsible for all
Trading Sciences global products with focus on our digital channels. My 3
core responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set the strategic technical vision for Data Science products, both in
terms of performance/added-value and rollout of the products to
different markets;&lt;/li&gt;
&lt;li&gt;Highly technical strategic and operational phases of developing a
Machine Learning platform for Data Scientists in AWS;&lt;/li&gt;
&lt;li&gt;People manager of 3 teams of internal and external Data Scientists
and Machine Learning engineers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some extra details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Manage contracting and strategy with external partners (e.g. AWS);&lt;/li&gt;
&lt;li&gt;In charge of +1M yearly budget for external capacity;&lt;/li&gt;
&lt;li&gt;Added value impact of +50M;&lt;/li&gt;
&lt;li&gt;Technical involvement, sometimes hands-on to teach and explain
technical concepts that the team needs to adapt;&lt;/li&gt;
&lt;li&gt;Start a collaboration with AWS ML Labs for a high-risk / high-reward
cutting edge Data Science use case based on graph neural
networks;&lt;/li&gt;
&lt;li&gt;Lead the creation of hackathons to solve out-of-the-box business
problems;&lt;/li&gt;
&lt;li&gt;Establish DRY principles for code and data;&lt;/li&gt;
&lt;li&gt;Very strong collaboration with the Data Platform team to ensure the
adidas platform components address Data Science requirements.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="SageMaker"></category><category term="AWS"></category><category term="deep learning"></category><category term="PyTorch"></category><category term="MLOps"></category><category term="Spark"></category></entry><entry><title>Lead Data Scientist @ VodafoneZiggo</title><link href="/2020-02-01-lead-data-scientist-vodafoneziggo.html" rel="alternate"></link><published>2020-02-01T00:00:00+01:00</published><updated>2020-02-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2020-02-01:/2020-02-01-lead-data-scientist-vodafoneziggo.html</id><summary type="html">&lt;p&gt;Lead Data Scientist of a team of 14 people in VodafoneZiggo.&lt;/p&gt;</summary><content type="html">&lt;p&gt;VodafoneZiggo is one of the biggest telecom companies in The Netherlands, it provides internet, mobile and video on demand services. I worked as the Lead Data Scientist for the Advanced Analytics department with 16 people, a combination of Data Scientist and Data Engineers. Some of my accountabilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find, assess and kickstart use cases in the company;&lt;/li&gt;
&lt;li&gt;Elevate the WoW of the team with best practices;&lt;/li&gt;
&lt;li&gt;Guide the Cloud Migration to AWS and cloud cost forecasting;&lt;/li&gt;
&lt;li&gt;Assess 3rd party AI partnerships in the company;&lt;/li&gt;
&lt;li&gt;Hiring of internal and external Data Scientists and Engineers;&lt;/li&gt;
&lt;li&gt;Technical roadmap for the team;&lt;/li&gt;
&lt;li&gt;Point of contact for other teams in VodafoneZiggo (e.g. BICC);&lt;/li&gt;
&lt;li&gt;1 on 1 hands-on development sessions with the team;&lt;/li&gt;
&lt;li&gt;Data acquisition strategy;&lt;/li&gt;
&lt;li&gt;Delivery of technical products;&lt;/li&gt;
&lt;li&gt;Developed the AI environment in the cloud;&lt;/li&gt;
&lt;li&gt;GDPR related procedures to ensure compliance in our use cases;&lt;/li&gt;
&lt;li&gt;Establish DRY principles for code and data.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="AWS"></category><category term="deep learning"></category><category term="GDPR"></category><category term="cloud strategy"></category><category term="AI hiring"></category></entry><entry><title>Lead of Artificial Intelligence @ Talpa Network</title><link href="/2019-01-15-lead-artificial-intelligence-talpa-network.html" rel="alternate"></link><published>2019-10-01T00:00:00+02:00</published><updated>2019-10-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2019-10-01:/2019-01-15-lead-artificial-intelligence-talpa-network.html</id><summary type="html">&lt;p&gt;I started and built the AI department in the company.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Talpa Network is one of the biggest media companies in The Netherlands with many brands offering content over radio, television, magazines, Ecommerce, podcasts, video-on-demand, and radio-on-demand. I started and built the AI department in the company. Some of my accountabilities were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hire and built the team using my vast network;&lt;/li&gt;
&lt;li&gt;Built the AI development platform;&lt;/li&gt;
&lt;li&gt;Kickstart AI related projects focused on value creation;&lt;/li&gt;
&lt;li&gt;Assess AI partnerships for all brands;&lt;/li&gt;
&lt;li&gt;Point-of-contact for the team;&lt;/li&gt;
&lt;li&gt;Create AI awareness in the company;&lt;/li&gt;
&lt;li&gt;Collaborate daily with the Data and DevOps team to create an
end-to-end AI strategy;&lt;/li&gt;
&lt;li&gt;Part of the architecture board;&lt;/li&gt;
&lt;li&gt;GDPR related procedures to ensure compliance in our use cases;&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="AI"></category><category term="AWS"></category><category term="Spark"></category><category term="JupyterHub"></category><category term="AI Roadmap"></category><category term="CI/CD"></category><category term="IaC"></category><category term="PyData stack"></category><category term="3rd party AI partnerships"></category><category term="AI hiring."></category></entry><entry><title>Collaborator / committer @ Keras</title><link href="/2019-10-01-keras-preprocessing-collaborator.html" rel="alternate"></link><published>2019-01-15T00:00:00+01:00</published><updated>2019-01-15T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2019-01-15:/2019-10-01-keras-preprocessing-collaborator.html</id><summary type="html">&lt;p&gt;Part of the core development team of the keras preprocessing component of the Keras framework.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Keras is one of the most used Deep Learning frameworks and I am a part of the core development team for the keras preprocessing component of the framework. The responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Participate in the discussions concerning the API.&lt;/li&gt;
&lt;li&gt;Discuss and assess on how to solve issues from the community.&lt;/li&gt;
&lt;li&gt;Solve issues from the community by offering advice or building / coding a solution.&lt;/li&gt;
&lt;li&gt;Review/merge pull requests from contributors.&lt;/li&gt;
&lt;li&gt;Improve the framework by building software features.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="deep learning"></category><category term="keras."></category></entry><entry><title>Data Lead @ Schiphol Royal Group</title><link href="/2018-10-01-data-scientist-schiphol-group.html" rel="alternate"></link><published>2018-10-01T00:00:00+02:00</published><updated>2018-10-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-10-01:/2018-10-01-data-scientist-schiphol-group.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as the data lead for Schiphol Royal Group.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Schiphol group manages the Schiphol airport in Amsterdam. I am the technical lead of the Data Science and Engineering Lab which consist of 20 people. Some of my responsibilities are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solve technical impediments hands-on or via discussions.&lt;/li&gt;
&lt;li&gt;Establish best practices in the team, technical and nontechnical.&lt;/li&gt;
&lt;li&gt;Make decisions regarding the teamâ€™s roadmap.&lt;/li&gt;
&lt;li&gt;Together with the business perform technical assessment.&lt;/li&gt;
&lt;li&gt;Lead technical hiring efforts and interviews.&lt;/li&gt;
&lt;li&gt;Review pull requests sporadically to share knowledge.&lt;/li&gt;
&lt;li&gt;Intervene in projects whenever is required.&lt;/li&gt;
&lt;li&gt;Technical advice at the beginning and during each project.&lt;/li&gt;
&lt;li&gt;Decisions about the data lake and advanced analytics platform.&lt;/li&gt;
&lt;li&gt;Technical exposure of the team to the organization.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="deep learning"></category><category term="spark"></category><category term="pandas"></category><category term="git"></category><category term="numpy"></category><category term="python"></category><category term="azure"></category><category term="databricks"></category><category term="keras"></category><category term="tensorflow"></category></entry><entry><title>Lead Data Scientist for Nspire project @ KPN</title><link href="/2018-03-01-data-scientist-kpn-nspire.html" rel="alternate"></link><published>2018-03-01T00:00:00+01:00</published><updated>2018-03-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2018-03-01:/2018-03-01-data-scientist-kpn-nspire.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a lead data scientist for the Nspire project in KPN.&lt;/p&gt;</summary><content type="html">&lt;p&gt;NSPIRE is a mobile application available for download which makes recommendations about what to do in your leisure time. I joined the project since almost the beginning and I was responsible for building the artificial intelligence part of it. Some of my responsibilities were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Advise on decisions about the application and technologies used.&lt;/li&gt;
&lt;li&gt;Work closely with an editorial office to fine-tuning the AI system.&lt;/li&gt;
&lt;li&gt;Implement several recommendation models.&lt;/li&gt;
&lt;li&gt;Taking the AI part of the application all the way from development to production.&lt;/li&gt;
&lt;li&gt;Supervise several data scientist during the time of the project.&lt;/li&gt;
&lt;li&gt;Share knowledge and communicate with internal data scientists such that they could take up the project after I leave.&lt;/li&gt;
&lt;/ul&gt;</content><category term="work"></category><category term="data science"></category><category term="scikit-learn"></category><category term="Flask"></category><category term="Pandas"></category><category term="git"></category><category term="Tensorflow"></category><category term="Keras"></category><category term="numpy"></category><category term="python"></category></entry><entry><title>Senior Data Scientist @ Unilever</title><link href="/2017-11-01-data-scientist-unilever.html" rel="alternate"></link><published>2017-11-01T00:00:00+01:00</published><updated>2017-11-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-11-01:/2017-11-01-data-scientist-unilever.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a senior data scientist for Unilever.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked developing a fuzzy name matching algorithm for entity data of all countries within the Unilever market. Data coming from different sources has been unavoidably duplicated. The goal was to create golden records which will be enriched from all matching ones. This is a known problem since already with 1 million records yields a cartesian product of 10^12 comparisons, which is unfeasible. I was able to produce a high performance approach which mixed machine learning, distributed computing and highly optimized algorithms, this approach yield a run-time of 1.5hrs for ~10 million records across 50 countries. The algorithm was put in place in production by data engineers.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Spark"></category><category term="Python"></category><category term="C++"></category><category term="Cython"></category><category term="Jupyter"></category><category term="TF-IDF"></category><category term="n-grams"></category><category term="Azure"></category><category term="ssh"></category><category term="git"></category></entry><entry><title>Senior Data Scientist @ KPN</title><link href="/2017-07-01-data-scientist-kpn.html" rel="alternate"></link><published>2017-06-01T00:00:00+02:00</published><updated>2017-06-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-06-01:/2017-07-01-data-scientist-kpn.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a senior data scientist for biggest telecom company in The Netherlands, KPN.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked in the commercial analytics department of KPN (Telecom). I had several roles, I was doing the work of a senior data scientist by giving advice and direction to several projects, at the same time he helped the analytics team build better models. In addition he built a tool where analysts could easily extract insights from the predictions, specially for the predictive drivers of classification models. Such insights are in production and are used to guide marketing campaigns.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="R"></category><category term="Python"></category><category term="Javascript"></category><category term="Jupyter"></category><category term="RandomForest"></category><category term="ssh"></category><category term="ForestFloor"></category><category term="git"></category><category term="Teradata"></category><category term="Flask"></category><category term="Gunicorn"></category><category term="Jenkins"></category></entry><entry><title>Senior Data Scientist @ Nederlandse Energie Maatschappij</title><link href="/2017-05-01-data-scientist-nle.html" rel="alternate"></link><published>2017-05-01T00:00:00+02:00</published><updated>2017-05-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-05-01:/2017-05-01-data-scientist-nle.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for the Dutch energy company (Nederlandse Energie Maatschappij).&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this project I was responsible for adding a model to an existing Spark pipeline. This model assigns customer conversion probabilities to different price offering strategies. The type of model does not exist in Spark, therefore a customized implementation was built which could integrate seemingly to the already existing SparkML pipeline.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Spark"></category><category term="Python"></category><category term="Pandas"></category><category term="ssh"></category><category term="git"></category><category term="S3"></category><category term="PyMC3"></category><category term="SparkML"></category></entry><entry><title>Data Scientist / Engineer @ Knab</title><link href="/2017-02-01-data-scientist-engineer-knab.html" rel="alternate"></link><published>2017-02-01T00:00:00+01:00</published><updated>2017-02-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2017-02-01:/2017-02-01-data-scientist-engineer-knab.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist and data engineer for the Knab bank.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked in the insurance department building and productionizing a ranking algorithm. This model matches the best insurances to the customer needs and characteristics. I wrapped the model in an API to make it accessible to a future application in production, this implies continuous integration and automation of ETL processes. As a second project I built and automated ETL and cross-reference process that required encryption due to security measures. Both projects were used to provide a solution in production.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="data engineering"></category><category term="Python"></category><category term="Pandas"></category><category term="Airflow"></category><category term="HDFS"></category><category term="S3"></category><category term="Postgres"></category><category term="ssh"></category><category term="git"></category><category term="Flask"></category><category term="gpg encryption"></category><category term="Jupyter"></category></entry><entry><title>Data Scientist @ Bakkersland</title><link href="/2016-08-01-data-scientist-bakkersland.html" rel="alternate"></link><published>2016-08-01T00:00:00+02:00</published><updated>2016-08-01T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-08-01:/2016-08-01-data-scientist-bakkersland.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for Bakkersland.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I worked as the data scientist optimizing an existing shelf-replenisher prediction system for shops across The Netherlands, such system is used in production to maximize profit and minimize waste. I also developed a customer predictive algorithm to use as an input to improve the shelf-replenisher predictions. In addition I migrated all scheduled jobs to Airflow, and helped built a dashboard to monitor the model performance in production.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Python"></category><category term="Pandas"></category><category term="Airflow"></category><category term="R"></category><category term="dplyr"></category><category term="Shiny"></category><category term="Postgres"></category><category term="ssh"></category><category term="git"></category><category term="FBProphet"></category></entry><entry><title>Data Scientist @ GoDataDriven</title><link href="/2016-07-04-data-scientist-godatadriven.html" rel="alternate"></link><published>2016-07-04T00:00:00+02:00</published><updated>2016-07-04T00:00:00+02:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-07-04:/2016-07-04-data-scientist-godatadriven.html</id><summary type="html">&lt;p&gt;Started working as a data scientist for GoDataDriven.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Apart from working with customers Rodrigo has been involved in the
development of the GoDataDriven accelerator training program. He has
been the trainer of several topics: data science with python, making things
scale, time-series and deep learning.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="scikit-learn"></category><category term="PyMC3"></category><category term="Pandas"></category><category term="Keras"></category></entry><entry><title>Data Scientist @ Leiden University / Infostrada</title><link href="/2016-01-01-data-scientist-leiden-university-infostrada.html" rel="alternate"></link><published>2016-01-01T00:00:00+01:00</published><updated>2016-01-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2016-01-01:/2016-01-01-data-scientist-leiden-university-infostrada.html</id><summary type="html">&lt;p&gt;As a consultant from GoDataDriven working as a data scientist for a joint project between Lieden University and Infostrada.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Rodrigo was the lead data scientist in the development of a machine
learning algorithm on top of a multiplayer Elo ranking system to assess the
expected performance of athletes in different sports. The algorithm was
capable of calculating probabilities of outcomes in matches, predicting
placings in tournaments and identificating future sport talents.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="R"></category><category term="RStudio"></category><category term="Shiny"></category><category term="dplyr"></category><category term="MySQL"></category></entry><entry><title>Data Scientist @ Qualogy</title><link href="/2015-12-01-data-scientist-qualogy.html" rel="alternate"></link><published>2015-12-01T00:00:00+01:00</published><updated>2015-12-01T00:00:00+01:00</updated><author><name>Rodrigo Agundez</name></author><id>tag:None,2015-12-01:/2015-12-01-data-scientist-qualogy.html</id><summary type="html">&lt;p&gt;Started working as a data scientist for Qualogy.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Most of the time Rodrigo worked at the client, internally he took the role of
presenting what the newly data science department was about to the rest
of the company. He also created with two more colleagues a Cloudera
Hadoop workshop which was given during a week to IT employees from
other departments.&lt;/p&gt;
&lt;p&gt;He also worked on the development of a face recognition system in the
context of a smart-office. He was the core developer of the machine
learning algorithm and also worked on cleaning and preparing the image
data. He also contributed to a user interface prototype.&lt;/p&gt;</content><category term="work"></category><category term="data science"></category><category term="Python"></category><category term="Flask"></category><category term="Pandas"></category><category term="OpenCV"></category><category term="HTML"></category><category term="CSS"></category><category term="git"></category><category term="ssh"></category></entry></feed>