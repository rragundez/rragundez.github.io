{"pages":[{"title":"Rod360","text":"Section","tags":"pages","url":"/pages/rod360.html"},{"title":"Elitist shuffle for recommendation systems","text":"This post was originally published in the GoDataDriven blog In today's high pace user experience it is expected that new recommended items appear every time the user opens the application, but what to do if your recommendation system runs every hour or every day? I give a solution that you can plug & play without having to re-engineer your recommendation system. The common practice to update recommended items is to have the recommendation system re-score the available items every period of time T . This means that for a whole period T , the end-user faces the same content in the application's entry screen. In today's high pace user experience if T is even a few hours, let alone a day, the user can get bored of the same content displayed every time it opens the application during the period T . There can be many ways this scenario can happen but imagine the user opens the application and doesn't like the recommended items and is too lazy or busy to scroll or search for something else. If the user opens the application again some minutes later to find exactly the same content as before this might have a big (negative) impact on the retention for this user. An obvious solution to this problem is to shuffle the content in such a way that it remains relevant to the user while new content appears on the screen each time the user re-opens the application. Below there are two screen shots from my YouTube account a couple of seconds apart with no interaction, just clicking the refresh button. We can notice several things: Content is still relevant. Content is not the same. Some content has changed position. Some new content has appeared. This can be because YouTube re-scores items in a very short time T or runs an online algorithm. 1 What can you do to achieve something similar if your recommendation system has a T in the order of hours? In this blog post, I propose a simple solution based on a non-uniform shuffling algorithm that you can basically plug & play or build on top off. Example scenario Suppose you have 10,000 items in total that can be recommended to your user, you run the recommendation system over all the items and those 10,000 items get ranked in order of relevance of the content. 2 The application shows 5 items on the entry screen. The first time the user opens the application after the re-scoring process the top 5 ranked items are shown. It is decided that from now on (based on user control groups, investigation, AB testing, etc.) until the next re-scoring process the entry screen should not be the same every time and remain relevant for the user. Based on an investigation from the data scientist it turns out that somewhat relevant items appear until item 100. 3 Then the idea is to somehow shuffle those 100 items such that the top 5 items shown are still relevant but not the same. In order for the figures of this blog post to be more readable and understandable, I'll use a hypothetical threshold of 20 items and not 100. Fisherâ€“Yates shuffle / uniform Shuffling in Python is a very common action and can be done using the random module which contains the shuffle function . >>> print ( inspect . getsource ( random . shuffle )) def shuffle ( self , x , random = None ): \"\"\"Shuffle list x in place, and return None. Optional argument random is a 0-argument function returning a random float in [0.0, 1.0); if it is the default None, the standard random.random will be used. \"\"\" if random is None : randbelow = self . _randbelow for i in reversed ( range ( 1 , len ( x ))): # pick an element in x[:i+1] with which to exchange x[i] j = randbelow ( i + 1 ) x [ i ], x [ j ] = x [ j ], x [ i ] else : _int = int for i in reversed ( range ( 1 , len ( x ))): # pick an element in x[:i+1] with which to exchange x[i] j = _int ( random () * ( i + 1 )) x [ i ], x [ j ] = x [ j ], x [ i ] This shuffle method uses the optimized Fisherâ€“Yates algorithm introduced by Richard Durstenfield in 1964 which reduced the running time from \\(O(n&#94;2)\\) to \\(O(n)\\) . By default the algorithm produces a uniform shuffle of an array in which every permutation is equally likely. This means that an item has equal probability to end up in any position. 4 Below you can find an animation of the results of the random.shuffle default algorithm. I show the initial position of an item in red and the expected probability distribution of landing in any position after 5000 shuffling simulations. This type of shuffle is not beneficial for our purpose as there is the same probability of the least recommended item to appear on top than any other, this is definitely not the way to go since we can end up with very poor recommendations on top. Fisherâ€“Yates shuffle / non-uniform Notice that the shuffle function shown above has the parameter random which is described in the docstring as follows: def shuffle ( self , x , random = None ): \"\"\"Shuffle list x in place, and return None. Optional argument random is a 0-argument function returning a random float in [0.0, 1.0); if it is the default None, the standard random.random will be used. \"\"\" If you try to understand the Fisher-Yates algorithm and then look at the source code, you notice that the random parameter affects the location where intermediate swaps will happen and that the effect of a non-uniform random distribution parameter is quite difficult to predict. It kept my mind busy for some hours. I tried different functions to pass to the random parameter but they all behaved strange and unexpected in one way or another, for example let's try a \\(\\beta\\) distribution such that the first draws are very likely to be swapped with elements at the end (higher probability near 1.0). 5 The simulation below uses the \\(\\beta\\) -distribution as the random parameter. This approach does allocate higher probabilities towards higher positions for higher initially ranked items, but the distribution is highly non-symmetrical and very different for different initial positions. I find it surprising that at some point the initial position does not have the maximum probability. 6 Also, I find it very hard to explain the relation between the given \\(\\beta\\) -distribution and the resulting probability distribution . I played with the parameters and other distributions but still noticed strange behavior. This will make it quite difficult to explain the expected impact on the recommended items to the user. Elitist shuffle This is actually a simple approach, I shuffle the items by choosing items with a weighted probability (this is the same as sampling from a multinomial distribution without replacement). I won't go into the details but the function numpy.random.choice with the parameter replace=False does what we want, it is just a matter of choosing the appropriate weight probabilities. In this case I choose to set the weights by transforming the reverse position as np.linspace(1, 0, num=len(items), endpoint=False) . 7 Then I introduce a parameter called inequality as a knob to tune the weight probability difference between positions. >>> print ( inspect . getsource ( elitist_shuffle )) def elitist_shuffle ( items , inequality ): \"\"\"Shuffle array with bias over initial ranks A higher ranked content has a higher probability to end up higher ranked after the shuffle than an initially lower ranked one. Args: items (numpy.array): Items to be shuffled inequality (int/float): how biased you want the shuffle to be. A higher value will yield a lower probabilty of a higher initially ranked item to end up in a lower ranked position in the sequence. \"\"\" weights = np . power ( np . linspace ( 1 , 0 , num = len ( items ), endpoint = False ), inequality ) weights = weights / np . linalg . norm ( weights , ord = 1 ) return np . random . choice ( items , size = len ( items ), replace = False , p = weights ) As the simulation below shows, this approach gives a clearer picture of what's going on and it let us tune the algorithm using the inequality parameter according to the requirements of our application. This is an animation based on 5000 simulations with inequality=10 From the animation we notice: The maximum probability remains on the initial position. Probability decays monotonically with the distance from the initial position. The distribution is non-symmetrical but smoother than the previous example. Higher ranked items have a higher chance of being moved from their initial position. A big win is that the inequality parameter has a direct understandable impact on the resulting distributions, want higher items to be more probable to remain on top? Increase inequality. In addition, the behavior translates into the desired functionality: Top content would still be relevant after shuffle. Content is not the same. Some content has changed position. Some new content has appeared. Drawback The elitist_shuffle function is much slower than np.random.shuffle , but still fast for a common application. Coming back to the example scenario where the items to shuffle are 100 , the elitist_shuffle function takes around 1.8ms . If this is too slow for you I would recommend to first try numba with the no_python parameter enabled and then if necessary try a Cython implementation. AdiÃ³s As final remarks, I advise you to: First, discuss with your team if you need a feature like this. There are applications where the user might be expecting to find the same items it saw last time. Perhaps trigger this behavior if more than x seconds have passed. Add the recommendation system scores to the calculation of the weight probabilities. This could just be setting the weights to the scores before the exponentiation and \\(l&#94;1\\) normalization ðŸ˜‰. As always I'm happy to discuss and answer any questions, just ping me on twitter @rragundez . You can find the code here . Some other user similar to me might have done some actions that affect my recommendations, or simply not clicking on the items affects my own recommendations. â†© There can be an exploration-exploitation step after. â†© It can also be a dynamic threshold based on the scores from the recommendation system. â†© This algorithm is also used by numpy . â†© This is what we want since the algorithm first swaps elements from the end (look at reversed in line 303 . â†© It is not a matter of increasing the number of simulations. I did that and found the same behavior. â†© You might be tempted to use np.arange(len(items), 0, step=-1) which is not numerically robust for a big inequality parameter. â†© if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"/elitist-shuffle.html"},{"title":"Multi-threshold Neuron Model","text":"This post was originally published in the GoDataDriven blog Inspired by a new biological scientific research, I propose, build and train a Deep Neural Network using a novel neuron model. Figure 0. Schematic diagrams of two neuron models. (Central-threshold neuron) The model on the left is the current employed model in artificial neural networks where the input signals are propagated if their sum is above a certain threshold. (Multi-threshold neuron) In contrast, in the right I show the new proposed model where each input signal goes through a threshold filter before summing them. In this blog post I construct and train a simple Deep Neural Network based on a novel experimental driven neuron model proposed last year (2017) in July. This blog is separated as follows: Scientific background Summarize the article that lead me to this idea and explain some of the theory. Concepts Relate Deep Learning technical concepts to Neuroscience concepts mentioned in the paper. Approximations Introduce approximations I will make on the multi-threshold neuron model. Discussion Overview of mathematical and Deep Learning implications as a consequence of the multi-threshold neuron model. Model & training Tensorflow implementation and training of a simple fully-connected Deep Neural Network using the multi-threshold neuron model. Results Briefly show and explain results from training and testing the proposed model vs the commonly used one in Deep Neural Networks (DNNs). Scientific background S. Sardi et al. published in July last year (2017) an experimental work in Nature scientific reports which contradicts a century old assumption about how neurons work. The work was a combined effort between the Physics, Life Sciences and Neuroscience departments of Bar-Ilan University in Tel Aviv, Israel. The authors proposed three different neuron models which they put to the test with different types of experiments. They describe each neuron model with, what they call, neuronal equations . Figure 1. Schematic representation of a neuron. The signal in a neural network flows from a neuron's axon to the dendrites of another one. That is, the signal in any neuron is incoming from its dendrites and outgoing to its axon. Below I describe two of these neuron models in the paper. In particular the commonly used neuron model which I call \"central-threshold\" and the neuron model proposal in this blog \"multi-threshold\". Central-threshold neuron This is the current adopted computational description of neurons ( artificial neurons ), and the corner stone of Deep Learning. \"A neuron consists of a unique centralized excitable mechanism\". The signal reaching the neuron consists of a linear sum of the incoming signals from all the dendrites connected to the neuron, if this sum reaches a threshold, a spike signal is propagated through the axon to the other connected neurons. The neuronal equation of this model is: $$I = \\Theta\\Big(\\sum_{i=1}&#94;NW_i\\cdot I_i - t\\Big)$$ where \\(i\\) : identifies any connected neuron \\(N\\) : total number of connected neurons \\(W_i\\) : is the weight (strength) associated to the connection with neuron \\(i\\) \\(I_i\\) : is the signal coming out of neuron \\(i\\) \\(t\\) : is the centralized single neuron threshold \\(\\Theta\\) : is the Heaviside step function \\(I\\) : signal output from the neuron Multi-threshold neuron In this model the centralized threshold ( \\(\\Theta\\) ) is removed. The neuron can be independently excited by any signal coming from a dendrite given that this signal is above a threshold. This model describes a multi-threshold neuron and the mathematical representation can be written as: $$I=\\sum_{i=1}&#94;N\\Theta(W_i\\cdot I_i - t_i)$$ where \\(i\\) : identifies any connected neuron \\(N\\) : total number of connected neurons \\(W_i\\) : is the weight (strength) associated to the connection with neuron \\(i\\) \\(I_i\\) : is the signal coming out of neuron \\(i\\) \\(t_i\\) : is the threshold value for each neuron \\(i\\) \\(\\Theta\\) : is the Heaviside step function \\(I\\) : signal output from the neuron Study conclusion Based on their experiments the authors conclude that the multi-threshold neuron model explains best the data. The authors mention that the main reason for adopting the central-threshold neuron as the main model, is that technology did not allow for direct excitation of single neurons, which other model experiments require. Moreover, they state that these results could have been discovered using technology that existed since the 1980s. Concepts There are some main concepts in the Deep Learning domain that you should be familiar with before proceeding. If you are familiar with them skip this part. Artificial neuron A mathematical representation of a biological neuron. They are the corner stone of artificial neural networks and Deep Learning. The idea is that the artificial neuron receives input signals from other connected artificial neurons and via a non-linear transmission function emits a signal itself. Activation function The current understanding of a neuron is that it will transmit some signal only if the sum from incoming signals from other neurons exceeds a threshold. For an artificial neuron this threshold filter is applied via an activation function. There are many activation functions but the Rectified Linear unit (ReLu) is one of the most broadly used in the Deep Learning community, and it's the one I will use in this notebook. The mathematical definition of the function is: $$R(z) = max(0, z) = \\begin{cases} 0 &\\quad\\text{for } z\\leq0 \\\\ z &\\quad\\text{for } z > 0 \\end{cases}$$ You can check its implementation in the Tensorflow source code or in the Tensorflow playground code . Approximations I am a theoretical physicist and as such it's impossible for me to resist the spherical cow . Single threshold value The multi-threshold neuron model contains different threshold parameter values ( \\(t_i\\) ). Mathematically a threshold has the same effect if I take it as a constant and instead the input signal is moved up or down by the connecting weight parameters. Hence, the neuronal equation becomes: 1 $$I=\\sum_{i=1}&#94;N\\Theta(W_i\\cdot I_i - t)$$ ReLu activation function I'll replace the Heaviside step function ( \\(\\Theta\\) ) with threshold \\(t\\) by a Rectified Linear unit ( \\(\\mathcal{R}\\) ). $$I=\\sum_{i=1}&#94;N\\mathcal{R}(W_i\\cdot I_i)$$ In general any activation function could replace the Heaviside step function. Bias Notice that the proposed model equation contains no bias terms. I'll add a bias term to the equation since it's known to help neural networks fit better. It can also help with the threshold approximation, tuning the biases instead of the thresholds. $$I=\\sum_{i=1}&#94;N\\mathcal{R}(W_i\\cdot I_i) + b$$ Discussion The idea is to take the multi-threshold neuron model and try to write a Deep Learning implementation, a neural network consisting of multi-threshold neurons. Tensorflow is quite flexible and allows for writing user defined implementations. Backpropagation In order for my neural network to be trained I need backpropagation, this means that the derivative of whatever I introduce is necessary. Luckily, I'm not changing the activation function itself, I can just use the already derivative of the ReLu function in Tensorflow: $$\\frac{d}{dz}\\mathcal{R}(z)= \\begin{cases} 0 &\\quad\\text{for } z\\leq0 \\\\ 1 &\\quad\\text{for } z > 0 \\end{cases}$$ You can check it out in the Tensorflow source code or in the Tensorflow playground code . Tensor multiplication What I'm really changing is the architecture of the artificial neural network as seen in Figure 0, the activation function is no longer applied on the sum of all the inputs from the connected neurons, but instead on the input arriving from every single connected neuron. The sum operation is going from inside the activation function to outside of it: $$\\mathcal{R}\\Big(\\sum_{i=1}&#94;NW_i\\cdot I_i\\Big) \\rightarrow \\sum_{i=1}&#94;N\\mathcal{R}(W_i\\cdot I_i)$$ Do you see the implementation problem described by the equation above? In the central-threshold model (left equation) the input to the activation function \\(\\sum_iW_i\\cdot I_i\\) is exactly the dot product between vectors \\((W_1, W_2,\\dots,W_N)\\) and \\((I_1, I_2,\\dots,I_N)\\) and it's this fact which allows fast computation of input signals for many neurons and observations at once via a single matrix multiplication. In the multi-threshold model this is no longer possible. I think this will be the biggest challenge when coming up with an implementation which can be trained efficiently and fast. Example Suppose I have the following weight matrix connecting two neuron layers, the first layer has 3 neurons the second has 2: $$W= \\begin{bmatrix} 3 & -4 \\\\ -2& 2\\\\ 0& 4 \\end{bmatrix} $$ and that the output signal from the neurons in the first layer are $$I_0= \\begin{bmatrix} 2 & 5 & 1 \\end{bmatrix} $$ with bias terms $$b= \\begin{bmatrix} 2 & -1 \\end{bmatrix} $$ Using the standard central-threshold neuron model, the output signal of the second layer is: $$\\mathcal{R}\\Big(I_0\\cdot W + b\\Big) = \\mathcal{R}\\Big( \\begin{bmatrix} 2 & 5 & 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 3 & -4 \\\\ -2& 2\\\\ 0& 4 \\end{bmatrix} + \\begin{bmatrix} 2 & -1 \\end{bmatrix} \\Big) = $$ $$ \\mathcal{R}\\Big( \\begin{bmatrix} -2 & 5 \\end{bmatrix} \\Big) = \\begin{bmatrix} \\mathcal{R}(-2)& \\mathcal{R}(5) \\end{bmatrix} \\Big) = \\begin{bmatrix} 0 & 5 \\end{bmatrix} $$ In the case of the multi-threshold neuron model proposed the output is $$ [\\sum_{i=1}&#94;N\\mathcal{R}(W_{i1}\\cdot I_i) + b_1, \\sum_{i=1}&#94;N\\mathcal{R}(W_{i2}\\cdot I_i) + b_2]= $$ $$ \\begin{bmatrix} \\mathcal{R}(6) + \\mathcal{R}(-10) + \\mathcal{R}(0) + 2 & \\mathcal{R}(-8) + \\mathcal{R}(10) + \\mathcal{R}(4) -1 \\end{bmatrix} = \\begin{bmatrix} 8 & 13 \\end{bmatrix} $$ As the example shows, a fundamental difference is that in the multi-threshold case if any input output signal times the weight is positive then the output will be positive. This will greatly reduce the sparsity of the neurons firing throughout the network in comparison with the conventional central-threshold model. I don't know all the implications but I expect that it will be more difficult for individual neurons (or parts of the network) to singly address a specific feature, therefore in principle reducing overfitting. A known issue of most activation functions in Deep Neural Networks is the \"vanishing gradient problem\", it relates to the decreasing update value to the weights as the errors propagate through the network via backpropagation. In the standard central-threshold model the ReLu partially solves this problem by having a derivative equal to 1 if the neuron fires, this propagates the error without vanishing the gradient. On the other hand, if the neuron signal is negative and squashed by the ReLu (did not fire) the corresponding weights are not updated, since the ReLu derivate is zero i.e. neuron connections are not learning when the connecting neurons didn't fire. In the multi-threshold model, I expect this last issue to be reduced since sparsity reduces, more weights should be updated on each step in comparison with the central-threshold neuron. Model & training I first concentrate in replicating the example above using tensorflow , it contains two built-in related ReLu functions: relu_layer relu The relu_layer function already assumes a layer architecture with central-threshold neurons. The relu function on the other hand can operate on each entry of a tensor. import tensorflow as tf sess = tf . Session () b = tf . constant ([ 2 , - 1 ]) w = tf . constant ([[ 3 , - 2 , 0 ], [ - 4 , 2 , 4 ]]) I_0 = tf . constant ([ 2 , 5 , 1 ]) I_1 = tf . reduce_sum ( tf . nn . relu ( tf . multiply ( I_0 , w )), axis = 1 ) + b I_1 . eval ( session = sess ) >>> array ([ 8 , 13 ], dtype = int32 ) Notice that b and I_0 are one dimensional tensors, this allows me to take advantage of the tensorflow broadcasting feature. Using the code above I can then define a neural network layer consisting of multi-threshold neurons 2 . def multi_threshold_neuron_layer ( input_values , weights , b , activation = tf . nn . relu ): return tf . reduce_sum ( activation ( tf . multiply ( input_values , weights )), axis = 1 ) + b MNIST - 2 hidden layer multi-threshold neural network With this basic implementation, my goal was to see if the model is actually trainable. I just wanted to observe the loss decrease with each iteration. As you probably noticed, the multi_threshold_neuron_layer can only take 1 example at a time, this is the complication I mentioned, simple matrix multiplication taking several observations is no longer possible for now. In part II of the blog I hope to expand to a more efficient implementation. The multi-threshold neural network is then: # Construct model I_0 = tf . placeholder ( \"float\" , shape = ( input_size ,)) # input layer W_01 = tf . Variable ( tf . random_normal (( hidden_layers_sizes [ 0 ], input_size ))) b_1 = tf . Variable ( tf . random_normal (( hidden_layers_sizes [ 0 ],))) I_1 = multi_threshold_neuron_layer ( I_0 , W_01 , b_1 ) # 1st hidden layer W_12 = tf . Variable ( tf . random_normal (( hidden_layers_sizes [ 1 ], hidden_layers_sizes [ 0 ]))) b_2 = tf . Variable ( tf . random_normal (( hidden_layers_sizes [ 1 ],))) I_2 = multi_threshold_neuron_layer ( I_1 , W_12 , b_2 ) # 2nd hidden layer W_23 = tf . Variable ( tf . random_normal (( number_of_classes , hidden_layers_sizes [ 1 ]))) b_3 = tf . Variable ( tf . random_normal (( number_of_classes ,))) output = tf . transpose ( tf . matmul ( W_23 , tf . reshape ( I_2 , shape = ( - 1 , 1 )))) + b_3 # output layer # truth target = tf . placeholder ( \"float\" , shape = ( 1 , number_of_classes )) Using the digits MNIST data set I ran a comparison between a DNN using the conventional central-threshold neurons and the proposed multi-threshold neurons. 3 from tensorflow.examples.tutorials.mnist import input_data mnist = input_data . read_data_sets ( \"/tmp\" , one_hot = True ) Results It is trainable! I actually though this would just crash and burn so I was very happy to see that loss go down :). I calculated the cross-entropy loss and accuracy during training and final accuracy in a test set. It is very important to remember that to keep things fair the calculations for both models are using a batch of 1 observation. The training period ran for 4 epochs with a training set of 55000 observations . Normally the loss and accuracy is calculated over the batch, in this case that makes no sense 4 . Instead what I do is report the average loss and average accuracy over every 1100 observations 5 . The score of my model consisted of calculating the accuracy over a test set of 10000 observations . Training loss and accuracy There are many things that can be discussed from Figure 2 but here are the main points: Cross-entropy loss decreases with iterations which means the model is trainable. When the central-threshold model is performing well its loss is much lower than the multi-threshold . Notice that this is the case since the beginning of the training period, a sort of a shift. This could be because our images contain consistent white areas (edges) where the cross-entropy benefits from having sparse activations in our neural network. The multi-threshold model seems to be more robust against higher learning rates. Moreover, it seems to prefer higher learning rates. As I mentioned before I would expect the multi-threshold model to have less sparse activations which in turn should result in a faster learning 6 . This can be observed for learning rate .0005 and .001 . Test Accuracy Learning rate Central-threshold Multi-threshold 0.0005 0.8571 0.8757 0.001 0.8958 0.8879 0.005 0.2554 0.9085 0.01 0.1028 0.773 As seen in the training report above, the multi-threshold model seems to be more robust against higher learning rates. It could be that this is just a sort of shift and for even bigger learning rates it will show the same behavior as the central-threshold . The multi-threshold model does not overfit in these examples. Even more, for learning rate 0.005 it achieves a loss 2 orders of magnitude higher than the central-threshold but a higher accuracy in the test set. Adios This was a pretty fun blog to make. I have some final remarks: The proposed model is trainable, but I cannot say much of the specifics since that requires more investigation that I have not done. A very important point is that since at the moment I can only use batches of 1, the training time is painfully slow, definitely not something for realistic applications. Finally, I know that Figure 3 seems quite promising but let's not forget that this is done with a batch of a single observation. In part II of this blog I'll try to come up with the functionality of having more observations per update and use a convolutional layer to make a more realistic comparison. You can find the code here . If you have any other questions just ping me in twitter @rragundez . This is also happening in the current neural network implementations, since in reality there is no reason for different neurons to have the same threshold, nevertheless commonly a single activation function is used on all neurons. â†© It is a one line function, I know I know, but I can already sense there will be more to it later since this just works for a single input example. â†© Since at the moment the multi-threshold neuron model uses only a single example at a time, to make a fair comparison both DNN weights are updated on each example (batches of size 1), x, y = mnist.train.next_batch(1, shuffle=True) . â†© If you do that the accuracy and loss will be all over the place as it will be dependent on a single observation. This could make difficult to assess if the model is indeed getting better on each iteration by seeing the loss monotonically decrease. â†© You don't want this number to be too high since you expect an average lower loss and higher accuracy for observations at the end. If there are too many observations your standard deviation will increase and the reported average can be meaningless. â†© The weights of a neural network using relu activations where the neuron output is zero cannot learn because the back-propagated derivative is zero. â†© if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"/multi-threshold-neuron.html"},{"title":"Snowshoeing","text":"Snowshoeing in winter Bacon ipsum dolor amet spare ribs burgdoggen turducken shankle pork loin. Ham kevin meatball turducken, hamburger flank pancetta jerky andouille rump doner cow boudin jowl. Tri-tip cow turducken buffalo kielbasa boudin tail short loin jerky jowl pork chop fatback venison. Burgdoggen short ribs kevin pork frankfurter meatloaf. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Landjaeger cupim capicola sirloin ball tip, picanha turkey t-bone bresaola fatback biltong doner shoulder. Burgdoggen pork pig, turducken t-bone jerky rump frankfurter tongue buffalo turkey sausage leberkas. Jowl doner fatback venison biltong frankfurter pork cow pork belly pancetta ball tip ham hock sirloin short loin. Short ribs brisket beef ribs prosciutto bacon venison beef jowl cupim t-bone capicola meatball landjaeger. Tongue pork loin boudin chicken sirloin. Tri-tip ribeye beef, ground round meatloaf rump beef ribs biltong brisket t-bone buffalo prosciutto pork loin tail spare ribs. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Ham ham hock short loin fatback filet mignon, venison meatball swine sausage pork andouille capicola frankfurter. T-bone short loin porchetta chuck salami pancetta. Short loin shankle pastrami drumstick chicken ribeye flank. Venison salami turducken, chicken filet mignon landjaeger sirloin tail kevin meatloaf short ribs bacon. Kevin pig beef tri-tip pastrami pork belly pork chop sirloin rump ribeye pork loin cow flank. Shoulder sirloin landjaeger venison chicken bresaola hamburger pastrami short ribs. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Short ribs burgdoggen salami, chuck pork belly pork flank. Shankle leberkas porchetta prosciutto sirloin buffalo. Bresaola andouille chicken, brisket fatback boudin buffalo frankfurter porchetta shoulder beef meatloaf. Bresaola kevin rump, ground round pork belly pork shankle shank short loin strip steak salami. Biltong brisket alcatra sirloin venison bresaola drumstick ham hock tri-tip tenderloin strip steak pork meatball short loin. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig.","tags":"life","url":"/snowshoeing.html"},{"title":"Hiking","text":"Hiking in the Mountains Bacon ipsum dolor amet spare ribs burgdoggen turducken shankle pork loin. Ham kevin meatball turducken, hamburger flank pancetta jerky andouille rump doner cow boudin jowl. Tri-tip cow turducken buffalo kielbasa boudin tail short loin jerky jowl pork chop fatback venison. Burgdoggen short ribs kevin pork frankfurter meatloaf. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Landjaeger cupim capicola sirloin ball tip, picanha turkey t-bone bresaola fatback biltong doner shoulder. Burgdoggen pork pig, turducken t-bone jerky rump frankfurter tongue buffalo turkey sausage leberkas. Jowl doner fatback venison biltong frankfurter pork cow pork belly pancetta ball tip ham hock sirloin short loin. Short ribs brisket beef ribs prosciutto bacon venison beef jowl cupim t-bone capicola meatball landjaeger. Tongue pork loin boudin chicken sirloin. Tri-tip ribeye beef, ground round meatloaf rump beef ribs biltong brisket t-bone buffalo prosciutto pork loin tail spare ribs. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Ham ham hock short loin fatback filet mignon, venison meatball swine sausage pork andouille capicola frankfurter. T-bone short loin porchetta chuck salami pancetta. Short loin shankle pastrami drumstick chicken ribeye flank. Venison salami turducken, chicken filet mignon landjaeger sirloin tail kevin meatloaf short ribs bacon. Kevin pig beef tri-tip pastrami pork belly pork chop sirloin rump ribeye pork loin cow flank. Shoulder sirloin landjaeger venison chicken bresaola hamburger pastrami short ribs. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Short ribs burgdoggen salami, chuck pork belly pork flank. Shankle leberkas porchetta prosciutto sirloin buffalo. Bresaola andouille chicken, brisket fatback boudin buffalo frankfurter porchetta shoulder beef meatloaf. Bresaola kevin rump, ground round pork belly pork shankle shank short loin strip steak salami. Biltong brisket alcatra sirloin venison bresaola drumstick ham hock tri-tip tenderloin strip steak pork meatball short loin. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig. Leberkas ground round kevin chuck, shankle tail pork loin ham turducken meatloaf pork belly sausage capicola sirloin. Tri-tip biltong pork loin tongue. Tenderloin shank filet mignon capicola. Turducken bacon beef, tail landjaeger burgdoggen biltong beef ribs filet mignon shankle sirloin flank tongue drumstick pig.","tags":"life","url":"/hiking.html"},{"title":"PyData Amsterdam 2018","text":"Section","tags":"Talks & workshops","url":"/rod360.html"},{"title":"\"I Pity the fool\", Deep Learning style","text":"This post was originally published in the GoDataDriven blog With deep learning applications blossoming, it is important to understand what makes these models tick. Here I demonstrate, using simple and reproducible examples, how and why deep neural networks can be easily fooled. I also discuss potential solutions. Several studies have been published on how to fool a deep neural network (DNN). The most famous study, which was published in 2015 used evolutionary algorithms or gradient ascent to produce the adversarial images. 1 A very recent study (October 2017) revealed that fooling a DNN could be achieved by changing a single pixel. 2 This subject seems fun and all but has substantial implications on current and future applications of deep learning. I believe that understanding what makes these models tick is extremely important to be able to develop robust deep learning applications (and avoid another event like random forest mania). 3 A comprehensive and complete summary can be found in the When DNNs go wrong blog, which I recommend you to read. All these amazing studies use state of the art deep learning techniques, which makes them (in my opinion) difficult to reproduce and to answer questions we might have as non-experts in this subject. My intention in this blog is to bring the main concepts down to earth, to an easily reproducible setting where they are clear and actually visible. In addition, I hope this short blog can provide a better understanding of the limitations of discriminative models in general. The complete code used in this blog post can be found here . Discriminative what? Neural networks belong to the family of discriminative models, they model the dependence of an unobserved variable (target) based on observed input (features). In the language of probability this scenario is represented by the conditional probability and it is expressed as: $$p(target|features)$$ it reads: the probability of the target given the features (e.g. the probability that it will rain based on yesterday's weather, temperature and pressure measurements). Multinomial logistic regression models are also part of these discriminative models and they basically are a neural network without a hidden layer. Please don't be disappointed but I will start by demonstrating some concepts using multinomial logistic regression. Then I'll expand the concepts to a deep neural network. Fooling multinomial logistic regression As mentioned before a multinomial logistic regression can be seen as a neural network without a hidden layer. It models the probability of the target ( \\(Y\\) ) being a certain category ( \\(c\\) ), as a function ( \\(F\\) ) that depends on the linear combination of the features ( \\(X=(X_1, X_2,...,X_N)\\) ). We write this as $$P(Y=c|X)=F(\\theta_{c}&#94;T\\cdot X)$$ where \\(\\theta_c\\) are the coefficients of the linear combination for each category. The predicted class by the model is the one which gives the highest probability. When the target \\(Y\\) is binary, \\(F\\) is taken to be some sigmoid function , the most common being the logistic function . When \\(Y\\) is multiclass we commonly use \\(F\\) as the softmax function . Apart from the conceptual understanding of discriminative models, the linear combination of the features ( \\(\\theta_{c}&#94;T\\cdot X\\) ) is what makes classification models vulnerable as I will demonstrate. In the own words of Master Jedi Goodfellow: \"Linear behavior in high-dimensional spaces is sufficient to cause adversarial examples\". 4 Iris dataset When I was thinking on how to do this blog post and actually visualize the concepts, I concluded I needed two things: A 2-dimensional feature space. A model with high accuracy on this space. The 2-dimensional space because I wanted to generate plots which directly show the concepts. High accuracy because it's meaningless if I am able to fool a bad model. Lucky for me, it turns out that a good accuracy can be obtained on the Iris dataset by just keeping two features: petal length and petal width. Putting everything into shape this is how the data looks like This dataset contains only 150 observations, I will fit the model to all the data using a cross-entropy loss function and a L2 regularization term. This is just a plug and play from the amazing scikit-learn. model = LogisticRegression ( max_iter = 100 , solver = 'lbfgs' , multi_class = 'multinomial' , penalty = 'l2' ) model . fit ( X = iris . loc [:, iris . columns != 'flower' ], y = iris . flower ) The mean accuracy of the model is \\(96.6\\%\\) . This score is based on the training data and can be misleading, even if I am using a regularization term I can still be overfitting. 5 Let's now look at our predictions and at how our model is drawing the classification boundaries. In Figure 0 the red outer circles indicate those observations that were wrongly classified. The setosa flowers are easily identified and there is a region where the versicolor and virginica observations are close together. In Figure 1 we can see the different regions for each flower category. The regions are separated by a linear boundary, this is a consequence of the linear combination model used \\(P(Y=c|X)=F(\\theta_{c}&#94;T\\cdot X)\\) . As mentioned, in the case of a logistic regression (binary classification) \\(F\\) is the logistic function $$F(\\theta_{c}&#94;T\\cdot X)=\\frac{1}{1 + e&#94;{-\\theta_{c}&#94;T\\cdot X}}$$ and the classification boundary is given by \\(P(Y=c|X)=\\frac{1}{2}\\) when \\(\\theta_{c}&#94;T\\cdot X=0\\) . If the features are in one dimension then the boundary will be a single value, for two features the boundary is a single line and for three features a plane and so on. In our multinomial case we use the softmax function $$F(\\theta_{c}&#94;T\\cdot X)=\\frac{e&#94;{\\theta_{c}&#94;T\\cdot X}}{\\Sigma_{i=1}&#94;Ne&#94;{\\theta_{i}&#94;T\\cdot X}}$$ where the sum over \\(i\\) in the denominator runs over all the possible classes of the target. In the regions where only two classes have a non-negligible probability the softmax function simplifies to the logistic function. Therefore the linear classification boundaries between two regions is given by the contour \\(P(Y=c|X)=\\frac{1}{2}\\) as shown in Figure 3. In addition, when none of the classes have a negligible probability the boundary approaches the contour \\(P(Y=c|X)=\\frac{1}{3}\\) where the uncertainty of our prediction is maximum. This region is illustrated in Figure 2. A thing to note is that the regions extend to values which can be very far from the observations, which means we can grab a petal length of 1 and petal width of 4 and still be classified as a setosa. Even more, Figure 4 shows that even far away from our observations we can find regions with extremely high probability. We can even use a negative petal length! Let's pick some points from Figure 4 and see if I am able to fool the multinomial logistic classifier: Point: (.1, 5) Prediction: setosa Probability: 0.998 Point: (10, 10) Prediction: virginica Probability: 1.0 Point: (5, -5) Prediction: versicolor Probability: 0.992 The three points give a high probability on the prediction but are not even remotely like the observations in our dataset. Ok, now to the good stuff. Fooling a Deep Neural Network As I said before, in order for me to demonstrate the concepts and have a comprehensive visualization I need two things A 2-dimensional feature space. A model with high accuracy on this space. In the case of a deep neural network it makes no sense to attack a problem with 2 features, as the intent of neural network is to throw a bunch of features as the input layer and let the hidden layers figure out and construct new features which are relevant to my classification problem. So my reasoning as how to solve my first requirement goes as follows: Build a DNN where the last hidden layer has two units. Then do the space analysis on the features from that layer. Pick a point on that layer space which is far from the propagated observations but still is classified with a high probability. Invert all the operations made from the input layer to that last hidden layer and apply them to my selected 2D point from step 3. If I can perform those steps I should end with an input which is nothing like my observations but still is classified with high probability by the DNN, giving me an adversarial example. MNIST I chose the MNIST digits since it is a straight forward dataset to perform classification and it is complex enough to apply a DNN. I only take 4 classes, the numbers \\({0, 1, 2, 3}\\) . The final dataset consists of a bit more than 28,000 observations with 28x28=784 features. digits = fetch_mldata ( \"MNIST original\" ) index = np . in1d ( digits . target , [ 0 , 1 , 2 , 3 ]) digits . data = digits . data [ index ] digits . target = digits . target [ index ] Number of observations: 28911 Nr. observations per class: 1.0 7877 3.0 7141 2.0 6990 0.0 6903 A sample view of our observations: DNN configuration The challenge here is to find the correct configuration such that the training of the DNN converges and has a good performance on the training set. In addition, in order to be able to invert all the operations from the input layer to the last hidden layer then all functions applied must have an inverse. This means that if I decide to use any of the activation functions provided: logistic, tanh and relu, I need to keep track and impose restrictions on my nodes activation so that they are in the codomain of the activation function. This is not trivial and in my opinion does not add much to the concepts I'm trying to get across. Therefore I use the identity activation which can make the convergence a bit more tricky. 6 The final configuration of the DNN consists of: 3 hidden layers with sizes {50, 20, 2}. Identity activation function (no activation function). Stochastic gradient descent optimizer (sgd). Adaptive learning rate. dnn_identity = MLPClassifier ( hidden_layer_sizes = ( 50 , 20 , 2 ), activation = 'identity' , solver = 'sgd' , learning_rate = 'adaptive' , learning_rate_init =. 00005 , random_state = 21 ) The DNN achieved close to 95% accuracy and reached conversion quite nicely as shown in Figure 6. For comparison and for use in my arguments I built another DNN with an activation function \\(tanh\\) using the Adam optimizer. dnn_tanh = MLPClassifier ( hidden_layer_sizes = ( 50 , 20 , 2 ), activation = 'tanh' , solver = 'adam' , learning_rate_init =. 0001 , random_state = 21 ) The second DNN with the activation function achieved an accuracy of 98%, the loss curve in Figure 7 reveals that the training can be further improved but for now this is good enough. Extract feature encoding from the last hidden layer Once the model is trained we can retrieve the coefficients connecting all the layers. We use these coefficients to \"manually\" propagate our observations input up to the last hidden layer and then plot some of them in a 2D graph. This small function propagates the input layer up to a specified layer. def propagate ( input_layer , layer_nr , dnn , activation_function ): \"\"\"Obtain the activation values of any intermediate layer of the deep neural network.\"\"\" layer = input_layer for intercepts , weights in zip ( dnn . intercepts_ [: layer_nr ], dnn . coefs_ [: layer_nr ]): layer = activation_function ( layer . dot ( weights ) + intercepts ) return layer hl_identity = propagate ( digits . data , 3 , dnn_identity , lambda x : x ) hl_tanh = propagate ( digits . data , 3 , dnn_tanh , np . tanh ) The representation of the observations under the encoding of the last 2D hidden layer is shown on Figure 8 and 9. The identity DNN, as shown in Figure 8, has encoded our observations by creating hidden features which separate them in the hidden layer dimensionality (2D in this case). The more sophisticated \\(tanh\\) DNN achieves better performance because it is capable of coming up with hidden features which separate in a better way our observations as shown in Figure 9. Nevertheless Figures 10 and 11 reveal that in both cases linear classification boundaries are being constructed to separate our category regions. Similar to the multinomial logistic regression, this is caused by the dot product (linear Kernel) between the last hidden layer and the final weights which connect the hidden layer with the output layer. This means that these regions extend far away from where our observations lie, even more these regions have a high probability as shown in Figure 12 and 13. So now the only thing to do is to grab a point from Figure 8 (for example: -200, 200), do all the inverse operations to bring back the encoding to the input layer and reshape the vector into an image which of course will look nothing like a \\(1\\) but will be classified as a \\(1\\) with very high probability by our DNN. Brief tangent Before proceeding I would like to have a more conceptual discussion regarding the implications of the arguments presented for figure 8 and 9. The DNN creates hidden features which separate our observations as best as possible. This means that such hidden features will concentrate on capturing differences between our classes. For example, let's say we want to classify dogs and horses 7 . According to our reasoning, will a feature that captures the amount of legs be created? I don't think so, because having such a feature doesn't add to the purpose of separating our classes. We can send a horse with 5 legs and this fact will not raise any flags on our DNN. I believe this is the underlying concept when we say that discriminative models do not capture the essence of the objects to be classified. Here is where generative models come to the rescue, they recently have shown amazing results by capturing the underlying \"context\" of the objects. In a probability framework they shift from modelling the conditional probability to model the joint probability. Notice that the probability near the boundaries grows exponentially with the product \\(\\theta_c\\cdot X\\) following the sigmoid function. This means that if we take an observation which lies close to a boundary, it takes a small perturbation to take it to another region. This is the principle behind the study of fooling a DNN with a single pixel change 2 . Finally notice that all our analysis is in a 2D space and as such the regions extend in a surface. In a 3D space these regions will become volumes, hence increasing the region size where adversarial examples can be found. Just like Master Jedi Goodfellow said: \"Linear behavior in high-dimensional spaces is sufficient to cause adversarial examples\" 3 . Pity the fool A bit of linear algebra. Two consecutive layers can be described by a set of linear equations which in matrix notation can be represented by 8 : $$L_{N}&#94;i\\times \\Theta_{N\\times M}=L_{M}&#94;{i+1}$$ where \\(i\\) is a certain layer number, \\(N\\) and \\(M\\) the number of units in the layer and \\(\\Theta\\) the coefficients representing the connections between layers. In our DNN each layer reduces in size, this means that \\(N>M\\) . In order to find the layer \\(i\\) from the layer \\(i+1\\) we need to find the inverse of \\(\\Theta_{N\\times M}\\) and compute $$L_{N}&#94;i=L_{M}&#94;{i+1}\\times \\Theta_{N\\times M}&#94;{-1}$$ The problem (of course) is that non-square matrices do not have an inverse. In the DNN context, what is happening is that we are losing information by compacting our observations in a lower dimensional space. This means there is no way to exactly trace back layers, simply because we don't have enough information. This does not mean that we cannot find a vector representing \\(L&#94;i_N\\) which satisfies \\(L_{N}&#94;i\\times \\Theta_{N\\times M}=L_{M}&#94;{i+1}\\) given the layer \\(L&#94;{i+1}_M\\) and the coefficients \\(\\Theta_{N\\times M}\\) , which means that such vector is not unique. A solution for the layer \\(L_{N}&#94;i\\) can be derived using the pseudoinverse, in particular the Mooreâ€“Penrose inverse is adequate for our type of problem, and best of all it is implemented in Numpy! Below I define a function which inverts the propagation from a hidden layer to the input layer with an identity activation function. 9 def invert_propagation ( hidden_layer , layer_nr , dnn ): \"\"\"Obtain the input layer from a hidden layer of a deep neural network\"\"\" layer = hidden_layer for intercepts , weights in zip ( nn . intercepts_ [ layer_nr :: - 1 ], nn . coefs_ [ layer_nr :: - 1 ]): inv_weight = np . linalg . pinv ( weights ) layer = ( layer - intercepts ) . dot ( inv_weight ) return layer Finally, the moment of truth. I choose a nonsense value for each region by looking at Figures 10 and 12. In particular I choose: Region 0: (1200, -300) Region 1: (-500, 500) Region 2: (100,400) Region 3: (-1000, 900) Now I invert the propagation for each point, obtain the input layer, reshape the input to a 28x28 image and show it together with the prediction from the DNN and the probability of such prediction. def pity_the_fool ( hidden_vector , dnn , ax ): input_vector = invert_propagation ( hidden_vector , 2 , dnn_identity ) ax . imshow ( input_vector . reshape (( 28 , 28 )), cmap = 'gray' ) prediction = dnn . predict ( input_vector . reshape ( 1 , - 1 ))[ 0 ] probability = np . max ( dnn . predict_proba ( input_vector . reshape ( 1 , - 1 ))) ax . set_title ( \"Prediction: {:.0f} \\n \" \"Probability: {:.3f} \\n \" \"Hiden vector: {}\" . format ( prediction , probability , hidden_vector )) ax . axis ( 'off' ) The figures above clearly show that I have managed to fool the DNN. It is like the DNN had some Mexican peyote or something. The labels are consistent with the regions we took the points from and are classified with almost 100% probability. There is no way a human eye can tell that those images are a 0, a 1, a 2 and a 3. Not even to tell that there are numbers. Light at the end of the tunnel I have stated that the main problem is the linear classification boundaries, is there a way we can avoid this? Well, I left a hint out there when I mentioned that the dot product presented is nothing more than a linear kernel. I will not go into the details of how the kernel trick works, but in summary it lets us perform dot products in higher dimensional spaces of our features without ever computing the new features in that high-dimensional space. If you never heard about it, it can be a bit of a weird thing. Just to mess more with your cerebro, if for example we were to use the Gaussian kernel , this is equal to performing calculations in an infinite high-dimensional space, yes infinite! 10 By using these kernels the model is not restricted to linear classification boundaries. Below I compare a support vector machine model (SVM) with a linear kernel and a Gaussian kernel using the iris dataset. svm_linear = SVC ( kernel = 'linear' , probability = True ) svm_gaussian = SVC ( kernel = 'rbf' , probability = True ) Both SVM models obtain an accuracy of \\(\\approx 96.6%\\) . Figure 18 shows that the SVM with the linear kernel also suffers from the issues discussed. In general any discriminative model that is trying to model the conditional probability via some transformation of the dot product \\(\\Theta\\cdot X\\) is doomed to be susceptible to adversarial examples attacks. Figure 19 is beautiful, shows exactly how getting rid of the linearity ( \\(\\Theta\\cdot X\\) ) allows for non-linear classification boundaries and hence the regions with high probability do not extend indefinitely. In this case all points with high probability are close to our observations, so in principle they should \"look\" like our observations. A SVM with a Gaussian kernel can't accomplish the extremely complicated tasks that deep neural networks can, but an idea could be to find a way to implement a non-linear kernel between the last hidden layer and the output layer. This discussion is outside the of scope of this article, but hopefully I will find the time to look into it and write about my findings. Another solution to the above discussed issues lies in a completely different perspective, instead of trying to model the conditional probability, try to model the joint probability with generative models. These models should capture the underlying \"context\" of our observations and not only what makes them different. This fundamental difference allows generative algorithms to do things which are impossible for a DNN. Such as producing never seen examples which have a striking resemblance to original observations, and even more to tune the context of these examples. A super nice demonstration is the generation of never seen faces where the degree of smiling and sunglasses is tuned. Adios Well that took much more work than I expected. I hope you enjoyed reading this blog post and got excited about deep learning. You can find the code here . If you have any other questions just ping me in twitter @rragundez . Deep Neural Networks are Easily Fooled â†© One pixel attack for fooling deep neural networks â†© â†© This should be the case not only for Deep Learning models but all models in general. I increasingly see pseudo Data Scientist making outrageous claims or using models with a one-fits-all mentality. I understand there are juniors in the organizations but that's why you should have a strong Lead Data Scientist to provide guidance or hire GoDataDriven to make your team blossom, not only on their technical abilities but also in their mentality when attacking a problem. â†© â†© Explaining and harnessing adversarial examples â†© For the demonstration I decided to train on all the data since the dataset is so small (150 observations). In the deep neural network case I will use a much larger dataset and a test set. â†© It is known that no activation function can lead to exploiting activations values which in turn affect the convergence of the Deep Neural Network. â†© I don't like cats. â†© This is taking into account the intercept into the coefficients and adding a unit to layer \\(i\\) with an activation of 1. â†© If you were to use an activation function here is where you need to be careful that activation stay in the codomain of activation function. Since we cannot exactly reconstruct the previous layer we cannot be sure that the pseudo inverse will yield values which are outside the codomain therefore generating an exception. I tried a little bit with the tanh activation function but at least for me it was not straight forward. â†© This is because of the Taylor expansion of the exponential function. â†© if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"/fool-neural-network.html"},{"title":"Machine Learning Application Skeleton","text":"In this blog post I provide an overview of a Python skeleton application I made. This skeleton can help you bridge the gap between your model and a machine learning application. For example, you can use your existing Flask application, import it in run_app.py as app , and this will add the production ready features of Gunicorn . Take me to the code Why bother? The times when business saw machine learning models as black boxes with no hope of understanding are long gone. It use to be that the data analytics or data science department of a company produced results in a silo kind of environment. Little or no interaction took place between these departments and the business side making the decisions (marketing, sales, client support, etc.). Advice coming from machine learning models consisted of reports, which were nice to have if they supported ideas from the business. As data driven decisions demonstrated their value, the business side started peeking behind the curtain. Paper/files reports have been substituted by static reporting dashboards, which themselves are being replaced by interactive ones. The business end users want to interact with the models, understand why certain predictions are made and evenmore, they want to be capable of performing predictions on the fly (imagine simultaneously having a customer on the phone and updating the probabilities of him/her buying certain products, or a marketing department tuning campaigns themselves depending on regional features). In short, I had some time during a rainy weekend and a GDD Friday 1 , already did something similar for a client and I think it is important to bring machine learning models to the business side. Also, as a bonus they will stop bothering you every time they need insights or a slightly different prediction. What's in the goody bag? Template to extend a Flask application using Gunicorn . This allows the application to be run in a more production ready environment (multiple workers and threads for example). In here you can find a complete list of all the possible Gunicorn settings. I added the possibility to use some of them as command line arguments. Some relevant ones are: host port workers - define number of workers. threads - number of threads on each worker. daemon - run application in the background. access-logfile - save access logs to a file. forwarded-allow-ips - list allowed IP addresses. Dummy application which demonstrates how to ingest several types of user inputs into your Python application. Debug mode which (similar to Flask) will run a single process logging to debug level restart process on code change reload html and jinja templates on change Dockerfile template to containerize the application. Interactive application which runs a classifier model, outputs predictions and information about the machine learning model. The model can be run by using the UI or by directly making a post request to the endpoint. A more complete description, a set of instructions and the code can be found in this repository . Note: I also include a setup.py file that you should use to install your package used in the application. Adios If you structure your project following the advice from Henk Griffioen (A.K.A. El Chicano), the integration of this ML application skeleton to your project should be straight forward. I hope this work can help you bring your models into a machine learning application, it certainly helped and will help me in the future. You can find the code here . If you have any other questions just ping me in twitter @rragundez . One Friday a month when we get to do whatever we want, it is awesome. â†©","tags":"tech","url":"/ml-pyapp.html"},{"title":"Facebook's Prophet: Forecasting Stores Transactions","text":"This post was originally published in the GoDataDriven blog Yesterday Giovanni , our Chief Scientist, mentioned this recently released (2 days ago in github ) open source forecasting API by Facebook's Core Data Science team, so I decided to give it a try during one of our famous GDD Fridays. In Prophet's own words: \" Prophet is a procedure for forecasting time series data. It is based on an additive model where non-linear trends are fit with yearly and weekly seasonality, plus holidays. It works best with daily periodicity data with at least one year of historical data. Prophet is robust to missing data, shifts in the trend, and large outliers\". Prophet's algorithm explanation can be found in this article . Prophet offers a R and Python API, I used the Pythton API of course. Why bother? The data belongs to a customer for which models are alreading in production. I wanted to see how Prophet's forecasts behave using the same data we use in one of these models developed by Rogier and me. In reality, the forecast of the number of transactions in a shop is used as a part of an ensemble to predict products sales. Since Prophet does not accept features, it would be unfair to make a comparison at that level since, for example, price is a very important factor. Data: transactions and holidays The data is of a current client, therefore I won't be disclosing any details of it. Our models make forecasts for different shops of this company. In particular I took 2 shops, one which contains the easiest transactions to predict from all shops, and another with a somewhat more complicated history. The data consists of real transactions since 2014. Data is daily with the target being the number of transactions executed during a day. There are missing dates in the data when the shop closed, for example New Year's day and Christmas. The holidays provided to the API are the same I use in our model. They contain from school vacations or large periods, to single holidays like Christmas Eve. In total, the data contains 46 different holidays. Code If the data is in a nice format (this is a big if), Prophet provides a very easy to use API. In particular, once I cleaned, aggregated and dumped the data, the calculation consisted on these two pieces of code: def predict ( tseries , predict_date , holidays = None ): model = Prophet ( holidays = holidays ) # train on data until 3 days before model . fit ( tseries [ tseries . ds < ( predict_date - timedelta ( days = 2 ))]) forecast = model . predict ( model . make_future_dataframe ( periods = 5 )) return forecast . loc [ forecast . ds == predict_date , [ 'ds' , 'yhat' ]] pred = [] pred_holidays = [] for date in pd . date_range ( '2016-1-1' , '2016-12-31' ): pred . append ( predict ( tseries_shop , date )) pred_holidays . append ( predict ( tseries_shop , date , holidays = holidays )) predictions = pd . merge ( pd . concat ( pred ), pd . concat ( pred_holidays ), on = 'ds' , how = 'inner' , suffixes = ( '' , '_hol' )) The forecast is done for 2016 with and without holiday data. Our production model gets trained daily via an Airflow job, to make a fair comparison, I train a Prophet model for each date in 2016 using the data until 3 days before the date to be forecast. This is because the order for a product needs to be submitted 2 days before, which means it uses the data available until then. Prophet leveraged the full capacity of my laptop using all 8 cores. The calculation took around 45 minutes per shop, which means a single day with or without holidays takes around 4 seconds. Metric The metric I used to measure the forecast performance is the coefficient of determination ( \\(R&#94;2\\) score) . The \\(R&#94;2\\) score gives the proportion of the variance in the data that is explained by the forecast. A perfect forecast will give 1.0 and a constant prediction for every day will give 0.0. Easy shop: Widushop Using Vincent's awesome Pokemon name generator , I will call this shop Widushop. This is the transaction data for the 3 years, The image shows a very similar pattern each year. Also, it shows some days that are definitely holidays where transactions drop or increase dramatically. Prophet produces a very accurate forecast, it scores 0.89 without using holidays and 0.94 using holidays. Below I show a comparison between the transactions (truth) and the forecast using holidays. Pretty nice! Overall it produces very good results, for holidays seems to overestimate (look at Christmas Eve), nevertheless that can be tuned by the parameter holidays.prior.scale as stated in the documentation . Difficult shop: Qumashop This time the shop name generated is Qumashop. The transaction history of Qumashop is more chaotic than the one for Widushop. Below I show the transaction history of Qumashop. Holidays have a much greater impact. Look at that peak in the middle of July, this is a known event that draws a lot of people to the city (it is in the holidays data). Notice that transactions in 2016 are considerably higher than other years, specially from July until September. Not catching this uprise trend would mean losing a lot of potential sales. This time the Prophet forecast is not as good as for Widushop giving 0.64 without holiday data and a solid 0.82 using holidays. Below I show a comparison between the transactions (truth) and the forecast using holidays for Qumashop. Look at that! very nice. I am specially happy that it catched the mentioned trend between July and September. Moreover, the residuals on the week following the big peak in July, the second week in September and the two weeks at the end of October are too high. Remember that in practice this is just a model of an ensemble, is better to have a little overall bigger residual that can reduced by other models, than having weeks with such big errors. Perhaps the forecasts for the week after the big peak in July can improve by introducing a changepoint the last day of the peak holiday week. Wrap-up Prophet's out of the box results were impressive. The quality of the forecasts are comparable with those from our current model in production for these 2 shops. Calculations were parallelized over all 8 cores of my machine. Training plus prediction time for each date was about 4 seconds. The API is ridiculously easy to use and the documentation seems sufficient. For what I can read in the documentation , Prophet does not accept features. Nevertheless, Prophet's forecasts can be part of an ensemble that produces predictions with a higher granularity. It would be interesting to make a comparison for every shop. I was surprised by the result on the difficult shop history. There are also several hyperparameters that would be interesting to look into, among several, these in particular: cap : the maximum possible value of the target. changepoint : indicate where do we expect an abrupt change in the time series. changepoint_prior_scale : related to how strongly should the model adjust to trends. holidays_prior_scale : adjust the importance of holiday effects. interval_width : sets the uncertainty interval to produce a confidence interval around the forecast. This could be very useful for monitoring the quality of the forecast. Defaults to 80%. To anyone starting a project using time-series for forecasting, I really recommend taking a close look at this tool. Great work Prophet! I hope this blog has been helpful and please bother me @rragundez with your results of playing around with Prophet. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"tech","url":"/prophet-quicklook.html"}]}